{
  "modules": {
    "BaseHTTPServer": {
      "file": "BaseHTTPServer.py", 
      "imports": [
        "sys", 
        "time", 
        "mimetools", 
        "socket", 
        "SocketServer", 
        "warnings"
      ]
    }, 
    "Bastion": {
      "file": "Bastion.py", 
      "imports": [
        "rexec", 
        "types", 
        "warnings"
      ]
    }, 
    "CGIHTTPServer": {
      "file": "CGIHTTPServer.py", 
      "imports": [
        "BaseHTTPServer", 
        "base64", 
        "binascii", 
        "select", 
        "subprocess", 
        "sys", 
        "copy", 
        "os", 
        "SimpleHTTPServer", 
        "urllib", 
        "pwd"
      ]
    }, 
    "ConfigParser": {
      "file": "ConfigParser.py", 
      "imports": [
        "collections", 
        "re", 
        "UserDict"
      ]
    }, 
    "Cookie": {
      "file": "Cookie.py", 
      "imports": [
        "Cookie", 
        "time.gmtime", 
        "time.time", 
        "doctest", 
        "pickle", 
        "re", 
        "string", 
        "warnings", 
        "cPickle"
      ]
    }, 
    "DocXMLRPCServer": {
      "file": "DocXMLRPCServer.py", 
      "imports": [
        "sys", 
        "inspect", 
        "pydoc", 
        "re", 
        "SimpleXMLRPCServer"
      ]
    }, 
    "HTMLParser": {
      "file": "HTMLParser.py", 
      "imports": [
        "htmlentitydefs", 
        "markupbase", 
        "re"
      ]
    }, 
    "MimeWriter": {
      "file": "MimeWriter.py", 
      "imports": [
        "mimetools", 
        "test.test_MimeWriter", 
        "warnings"
      ]
    }, 
    "Queue": {
      "file": "Queue.py", 
      "imports": [
        "collections", 
        "dummy_threading", 
        "heapq", 
        "threading", 
        "time.time"
      ]
    }, 
    "SimpleHTTPServer": {
      "file": "SimpleHTTPServer.py", 
      "imports": [
        "BaseHTTPServer", 
        "cStringIO.StringIO", 
        "cgi", 
        "mimetypes", 
        "os", 
        "posixpath", 
        "shutil", 
        "sys", 
        "StringIO", 
        "urllib"
      ]
    }, 
    "SimpleXMLRPCServer": {
      "file": "SimpleXMLRPCServer.py", 
      "imports": [
        "BaseHTTPServer", 
        "fcntl", 
        "os", 
        "pydoc", 
        "re", 
        "sys", 
        "SocketServer", 
        "traceback", 
        "xmlrpclib"
      ]
    }, 
    "SocketServer": {
      "file": "SocketServer.py", 
      "imports": [
        "cStringIO.StringIO", 
        "dummy_threading", 
        "errno", 
        "os", 
        "select", 
        "socket", 
        "sys", 
        "threading", 
        "StringIO", 
        "traceback"
      ]
    }, 
    "StringIO": {
      "file": "StringIO.py", 
      "imports": [
        "errno.EINVAL", 
        "sys"
      ]
    }, 
    "UserDict": {
      "file": "UserDict.py", 
      "imports": [
        "_abcoll", 
        "copy"
      ]
    }, 
    "UserList": {
      "file": "UserList.py", 
      "imports": [
        "collections"
      ]
    }, 
    "UserString": {
      "file": "UserString.py", 
      "imports": [
        "collections", 
        "os", 
        "sys", 
        "test.test_support", 
        "warnings"
      ]
    }, 
    "_LWPCookieJar": {
      "file": "_LWPCookieJar.py", 
      "imports": [
        "time", 
        "cookielib", 
        "re"
      ]
    }, 
    "_MozillaCookieJar": {
      "file": "_MozillaCookieJar.py", 
      "imports": [
        "time", 
        "cookielib", 
        "re"
      ]
    }, 
    "__future__": {
      "file": "__future__.py", 
      "imports": []
    }, 
    "__init__": {
      "file": "__init__.py", 
      "imports": []
    }, 
    "__phello__.foo": {
      "file": "__phello__.foo.py", 
      "imports": []
    }, 
    "_abcoll": {
      "file": "_abcoll.py", 
      "imports": [
        "sys", 
        "abc"
      ]
    }, 
    "_codecs_cn": {
      "file": "_codecs_cn.py", 
      "imports": [
        "_multibytecodec.__getcodec"
      ]
    }, 
    "_codecs_hk": {
      "file": "_codecs_hk.py", 
      "imports": [
        "_multibytecodec.__getcodec"
      ]
    }, 
    "_codecs_iso2022": {
      "file": "_codecs_iso2022.py", 
      "imports": [
        "_multibytecodec.__getcodec"
      ]
    }, 
    "_codecs_jp": {
      "file": "_codecs_jp.py", 
      "imports": [
        "_multibytecodec.__getcodec"
      ]
    }, 
    "_codecs_kr": {
      "file": "_codecs_kr.py", 
      "imports": [
        "_multibytecodec.__getcodec"
      ]
    }, 
    "_codecs_tw": {
      "file": "_codecs_tw.py", 
      "imports": [
        "_multibytecodec.__getcodec"
      ]
    }, 
    "_collections": {
      "file": "_collections.py", 
      "imports": [
        "threading._get_ident"
      ]
    }, 
    "_csv": {
      "file": "_csv.py", 
      "imports": []
    }, 
    "_ctypes_test": {
      "file": "_ctypes_test.py", 
      "imports": [
        "_ctypes", 
        "cpyext", 
        "imp", 
        "os", 
        "_pypy_testcapi"
      ]
    }, 
    "_curses": {
      "file": "_curses.py", 
      "imports": [
        "cffi.FFI", 
        "functools", 
        "sys"
      ]
    }, 
    "_curses_panel": {
      "file": "_curses_panel.py", 
      "imports": [
        "_curses"
      ]
    }, 
    "_elementtree": {
      "file": "_elementtree.py", 
      "imports": [
        "xml.etree.ElementTree"
      ]
    }, 
    "_functools": {
      "file": "_functools.py", 
      "imports": []
    }, 
    "_marshal": {
      "file": "_marshal.py", 
      "imports": [
        "__pypy__.builtinify", 
        "sys.intern", 
        "types"
      ]
    }, 
    "_md5": {
      "file": "_md5.py", 
      "imports": [
        "copy", 
        "struct"
      ]
    }, 
    "_osx_support": {
      "file": "_osx_support.py", 
      "imports": [
        "sys", 
        "contextlib", 
        "distutils.log", 
        "os", 
        "re", 
        "tempfile"
      ]
    }, 
    "_pyio": {
      "file": "_pyio.py", 
      "imports": [
        "__future__", 
        "_io.FileIO", 
        "array", 
        "errno", 
        "errno.EINTR", 
        "thread.allocate_lock", 
        "abc", 
        "codecs", 
        "dummy_thread", 
        "io", 
        "locale", 
        "os", 
        "warnings"
      ]
    }, 
    "_pypy_interact": {
      "file": "_pypy_interact.py", 
      "imports": [
        "__main__", 
        "code", 
        "os", 
        "sys", 
        "_pypy_irc_topic", 
        "pyrepl.simple_interact"
      ]
    }, 
    "_pypy_irc_topic": {
      "file": "_pypy_irc_topic.py", 
      "imports": [
        "string", 
        "time"
      ]
    }, 
    "_pypy_testcapi": {
      "file": "_pypy_testcapi.py", 
      "imports": [
        "binascii", 
        "distutils.ccompiler", 
        "imp", 
        "os", 
        "sys", 
        "tempfile"
      ]
    }, 
    "_pypy_wait": {
      "file": "_pypy_wait.py", 
      "imports": [
        "ctypes.CDLL", 
        "ctypes.POINTER", 
        "ctypes.byref", 
        "ctypes.c_int", 
        "ctypes.util.find_library", 
        "resource"
      ]
    }, 
    "_scproxy": {
      "file": "_scproxy.py", 
      "imports": [
        "ctypes.c_char_p", 
        "ctypes.c_int", 
        "ctypes.c_int32", 
        "ctypes.c_int64", 
        "ctypes.c_void_p", 
        "ctypes.cdll", 
        "ctypes.create_string_buffer", 
        "ctypes.pointer", 
        "ctypes.util.find_library", 
        "sys"
      ]
    }, 
    "_sha": {
      "file": "_sha.py", 
      "imports": [
        "copy", 
        "struct"
      ]
    }, 
    "_sha256": {
      "file": "_sha256.py", 
      "imports": [
        "struct"
      ]
    }, 
    "_sha512": {
      "file": "_sha512.py", 
      "imports": [
        "_sha512", 
        "struct"
      ]
    }, 
    "_sqlite3": {
      "file": "_sqlite3.py", 
      "imports": [
        "__pypy__.newlist_hint", 
        "cffi.FFI", 
        "collections", 
        "functools", 
        "os", 
        "sqlite3.dump", 
        "string", 
        "sys", 
        "threading._get_ident", 
        "weakref", 
        "datetime"
      ]
    }, 
    "_strptime": {
      "file": "_strptime.py", 
      "imports": [
        "thread.allocate_lock", 
        "time", 
        "calendar", 
        "dummy_thread", 
        "locale", 
        "re", 
        "datetime"
      ]
    }, 
    "_structseq": {
      "file": "_structseq.py", 
      "imports": []
    }, 
    "_testcapi": {
      "file": "_testcapi.py", 
      "imports": [
        "_pypy_testcapi", 
        "cpyext", 
        "imp", 
        "os"
      ]
    }, 
    "_threading_local": {
      "file": "_threading_local.py", 
      "imports": [
        "threading", 
        "threading.RLock", 
        "threading.current_thread"
      ]
    }, 
    "_weakrefset": {
      "file": "_weakrefset.py", 
      "imports": [
        "_weakref.ref"
      ]
    }, 
    "abc": {
      "file": "abc.py", 
      "imports": [
        "_weakrefset", 
        "types"
      ]
    }, 
    "aifc": {
      "file": "aifc.py", 
      "imports": [
        "__builtin__", 
        "audioop", 
        "cl", 
        "math", 
        "sys", 
        "chunk", 
        "struct"
      ]
    }, 
    "antigravity": {
      "file": "antigravity.py", 
      "imports": [
        "webbrowser"
      ]
    }, 
    "anydbm": {
      "file": "anydbm.py", 
      "imports": [
        "whichdb"
      ]
    }, 
    "argparse": {
      "file": "argparse.py", 
      "imports": [
        "sys", 
        "collections", 
        "copy", 
        "gettext", 
        "os", 
        "re", 
        "textwrap", 
        "warnings"
      ]
    }, 
    "ast": {
      "file": "ast.py", 
      "imports": [
        "_ast.*", 
        "_ast.__version__", 
        "collections", 
        "inspect"
      ]
    }, 
    "asynchat": {
      "file": "asynchat.py", 
      "imports": [
        "sys.py3kwarning", 
        "asyncore", 
        "collections", 
        "socket", 
        "warnings"
      ]
    }, 
    "asyncore": {
      "file": "asyncore.py", 
      "imports": [
        "errno.EAGAIN", 
        "errno.EALREADY", 
        "errno.EBADF", 
        "errno.ECONNABORTED", 
        "errno.ECONNRESET", 
        "errno.EINPROGRESS", 
        "errno.EINTR", 
        "errno.EINVAL", 
        "errno.EISCONN", 
        "errno.ENOTCONN", 
        "errno.EPIPE", 
        "errno.ESHUTDOWN", 
        "errno.EWOULDBLOCK", 
        "errno.errorcode", 
        "fcntl", 
        "select", 
        "sys", 
        "time", 
        "os", 
        "socket", 
        "warnings"
      ]
    }, 
    "atexit": {
      "file": "atexit.py", 
      "imports": [
        "sys", 
        "traceback"
      ]
    }, 
    "base64": {
      "file": "base64.py", 
      "imports": [
        "binascii", 
        "sys", 
        "getopt", 
        "re", 
        "struct"
      ]
    }, 
    "bdb": {
      "file": "bdb.py", 
      "imports": [
        "__main__", 
        "sys", 
        "fnmatch", 
        "linecache", 
        "os", 
        "repr", 
        "types"
      ]
    }, 
    "binhex": {
      "file": "binhex.py", 
      "imports": [
        "Carbon.File.FInfo", 
        "Carbon.File.FSSpec", 
        "MacOS.openrf", 
        "binascii", 
        "sys", 
        "os", 
        "struct"
      ]
    }, 
    "bisect": {
      "file": "bisect.py", 
      "imports": [
        "_bisect.*"
      ]
    }, 
    "cPickle": {
      "file": "cPickle.py", 
      "imports": [
        "__pypy__.builtinify", 
        "copy_reg", 
        "marshal", 
        "pickle", 
        "struct", 
        "sys", 
        "types"
      ]
    }, 
    "cProfile": {
      "file": "cProfile.py", 
      "imports": [
        "__main__", 
        "_lsprof", 
        "marshal", 
        "sys", 
        "optparse", 
        "os", 
        "pstats", 
        "types"
      ]
    }, 
    "cStringIO": {
      "file": "cStringIO.py", 
      "imports": [
        "StringIO"
      ]
    }, 
    "calendar": {
      "file": "calendar.py", 
      "imports": [
        "sys", 
        "locale", 
        "optparse", 
        "datetime"
      ]
    }, 
    "cgi": {
      "file": "cgi.py", 
      "imports": [
        "cStringIO.StringIO", 
        "operator.attrgetter", 
        "sys", 
        "mimetools", 
        "os", 
        "re", 
        "rfc822", 
        "StringIO", 
        "tempfile", 
        "traceback", 
        "urlparse", 
        "UserDict", 
        "warnings"
      ]
    }, 
    "cgitb": {
      "file": "cgitb.py", 
      "imports": [
        "sys", 
        "time", 
        "inspect", 
        "keyword", 
        "linecache", 
        "os", 
        "pydoc", 
        "tempfile", 
        "tokenize", 
        "traceback", 
        "types"
      ]
    }, 
    "chunk": {
      "file": "chunk.py", 
      "imports": [
        "struct"
      ]
    }, 
    "cmd": {
      "file": "cmd.py", 
      "imports": [
        "readline", 
        "sys", 
        "string"
      ]
    }, 
    "code": {
      "file": "code.py", 
      "imports": [
        "readline", 
        "sys", 
        "codeop", 
        "traceback"
      ]
    }, 
    "codecs": {
      "file": "codecs.py", 
      "imports": [
        "__builtin__", 
        "_codecs.*", 
        "sys", 
        "encodings"
      ]
    }, 
    "codeop": {
      "file": "codeop.py", 
      "imports": [
        "__future__"
      ]
    }, 
    "collections": {
      "file": "collections.py", 
      "imports": [
        "__pypy__.newdict", 
        "__pypy__.reversed_dict", 
        "_abcoll", 
        "_collections.defaultdict", 
        "_collections.deque", 
        "itertools.chain", 
        "itertools.imap", 
        "itertools.repeat", 
        "itertools.starmap", 
        "operator.eq", 
        "operator.itemgetter", 
        "sys", 
        "thread.get_ident", 
        "doctest", 
        "dummy_thread", 
        "heapq", 
        "keyword", 
        "cPickle"
      ]
    }, 
    "colorsys": {
      "file": "colorsys.py", 
      "imports": []
    }, 
    "commands": {
      "file": "commands.py", 
      "imports": [
        "os", 
        "warnings"
      ]
    }, 
    "compileall": {
      "file": "compileall.py", 
      "imports": [
        "imp", 
        "sys", 
        "getopt", 
        "os", 
        "py_compile", 
        "re", 
        "struct"
      ]
    }, 
    "compiler": {
      "dir": "compiler"
    }, 
    "compiler.__init__": {
      "file": "compiler/__init__.py", 
      "imports": [
        "compiler.pycodegen", 
        "compiler.transformer", 
        "compiler.visitor", 
        "warnings"
      ]
    }, 
    "compiler.ast": {
      "file": "compiler/ast.py", 
      "imports": [
        "compiler.consts"
      ]
    }, 
    "compiler.consts": {
      "file": "compiler/consts.py", 
      "imports": []
    }, 
    "compiler.future": {
      "file": "compiler/future.py", 
      "imports": [
        "compiler", 
        "compiler.ast", 
        "sys"
      ]
    }, 
    "compiler.misc": {
      "file": "compiler/misc.py", 
      "imports": []
    }, 
    "compiler.pyassem": {
      "file": "compiler/pyassem.py", 
      "imports": [
        "compiler.consts", 
        "compiler.misc", 
        "sys", 
        "dis", 
        "types"
      ]
    }, 
    "compiler.pycodegen": {
      "file": "compiler/pycodegen.py", 
      "imports": [
        "cStringIO.StringIO", 
        "compiler", 
        "compiler.ast", 
        "compiler.consts", 
        "compiler.future", 
        "compiler.misc", 
        "compiler.pyassem", 
        "compiler.symbols", 
        "compiler.syntax", 
        "imp", 
        "marshal", 
        "sys", 
        "os", 
        "pprint", 
        "struct"
      ]
    }, 
    "compiler.symbols": {
      "file": "compiler/symbols.py", 
      "imports": [
        "compiler", 
        "compiler.ast", 
        "compiler.consts", 
        "compiler.misc", 
        "symtable", 
        "sys", 
        "types"
      ]
    }, 
    "compiler.syntax": {
      "file": "compiler/syntax.py", 
      "imports": [
        "compiler", 
        "compiler.ast"
      ]
    }, 
    "compiler.transformer": {
      "file": "compiler/transformer.py", 
      "imports": [
        "compiler.ast", 
        "compiler.consts", 
        "parser", 
        "symbol", 
        "token"
      ]
    }, 
    "compiler.visitor": {
      "file": "compiler/visitor.py", 
      "imports": [
        "compiler.ast"
      ]
    }, 
    "contextlib": {
      "file": "contextlib.py", 
      "imports": [
        "sys", 
        "functools", 
        "warnings"
      ]
    }, 
    "cookielib": {
      "file": "cookielib.py", 
      "imports": [
        "_LWPCookieJar", 
        "_MozillaCookieJar", 
        "calendar", 
        "threading", 
        "time", 
        "copy", 
        "dummy_threading", 
        "httplib", 
        "logging", 
        "re", 
        "StringIO", 
        "traceback", 
        "urllib", 
        "urlparse", 
        "warnings"
      ]
    }, 
    "copy": {
      "file": "copy.py", 
      "imports": [
        "org.python.core.PyStringMap", 
        "sys", 
        "copy_reg", 
        "repr", 
        "types", 
        "weakref"
      ]
    }, 
    "copy_reg": {
      "file": "copy_reg.py", 
      "imports": [
        "types"
      ]
    }, 
    "csv": {
      "file": "csv.py", 
      "imports": [
        "_csv.Dialect", 
        "_csv.Error", 
        "_csv.QUOTE_ALL", 
        "_csv.QUOTE_MINIMAL", 
        "_csv.QUOTE_NONE", 
        "_csv.QUOTE_NONNUMERIC", 
        "_csv.__doc__", 
        "_csv.__version__", 
        "_csv.field_size_limit", 
        "_csv.get_dialect", 
        "_csv.list_dialects", 
        "_csv.reader", 
        "_csv.register_dialect", 
        "_csv.unregister_dialect", 
        "_csv.writer", 
        "cStringIO.StringIO", 
        "functools", 
        "re", 
        "StringIO"
      ]
    }, 
    "ctypes_config_cache": {
      "dir": "ctypes_config_cache"
    }, 
    "ctypes_config_cache.__init__": {
      "file": "ctypes_config_cache/__init__.py", 
      "imports": []
    }, 
    "ctypes_config_cache._locale_32_": {
      "file": "ctypes_config_cache/_locale_32_.py", 
      "imports": [
        "ctypes"
      ]
    }, 
    "ctypes_config_cache._locale_64_": {
      "file": "ctypes_config_cache/_locale_64_.py", 
      "imports": [
        "ctypes"
      ]
    }, 
    "ctypes_config_cache._locale_cache": {
      "file": "ctypes_config_cache/_locale_cache.py", 
      "imports": [
        "sys"
      ]
    }, 
    "ctypes_config_cache._resource_32_": {
      "file": "ctypes_config_cache/_resource_32_.py", 
      "imports": [
        "ctypes"
      ]
    }, 
    "ctypes_config_cache._resource_64_": {
      "file": "ctypes_config_cache/_resource_64_.py", 
      "imports": [
        "ctypes"
      ]
    }, 
    "ctypes_config_cache._resource_cache": {
      "file": "ctypes_config_cache/_resource_cache.py", 
      "imports": [
        "sys"
      ]
    }, 
    "ctypes_config_cache.dumpcache": {
      "file": "ctypes_config_cache/dumpcache.py", 
      "imports": [
        "ctypes_configure.dumpcache", 
        "os", 
        "sys"
      ]
    }, 
    "ctypes_config_cache.locale.ctc": {
      "file": "ctypes_config_cache/locale.ctc.py", 
      "imports": [
        "ctypes_config_cache.dumpcache", 
        "ctypes_configure.configure.ConstantInteger", 
        "ctypes_configure.configure.DefinedConstantInteger", 
        "ctypes_configure.configure.ExternalCompilationInfo", 
        "ctypes_configure.configure.SimpleType", 
        "ctypes_configure.configure.check_eci", 
        "ctypes_configure.configure.configure"
      ]
    }, 
    "ctypes_config_cache.rebuild": {
      "file": "ctypes_config_cache/rebuild.py", 
      "imports": [
        "os", 
        "py", 
        "rpython.tool.ansi_print.ansi_log", 
        "sys"
      ]
    }, 
    "ctypes_config_cache.resource.ctc": {
      "file": "ctypes_config_cache/resource.ctc.py", 
      "imports": [
        "ctypes.sizeof", 
        "ctypes_config_cache.dumpcache", 
        "ctypes_configure.configure.ConstantInteger", 
        "ctypes_configure.configure.DefinedConstantInteger", 
        "ctypes_configure.configure.ExternalCompilationInfo", 
        "ctypes_configure.configure.SimpleType", 
        "ctypes_configure.configure.configure"
      ]
    }, 
    "curses": {
      "dir": "curses"
    }, 
    "curses.__init__": {
      "file": "curses/__init__.py", 
      "imports": [
        "curses", 
        "curses.has_key", 
        "curses.wrapper", 
        "sys", 
        "os", 
        "_curses"
      ]
    }, 
    "curses.ascii": {
      "file": "curses/ascii.py", 
      "imports": []
    }, 
    "curses.has_key": {
      "file": "curses/has_key.py", 
      "imports": [
        "_curses"
      ]
    }, 
    "curses.panel": {
      "file": "curses/panel.py", 
      "imports": [
        "_curses_panel"
      ]
    }, 
    "curses.textpad": {
      "file": "curses/textpad.py", 
      "imports": [
        "curses", 
        "curses.ascii"
      ]
    }, 
    "curses.wrapper": {
      "file": "curses/wrapper.py", 
      "imports": [
        "curses"
      ]
    }, 
    "datetime": {
      "file": "datetime.py", 
      "imports": [
        "__future__", 
        "_strptime", 
        "math", 
        "struct", 
        "time"
      ]
    }, 
    "dbhash": {
      "file": "dbhash.py", 
      "imports": [
        "bsddb", 
        "sys", 
        "warnings"
      ]
    }, 
    "dbm": {
      "file": "dbm.py", 
      "imports": [
        "ctypes.CDLL", 
        "ctypes.POINTER", 
        "ctypes.Structure", 
        "ctypes.c_char", 
        "ctypes.c_char_p", 
        "ctypes.c_int", 
        "ctypes.c_void_p", 
        "ctypes.util", 
        "os", 
        "sys"
      ]
    }, 
    "decimal": {
      "file": "decimal.py", 
      "imports": [
        "collections", 
        "copy", 
        "itertools.chain", 
        "itertools.repeat", 
        "math", 
        "sys", 
        "threading", 
        "doctest", 
        "locale", 
        "numbers", 
        "re"
      ]
    }, 
    "difflib": {
      "file": "difflib.py", 
      "imports": [
        "collections", 
        "difflib", 
        "doctest", 
        "functools", 
        "heapq", 
        "re"
      ]
    }, 
    "dircache": {
      "file": "dircache.py", 
      "imports": [
        "os", 
        "warnings"
      ]
    }, 
    "dis": {
      "file": "dis.py", 
      "imports": [
        "sys", 
        "opcode", 
        "types"
      ]
    }, 
    "distutils": {
      "dir": "distutils"
    }, 
    "distutils.__init__": {
      "file": "distutils/__init__.py", 
      "imports": []
    }, 
    "distutils.archive_util": {
      "file": "distutils/archive_util.py", 
      "imports": [
        "distutils.dir_util", 
        "distutils.errors", 
        "distutils.log", 
        "distutils.spawn", 
        "sys", 
        "os", 
        "tarfile", 
        "warnings", 
        "zipfile", 
        "grp", 
        "pwd"
      ]
    }, 
    "distutils.bcppcompiler": {
      "file": "distutils/bcppcompiler.py", 
      "imports": [
        "distutils.ccompiler", 
        "distutils.dep_util", 
        "distutils.errors", 
        "distutils.file_util", 
        "distutils.log", 
        "os"
      ]
    }, 
    "distutils.ccompiler": {
      "file": "distutils/ccompiler.py", 
      "imports": [
        "distutils.debug", 
        "distutils.dep_util", 
        "distutils.dir_util", 
        "distutils.errors", 
        "distutils.fancy_getopt", 
        "distutils.file_util", 
        "distutils.log", 
        "distutils.spawn", 
        "distutils.sysconfig", 
        "distutils.util", 
        "sys", 
        "os", 
        "re", 
        "tempfile"
      ]
    }, 
    "distutils.cmd": {
      "file": "distutils/cmd.py", 
      "imports": [
        "distutils.archive_util", 
        "distutils.debug", 
        "distutils.dep_util", 
        "distutils.dir_util", 
        "distutils.dist", 
        "distutils.errors", 
        "distutils.fancy_getopt", 
        "distutils.file_util", 
        "distutils.log", 
        "distutils.spawn", 
        "distutils.util", 
        "sys", 
        "os", 
        "re"
      ]
    }, 
    "distutils.command": {
      "dir": "distutils/command"
    }, 
    "distutils.command.__init__": {
      "file": "distutils/command/__init__.py", 
      "imports": []
    }, 
    "distutils.command.bdist": {
      "file": "distutils/command/bdist.py", 
      "imports": [
        "distutils.core", 
        "distutils.errors", 
        "distutils.fancy_getopt", 
        "distutils.util", 
        "os"
      ]
    }, 
    "distutils.command.bdist_dumb": {
      "file": "distutils/command/bdist_dumb.py", 
      "imports": [
        "distutils.core", 
        "distutils.dir_util", 
        "distutils.errors", 
        "distutils.log", 
        "distutils.sysconfig", 
        "distutils.util", 
        "os"
      ]
    }, 
    "distutils.command.bdist_msi": {
      "file": "distutils/command/bdist_msi.py", 
      "imports": [
        "distutils.core", 
        "distutils.dir_util", 
        "distutils.errors", 
        "distutils.log", 
        "distutils.sysconfig", 
        "distutils.util", 
        "distutils.version", 
        "msilib", 
        "msilib.Dialog", 
        "msilib.Directory", 
        "msilib.Feature", 
        "msilib.add_data", 
        "msilib.schema", 
        "msilib.sequence", 
        "msilib.text", 
        "sys", 
        "os"
      ]
    }, 
    "distutils.command.bdist_rpm": {
      "file": "distutils/command/bdist_rpm.py", 
      "imports": [
        "distutils.core", 
        "distutils.debug", 
        "distutils.errors", 
        "distutils.file_util", 
        "distutils.log", 
        "distutils.sysconfig", 
        "sys", 
        "os", 
        "string"
      ]
    }, 
    "distutils.command.bdist_wininst": {
      "file": "distutils/command/bdist_wininst.py", 
      "imports": [
        "distutils", 
        "distutils.core", 
        "distutils.dir_util", 
        "distutils.errors", 
        "distutils.log", 
        "distutils.msvccompiler", 
        "distutils.sysconfig", 
        "distutils.util", 
        "sys", 
        "time", 
        "os", 
        "string", 
        "struct", 
        "tempfile"
      ]
    }, 
    "distutils.command.build": {
      "file": "distutils/command/build.py", 
      "imports": [
        "distutils.ccompiler", 
        "distutils.core", 
        "distutils.errors", 
        "distutils.util", 
        "sys", 
        "os"
      ]
    }, 
    "distutils.command.build_clib": {
      "file": "distutils/command/build_clib.py", 
      "imports": [
        "distutils.ccompiler", 
        "distutils.core", 
        "distutils.errors", 
        "distutils.log", 
        "distutils.sysconfig", 
        "os"
      ]
    }, 
    "distutils.command.build_ext": {
      "file": "distutils/command/build_ext.py", 
      "imports": [
        "distutils.ccompiler", 
        "distutils.core", 
        "distutils.dep_util", 
        "distutils.errors", 
        "distutils.extension", 
        "distutils.log", 
        "distutils.msvccompiler", 
        "distutils.sysconfig", 
        "distutils.util", 
        "imp", 
        "sys", 
        "os", 
        "re", 
        "site", 
        "string", 
        "types"
      ]
    }, 
    "distutils.command.build_py": {
      "file": "distutils/command/build_py.py", 
      "imports": [
        "distutils.core", 
        "distutils.errors", 
        "distutils.log", 
        "distutils.util", 
        "sys", 
        "glob", 
        "os"
      ]
    }, 
    "distutils.command.build_scripts": {
      "file": "distutils/command/build_scripts.py", 
      "imports": [
        "distutils.core", 
        "distutils.dep_util", 
        "distutils.log", 
        "distutils.util", 
        "os", 
        "re", 
        "stat"
      ]
    }, 
    "distutils.command.check": {
      "file": "distutils/command/check.py", 
      "imports": [
        "distutils.core", 
        "distutils.dist", 
        "distutils.errors", 
        "docutils.frontend", 
        "docutils.nodes", 
        "docutils.parsers.rst.Parser", 
        "docutils.utils.Reporter", 
        "StringIO"
      ]
    }, 
    "distutils.command.clean": {
      "file": "distutils/command/clean.py", 
      "imports": [
        "distutils.core", 
        "distutils.dir_util", 
        "distutils.log", 
        "os"
      ]
    }, 
    "distutils.command.config": {
      "file": "distutils/command/config.py", 
      "imports": [
        "distutils.ccompiler", 
        "distutils.core", 
        "distutils.errors", 
        "distutils.log", 
        "distutils.sysconfig", 
        "os", 
        "re"
      ]
    }, 
    "distutils.command.install": {
      "file": "distutils/command/install.py", 
      "imports": [
        "distutils.core", 
        "distutils.debug", 
        "distutils.errors", 
        "distutils.fancy_getopt", 
        "distutils.file_util", 
        "distutils.log", 
        "distutils.sysconfig", 
        "distutils.util", 
        "sys", 
        "os", 
        "pprint", 
        "site", 
        "string", 
        "types"
      ]
    }, 
    "distutils.command.install_data": {
      "file": "distutils/command/install_data.py", 
      "imports": [
        "distutils.core", 
        "distutils.util", 
        "os"
      ]
    }, 
    "distutils.command.install_egg_info": {
      "file": "distutils/command/install_egg_info.py", 
      "imports": [
        "distutils.cmd", 
        "distutils.dir_util", 
        "distutils.log", 
        "sys", 
        "os", 
        "re"
      ]
    }, 
    "distutils.command.install_headers": {
      "file": "distutils/command/install_headers.py", 
      "imports": [
        "distutils.core"
      ]
    }, 
    "distutils.command.install_lib": {
      "file": "distutils/command/install_lib.py", 
      "imports": [
        "distutils.core", 
        "distutils.errors", 
        "distutils.util", 
        "sys", 
        "os"
      ]
    }, 
    "distutils.command.install_scripts": {
      "file": "distutils/command/install_scripts.py", 
      "imports": [
        "distutils.core", 
        "distutils.log", 
        "os", 
        "stat"
      ]
    }, 
    "distutils.command.register": {
      "file": "distutils/command/register.py", 
      "imports": [
        "distutils.core", 
        "distutils.log", 
        "getpass", 
        "urllib2", 
        "urlparse", 
        "warnings"
      ]
    }, 
    "distutils.command.sdist": {
      "file": "distutils/command/sdist.py", 
      "imports": [
        "distutils.archive_util", 
        "distutils.core", 
        "distutils.dep_util", 
        "distutils.dir_util", 
        "distutils.errors", 
        "distutils.fancy_getopt", 
        "distutils.file_util", 
        "distutils.filelist", 
        "distutils.log", 
        "distutils.text_file", 
        "distutils.util", 
        "sys", 
        "glob", 
        "os", 
        "string", 
        "warnings"
      ]
    }, 
    "distutils.command.upload": {
      "file": "distutils/command/upload.py", 
      "imports": [
        "base64", 
        "cStringIO", 
        "distutils.core", 
        "distutils.errors", 
        "distutils.log", 
        "distutils.spawn", 
        "hashlib", 
        "os", 
        "platform", 
        "socket", 
        "urllib2", 
        "urlparse"
      ]
    }, 
    "distutils.config": {
      "file": "distutils/config.py", 
      "imports": [
        "ConfigParser", 
        "distutils.cmd", 
        "os"
      ]
    }, 
    "distutils.core": {
      "file": "distutils/core.py", 
      "imports": [
        "distutils.cmd", 
        "distutils.config", 
        "distutils.debug", 
        "distutils.dist", 
        "distutils.errors", 
        "distutils.extension", 
        "sys", 
        "os"
      ]
    }, 
    "distutils.cygwinccompiler": {
      "file": "distutils/cygwinccompiler.py", 
      "imports": [
        "copy", 
        "distutils.ccompiler", 
        "distutils.errors", 
        "distutils.file_util", 
        "distutils.log", 
        "distutils.spawn", 
        "distutils.sysconfig", 
        "distutils.unixccompiler", 
        "distutils.version", 
        "sys", 
        "os", 
        "re", 
        "string"
      ]
    }, 
    "distutils.debug": {
      "file": "distutils/debug.py", 
      "imports": [
        "os"
      ]
    }, 
    "distutils.dep_util": {
      "file": "distutils/dep_util.py", 
      "imports": [
        "distutils.errors", 
        "os", 
        "stat"
      ]
    }, 
    "distutils.dir_util": {
      "file": "distutils/dir_util.py", 
      "imports": [
        "distutils.errors", 
        "distutils.file_util", 
        "distutils.log", 
        "errno", 
        "os"
      ]
    }, 
    "distutils.dist": {
      "file": "distutils/dist.py", 
      "imports": [
        "ConfigParser", 
        "distutils.cmd", 
        "distutils.command", 
        "distutils.core", 
        "distutils.debug", 
        "distutils.errors", 
        "distutils.fancy_getopt", 
        "distutils.log", 
        "distutils.util", 
        "distutils.versionpredicate", 
        "sys", 
        "email", 
        "os", 
        "pprint", 
        "re", 
        "warnings"
      ]
    }, 
    "distutils.emxccompiler": {
      "file": "distutils/emxccompiler.py", 
      "imports": [
        "copy", 
        "distutils.ccompiler", 
        "distutils.errors", 
        "distutils.file_util", 
        "distutils.log", 
        "distutils.spawn", 
        "distutils.sysconfig", 
        "distutils.unixccompiler", 
        "distutils.version", 
        "sys", 
        "os", 
        "re", 
        "string"
      ]
    }, 
    "distutils.errors": {
      "file": "distutils/errors.py", 
      "imports": []
    }, 
    "distutils.extension": {
      "file": "distutils/extension.py", 
      "imports": [
        "distutils.sysconfig", 
        "distutils.text_file", 
        "distutils.util", 
        "sys", 
        "os", 
        "string", 
        "types", 
        "warnings"
      ]
    }, 
    "distutils.fancy_getopt": {
      "file": "distutils/fancy_getopt.py", 
      "imports": [
        "distutils.errors", 
        "sys", 
        "getopt", 
        "re", 
        "string"
      ]
    }, 
    "distutils.file_util": {
      "file": "distutils/file_util.py", 
      "imports": [
        "distutils.dep_util", 
        "distutils.errors", 
        "distutils.log", 
        "errno", 
        "os", 
        "stat"
      ]
    }, 
    "distutils.filelist": {
      "file": "distutils/filelist.py", 
      "imports": [
        "distutils.debug", 
        "distutils.errors", 
        "distutils.log", 
        "distutils.util", 
        "fnmatch", 
        "os", 
        "re", 
        "stat"
      ]
    }, 
    "distutils.log": {
      "file": "distutils/log.py", 
      "imports": [
        "sys"
      ]
    }, 
    "distutils.msvc9compiler": {
      "file": "distutils/msvc9compiler.py", 
      "imports": [
        "_winreg", 
        "distutils.ccompiler", 
        "distutils.errors", 
        "distutils.log", 
        "distutils.util", 
        "subprocess", 
        "sys", 
        "os", 
        "re"
      ]
    }, 
    "distutils.msvccompiler": {
      "file": "distutils/msvccompiler.py", 
      "imports": [
        "_winreg", 
        "distutils.ccompiler", 
        "distutils.errors", 
        "distutils.log", 
        "distutils.msvc9compiler", 
        "sys", 
        "win32api", 
        "win32con", 
        "os", 
        "string"
      ]
    }, 
    "distutils.spawn": {
      "file": "distutils/spawn.py", 
      "imports": [
        "distutils.debug", 
        "distutils.errors", 
        "distutils.log", 
        "distutils.sysconfig", 
        "errno", 
        "subprocess", 
        "sys", 
        "os"
      ]
    }, 
    "distutils.sysconfig": {
      "file": "distutils/sysconfig.py", 
      "imports": [
        "distutils.sysconfig_cpython", 
        "distutils.sysconfig_pypy", 
        "sys"
      ]
    }, 
    "distutils.sysconfig_cpython": {
      "file": "distutils/sysconfig_cpython.py", 
      "imports": [
        "_osx_support", 
        "_sysconfigdata.build_time_vars", 
        "distutils.errors", 
        "distutils.text_file", 
        "sys", 
        "os", 
        "re", 
        "string"
      ]
    }, 
    "distutils.sysconfig_pypy": {
      "file": "distutils/sysconfig_pypy.py", 
      "imports": [
        "distutils.errors", 
        "distutils.sysconfig_cpython", 
        "sys", 
        "os", 
        "shlex"
      ]
    }, 
    "distutils.tests": {
      "dir": "distutils/tests"
    }, 
    "distutils.tests.__init__": {
      "file": "distutils/tests/__init__.py", 
      "imports": [
        "sys", 
        "os", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "distutils.tests.setuptools_build_ext": {
      "file": "distutils/tests/setuptools_build_ext.py", 
      "imports": [
        "Pyrex.Distutils.build_ext.build_ext", 
        "distutils.ccompiler", 
        "distutils.command.build_ext", 
        "distutils.errors", 
        "distutils.file_util", 
        "distutils.log", 
        "distutils.sysconfig", 
        "distutils.tests.setuptools_extension", 
        "distutils.util", 
        "dl.RTLD_NOW", 
        "sys", 
        "os"
      ]
    }, 
    "distutils.tests.setuptools_extension": {
      "file": "distutils/tests/setuptools_extension.py", 
      "imports": [
        "Pyrex.Distutils.build_ext.build_ext", 
        "distutils.core", 
        "distutils.extension", 
        "sys"
      ]
    }, 
    "distutils.tests.support": {
      "file": "distutils/tests/support.py", 
      "imports": [
        "copy", 
        "distutils.core", 
        "distutils.log", 
        "distutils.sysconfig", 
        "sys", 
        "os", 
        "shutil", 
        "tempfile", 
        "unittest", 
        "warnings"
      ]
    }, 
    "distutils.tests.test_archive_util": {
      "file": "distutils/tests/test_archive_util.py", 
      "imports": [
        "distutils.archive_util", 
        "distutils.spawn", 
        "distutils.tests.support", 
        "sys", 
        "zlib", 
        "os", 
        "tarfile", 
        "test.test_support", 
        "unittest", 
        "warnings", 
        "zipfile", 
        "grp", 
        "pwd"
      ]
    }, 
    "distutils.tests.test_bdist": {
      "file": "distutils/tests/test_bdist.py", 
      "imports": [
        "distutils.command.bdist", 
        "distutils.tests.support", 
        "os", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_bdist_dumb": {
      "file": "distutils/tests/test_bdist_dumb.py", 
      "imports": [
        "distutils.command.bdist_dumb", 
        "distutils.core", 
        "distutils.tests.support", 
        "sys", 
        "zlib", 
        "os", 
        "test.test_support", 
        "unittest", 
        "zipfile"
      ]
    }, 
    "distutils.tests.test_bdist_msi": {
      "file": "distutils/tests/test_bdist_msi.py", 
      "imports": [
        "distutils.command.bdist_msi", 
        "distutils.tests.support", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_bdist_rpm": {
      "file": "distutils/tests/test_bdist_rpm.py", 
      "imports": [
        "distutils.command.bdist_rpm", 
        "distutils.core", 
        "distutils.errors", 
        "distutils.spawn", 
        "distutils.tests.support", 
        "sys", 
        "os", 
        "shutil", 
        "tempfile", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_bdist_wininst": {
      "file": "distutils/tests/test_bdist_wininst.py", 
      "imports": [
        "distutils.command.bdist_wininst", 
        "distutils.tests.support", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_build": {
      "file": "distutils/tests/test_build.py", 
      "imports": [
        "distutils.command.build", 
        "distutils.sysconfig", 
        "distutils.tests.support", 
        "sys", 
        "os", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_build_clib": {
      "file": "distutils/tests/test_build_clib.py", 
      "imports": [
        "distutils.ccompiler", 
        "distutils.command.build_clib", 
        "distutils.errors", 
        "distutils.spawn", 
        "distutils.sysconfig", 
        "distutils.tests.support", 
        "sys", 
        "os", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_build_ext": {
      "file": "distutils/tests/test_build_ext.py", 
      "imports": [
        "distutils.command.build_ext", 
        "distutils.core", 
        "distutils.errors", 
        "distutils.extension", 
        "distutils.sysconfig", 
        "distutils.tests.setuptools_build_ext", 
        "distutils.tests.setuptools_extension", 
        "distutils.tests.support", 
        "sys", 
        "xx", 
        "os", 
        "site", 
        "StringIO", 
        "test.test_support", 
        "textwrap", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_build_py": {
      "file": "distutils/tests/test_build_py.py", 
      "imports": [
        "distutils.command.build_py", 
        "distutils.core", 
        "distutils.errors", 
        "distutils.tests.support", 
        "sys", 
        "os", 
        "StringIO", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_build_scripts": {
      "file": "distutils/tests/test_build_scripts.py", 
      "imports": [
        "distutils.command.build_scripts", 
        "distutils.core", 
        "distutils.sysconfig", 
        "distutils.tests.support", 
        "sys", 
        "os", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_ccompiler": {
      "file": "distutils/tests/test_ccompiler.py", 
      "imports": [
        "distutils.ccompiler", 
        "distutils.debug", 
        "distutils.sysconfig", 
        "distutils.tests.support", 
        "os", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_check": {
      "file": "distutils/tests/test_check.py", 
      "imports": [
        "distutils.command.check", 
        "distutils.errors", 
        "distutils.tests.support", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_clean": {
      "file": "distutils/tests/test_clean.py", 
      "imports": [
        "distutils.command.clean", 
        "distutils.tests.support", 
        "sys", 
        "getpass", 
        "os", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_cmd": {
      "file": "distutils/tests/test_cmd.py", 
      "imports": [
        "distutils.cmd", 
        "distutils.debug", 
        "distutils.dist", 
        "distutils.errors", 
        "os", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_config": {
      "file": "distutils/tests/test_config.py", 
      "imports": [
        "distutils.core", 
        "distutils.log", 
        "distutils.tests.support", 
        "sys", 
        "os", 
        "shutil", 
        "tempfile", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_config_cmd": {
      "file": "distutils/tests/test_config_cmd.py", 
      "imports": [
        "distutils.command.config", 
        "distutils.log", 
        "distutils.tests.support", 
        "sys", 
        "os", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_core": {
      "file": "distutils/tests/test_core.py", 
      "imports": [
        "distutils.core", 
        "distutils.tests.support", 
        "sys", 
        "os", 
        "shutil", 
        "StringIO", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_dep_util": {
      "file": "distutils/tests/test_dep_util.py", 
      "imports": [
        "distutils.dep_util", 
        "distutils.errors", 
        "distutils.tests.support", 
        "time", 
        "os", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_dir_util": {
      "file": "distutils/tests/test_dir_util.py", 
      "imports": [
        "distutils.dir_util", 
        "distutils.log", 
        "distutils.tests.support", 
        "sys", 
        "os", 
        "shutil", 
        "stat", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_dist": {
      "file": "distutils/tests/test_dist.py", 
      "imports": [
        "distutils.cmd", 
        "distutils.dist", 
        "distutils.tests.support", 
        "distutils.tests.test_dist", 
        "sys", 
        "os", 
        "StringIO", 
        "test.test_support", 
        "textwrap", 
        "unittest", 
        "warnings"
      ]
    }, 
    "distutils.tests.test_file_util": {
      "file": "distutils/tests/test_file_util.py", 
      "imports": [
        "distutils.file_util", 
        "distutils.log", 
        "distutils.tests.support", 
        "os", 
        "shutil", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_filelist": {
      "file": "distutils/tests/test_filelist.py", 
      "imports": [
        "distutils.debug", 
        "distutils.errors", 
        "distutils.filelist", 
        "distutils.log", 
        "distutils.tests.support", 
        "os", 
        "re", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_install": {
      "file": "distutils/tests/test_install.py", 
      "imports": [
        "distutils.command.build_ext", 
        "distutils.command.install", 
        "distutils.core", 
        "distutils.errors", 
        "distutils.extension", 
        "distutils.sysconfig", 
        "distutils.tests.support", 
        "sys", 
        "os", 
        "site", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_install_data": {
      "file": "distutils/tests/test_install_data.py", 
      "imports": [
        "distutils.command.install_data", 
        "distutils.tests.support", 
        "sys", 
        "getpass", 
        "os", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_install_headers": {
      "file": "distutils/tests/test_install_headers.py", 
      "imports": [
        "distutils.command.install_headers", 
        "distutils.tests.support", 
        "sys", 
        "getpass", 
        "os", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_install_lib": {
      "file": "distutils/tests/test_install_lib.py", 
      "imports": [
        "distutils.command.install_lib", 
        "distutils.errors", 
        "distutils.extension", 
        "distutils.tests.support", 
        "sys", 
        "os", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_install_scripts": {
      "file": "distutils/tests/test_install_scripts.py", 
      "imports": [
        "distutils.command.install_scripts", 
        "distutils.core", 
        "distutils.tests.support", 
        "os", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_msvc9compiler": {
      "file": "distutils/tests/test_msvc9compiler.py", 
      "imports": [
        "_winreg", 
        "distutils.errors", 
        "distutils.msvc9compiler", 
        "distutils.msvccompiler", 
        "distutils.tests.support", 
        "sys", 
        "os", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_register": {
      "file": "distutils/tests/test_register.py", 
      "imports": [
        "distutils.command.register", 
        "distutils.errors", 
        "distutils.tests.test_config", 
        "docutils", 
        "getpass", 
        "os", 
        "test.test_support", 
        "unittest", 
        "urllib2", 
        "warnings"
      ]
    }, 
    "distutils.tests.test_sdist": {
      "file": "distutils/tests/test_sdist.py", 
      "imports": [
        "distutils.archive_util", 
        "distutils.command.sdist", 
        "distutils.core", 
        "distutils.errors", 
        "distutils.filelist", 
        "distutils.log", 
        "distutils.spawn", 
        "distutils.tests.test_config", 
        "zlib", 
        "os", 
        "tarfile", 
        "test.test_support", 
        "textwrap", 
        "unittest", 
        "warnings", 
        "zipfile", 
        "grp", 
        "pwd"
      ]
    }, 
    "distutils.tests.test_spawn": {
      "file": "distutils/tests/test_spawn.py", 
      "imports": [
        "distutils.errors", 
        "distutils.spawn", 
        "distutils.tests.support", 
        "time", 
        "os", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_sysconfig": {
      "file": "distutils/tests/test_sysconfig.py", 
      "imports": [
        "distutils.sysconfig", 
        "distutils.tests.support", 
        "os", 
        "shutil", 
        "test.test_support", 
        "test", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_text_file": {
      "file": "distutils/tests/test_text_file.py", 
      "imports": [
        "distutils.tests.support", 
        "distutils.text_file", 
        "os", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_unixccompiler": {
      "file": "distutils/tests/test_unixccompiler.py", 
      "imports": [
        "distutils.sysconfig", 
        "distutils.unixccompiler", 
        "sys", 
        "os", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_upload": {
      "file": "distutils/tests/test_upload.py", 
      "imports": [
        "distutils.command.upload", 
        "distutils.core", 
        "distutils.errors", 
        "distutils.tests.test_config", 
        "os", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_util": {
      "file": "distutils/tests/test_util.py", 
      "imports": [
        "distutils.errors", 
        "distutils.util", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_version": {
      "file": "distutils/tests/test_version.py", 
      "imports": [
        "distutils.version", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "distutils.tests.test_versionpredicate": {
      "file": "distutils/tests/test_versionpredicate.py", 
      "imports": [
        "distutils.versionpredicate", 
        "doctest", 
        "test.test_support"
      ]
    }, 
    "distutils.text_file": {
      "file": "distutils/text_file.py", 
      "imports": [
        "sys"
      ]
    }, 
    "distutils.unixccompiler": {
      "file": "distutils/unixccompiler.py", 
      "imports": [
        "_osx_support", 
        "distutils.ccompiler", 
        "distutils.dep_util", 
        "distutils.errors", 
        "distutils.log", 
        "distutils.sysconfig", 
        "sys", 
        "os", 
        "platform", 
        "re", 
        "types"
      ]
    }, 
    "distutils.util": {
      "file": "distutils/util.py", 
      "imports": [
        "_osx_support", 
        "distutils.dep_util", 
        "distutils.errors", 
        "distutils.log", 
        "distutils.spawn", 
        "distutils.sysconfig", 
        "sys", 
        "os", 
        "py_compile", 
        "re", 
        "string", 
        "tempfile", 
        "pwd"
      ]
    }, 
    "distutils.version": {
      "file": "distutils/version.py", 
      "imports": [
        "re", 
        "string", 
        "types"
      ]
    }, 
    "distutils.versionpredicate": {
      "file": "distutils/versionpredicate.py", 
      "imports": [
        "distutils.version", 
        "operator", 
        "re"
      ]
    }, 
    "doctest": {
      "file": "doctest.py", 
      "imports": [
        "__future__", 
        "collections", 
        "difflib", 
        "sys", 
        "inspect", 
        "linecache", 
        "os", 
        "pdb", 
        "re", 
        "StringIO", 
        "tempfile", 
        "traceback", 
        "types", 
        "unittest", 
        "warnings"
      ]
    }, 
    "dumbdbm": {
      "file": "dumbdbm.py", 
      "imports": [
        "__builtin__", 
        "os", 
        "UserDict"
      ]
    }, 
    "dummy_thread": {
      "file": "dummy_thread.py", 
      "imports": [
        "traceback"
      ]
    }, 
    "dummy_threading": {
      "file": "dummy_threading.py", 
      "imports": [
        "_dummy_threading.*", 
        "_dummy_threading.__all__", 
        "dummy_thread", 
        "sys.modules", 
        "threading"
      ]
    }, 
    "email": {
      "dir": "email"
    }, 
    "email.__init__": {
      "file": "email/__init__.py", 
      "imports": [
        "email.mime", 
        "email.parser", 
        "sys"
      ]
    }, 
    "email._parseaddr": {
      "file": "email/_parseaddr.py", 
      "imports": [
        "calendar", 
        "time"
      ]
    }, 
    "email.base64mime": {
      "file": "email/base64mime.py", 
      "imports": [
        "binascii.a2b_base64", 
        "binascii.b2a_base64", 
        "email.utils"
      ]
    }, 
    "email.charset": {
      "file": "email/charset.py", 
      "imports": [
        "codecs", 
        "email.base64mime", 
        "email.encoders", 
        "email.errors", 
        "email.quoprimime"
      ]
    }, 
    "email.encoders": {
      "file": "email/encoders.py", 
      "imports": [
        "base64", 
        "quopri"
      ]
    }, 
    "email.errors": {
      "file": "email/errors.py", 
      "imports": []
    }, 
    "email.feedparser": {
      "file": "email/feedparser.py", 
      "imports": [
        "email.errors", 
        "email.message", 
        "re"
      ]
    }, 
    "email.generator": {
      "file": "email/generator.py", 
      "imports": [
        "cStringIO.StringIO", 
        "email.header", 
        "sys", 
        "time", 
        "random", 
        "re", 
        "warnings"
      ]
    }, 
    "email.header": {
      "file": "email/header.py", 
      "imports": [
        "binascii", 
        "email.base64mime", 
        "email.charset", 
        "email.errors", 
        "email.quoprimime", 
        "re"
      ]
    }, 
    "email.iterators": {
      "file": "email/iterators.py", 
      "imports": [
        "cStringIO.StringIO", 
        "sys"
      ]
    }, 
    "email.message": {
      "file": "email/message.py", 
      "imports": [
        "binascii", 
        "cStringIO.StringIO", 
        "email.charset", 
        "email.errors", 
        "email.generator", 
        "email.iterators", 
        "email.utils", 
        "re", 
        "uu", 
        "warnings"
      ]
    }, 
    "email.mime": {
      "dir": "email/mime"
    }, 
    "email.mime.__init__": {
      "file": "email/mime/__init__.py", 
      "imports": []
    }, 
    "email.mime.application": {
      "file": "email/mime/application.py", 
      "imports": [
        "email.encoders", 
        "email.mime.nonmultipart"
      ]
    }, 
    "email.mime.audio": {
      "file": "email/mime/audio.py", 
      "imports": [
        "cStringIO.StringIO", 
        "email.encoders", 
        "email.mime.nonmultipart", 
        "sndhdr"
      ]
    }, 
    "email.mime.base": {
      "file": "email/mime/base.py", 
      "imports": [
        "email.message"
      ]
    }, 
    "email.mime.image": {
      "file": "email/mime/image.py", 
      "imports": [
        "email.encoders", 
        "email.mime.nonmultipart", 
        "imghdr"
      ]
    }, 
    "email.mime.message": {
      "file": "email/mime/message.py", 
      "imports": [
        "email.message", 
        "email.mime.nonmultipart"
      ]
    }, 
    "email.mime.multipart": {
      "file": "email/mime/multipart.py", 
      "imports": [
        "email.mime.base"
      ]
    }, 
    "email.mime.nonmultipart": {
      "file": "email/mime/nonmultipart.py", 
      "imports": [
        "email.errors", 
        "email.mime.base"
      ]
    }, 
    "email.mime.text": {
      "file": "email/mime/text.py", 
      "imports": [
        "email.encoders", 
        "email.mime.nonmultipart"
      ]
    }, 
    "email.parser": {
      "file": "email/parser.py", 
      "imports": [
        "cStringIO.StringIO", 
        "email.feedparser", 
        "email.message", 
        "warnings"
      ]
    }, 
    "email.quoprimime": {
      "file": "email/quoprimime.py", 
      "imports": [
        "email.utils", 
        "re", 
        "string"
      ]
    }, 
    "email.test": {
      "dir": "email/test"
    }, 
    "email.test.__init__": {
      "file": "email/test/__init__.py", 
      "imports": []
    }, 
    "email.test.test_email": {
      "file": "email/test/test_email.py", 
      "imports": [
        "base64", 
        "cStringIO.StringIO", 
        "difflib", 
        "email", 
        "email.feedparser", 
        "email.test", 
        "sys", 
        "time", 
        "os", 
        "re", 
        "test.test_support", 
        "textwrap", 
        "unittest", 
        "warnings"
      ]
    }, 
    "email.test.test_email_codecs": {
      "file": "email/test/test_email_codecs.py", 
      "imports": [
        "email.charset", 
        "email.header", 
        "email.message", 
        "email.test.test_email", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "email.test.test_email_codecs_renamed": {
      "file": "email/test/test_email_codecs_renamed.py", 
      "imports": [
        "email.charset", 
        "email.header", 
        "email.message", 
        "email.test.test_email", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "email.test.test_email_renamed": {
      "file": "email/test/test_email_renamed.py", 
      "imports": [
        "base64", 
        "cStringIO.StringIO", 
        "difflib", 
        "email", 
        "email.base64mime", 
        "email.charset", 
        "email.encoders", 
        "email.errors", 
        "email.generator", 
        "email.header", 
        "email.iterators", 
        "email.message", 
        "email.mime.application", 
        "email.mime.audio", 
        "email.mime.base", 
        "email.mime.image", 
        "email.mime.message", 
        "email.mime.multipart", 
        "email.mime.text", 
        "email.parser", 
        "email.quoprimime", 
        "email.test", 
        "email.utils", 
        "sys", 
        "time", 
        "os", 
        "test.test_support", 
        "unittest", 
        "warnings"
      ]
    }, 
    "email.test.test_email_torture": {
      "file": "email/test/test_email_torture.py", 
      "imports": [
        "cStringIO.StringIO", 
        "email", 
        "email.iterators", 
        "email.test.test_email", 
        "sys", 
        "os", 
        "test.test_support", 
        "types", 
        "unittest"
      ]
    }, 
    "email.utils": {
      "file": "email/utils.py", 
      "imports": [
        "base64", 
        "email._parseaddr", 
        "email.encoders", 
        "time", 
        "os", 
        "quopri", 
        "random", 
        "re", 
        "socket", 
        "urllib", 
        "warnings"
      ]
    }, 
    "encodings": {
      "dir": "encodings"
    }, 
    "encodings.__init__": {
      "file": "encodings/__init__.py", 
      "imports": [
        "__builtin__", 
        "codecs", 
        "encodings.aliases"
      ]
    }, 
    "encodings.aliases": {
      "file": "encodings/aliases.py", 
      "imports": []
    }, 
    "encodings.ascii": {
      "file": "encodings/ascii.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.base64_codec": {
      "file": "encodings/base64_codec.py", 
      "imports": [
        "base64", 
        "codecs"
      ]
    }, 
    "encodings.big5": {
      "file": "encodings/big5.py", 
      "imports": [
        "_multibytecodec", 
        "codecs", 
        "_codecs_tw"
      ]
    }, 
    "encodings.big5hkscs": {
      "file": "encodings/big5hkscs.py", 
      "imports": [
        "_multibytecodec", 
        "codecs", 
        "_codecs_hk"
      ]
    }, 
    "encodings.bz2_codec": {
      "file": "encodings/bz2_codec.py", 
      "imports": [
        "bz2", 
        "codecs"
      ]
    }, 
    "encodings.charmap": {
      "file": "encodings/charmap.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp037": {
      "file": "encodings/cp037.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp1006": {
      "file": "encodings/cp1006.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp1026": {
      "file": "encodings/cp1026.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp1140": {
      "file": "encodings/cp1140.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp1250": {
      "file": "encodings/cp1250.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp1251": {
      "file": "encodings/cp1251.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp1252": {
      "file": "encodings/cp1252.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp1253": {
      "file": "encodings/cp1253.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp1254": {
      "file": "encodings/cp1254.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp1255": {
      "file": "encodings/cp1255.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp1256": {
      "file": "encodings/cp1256.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp1257": {
      "file": "encodings/cp1257.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp1258": {
      "file": "encodings/cp1258.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp424": {
      "file": "encodings/cp424.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp437": {
      "file": "encodings/cp437.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp500": {
      "file": "encodings/cp500.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp720": {
      "file": "encodings/cp720.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp737": {
      "file": "encodings/cp737.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp775": {
      "file": "encodings/cp775.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp850": {
      "file": "encodings/cp850.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp852": {
      "file": "encodings/cp852.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp855": {
      "file": "encodings/cp855.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp856": {
      "file": "encodings/cp856.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp857": {
      "file": "encodings/cp857.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp858": {
      "file": "encodings/cp858.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp860": {
      "file": "encodings/cp860.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp861": {
      "file": "encodings/cp861.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp862": {
      "file": "encodings/cp862.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp863": {
      "file": "encodings/cp863.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp864": {
      "file": "encodings/cp864.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp865": {
      "file": "encodings/cp865.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp866": {
      "file": "encodings/cp866.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp869": {
      "file": "encodings/cp869.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp874": {
      "file": "encodings/cp874.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp875": {
      "file": "encodings/cp875.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.cp932": {
      "file": "encodings/cp932.py", 
      "imports": [
        "_multibytecodec", 
        "codecs", 
        "_codecs_jp"
      ]
    }, 
    "encodings.cp949": {
      "file": "encodings/cp949.py", 
      "imports": [
        "_multibytecodec", 
        "codecs", 
        "_codecs_kr"
      ]
    }, 
    "encodings.cp950": {
      "file": "encodings/cp950.py", 
      "imports": [
        "_multibytecodec", 
        "codecs", 
        "_codecs_tw"
      ]
    }, 
    "encodings.euc_jis_2004": {
      "file": "encodings/euc_jis_2004.py", 
      "imports": [
        "_multibytecodec", 
        "codecs", 
        "_codecs_jp"
      ]
    }, 
    "encodings.euc_jisx0213": {
      "file": "encodings/euc_jisx0213.py", 
      "imports": [
        "_multibytecodec", 
        "codecs", 
        "_codecs_jp"
      ]
    }, 
    "encodings.euc_jp": {
      "file": "encodings/euc_jp.py", 
      "imports": [
        "_multibytecodec", 
        "codecs", 
        "_codecs_jp"
      ]
    }, 
    "encodings.euc_kr": {
      "file": "encodings/euc_kr.py", 
      "imports": [
        "_multibytecodec", 
        "codecs", 
        "_codecs_kr"
      ]
    }, 
    "encodings.gb18030": {
      "file": "encodings/gb18030.py", 
      "imports": [
        "_multibytecodec", 
        "codecs", 
        "_codecs_cn"
      ]
    }, 
    "encodings.gb2312": {
      "file": "encodings/gb2312.py", 
      "imports": [
        "_multibytecodec", 
        "codecs", 
        "_codecs_cn"
      ]
    }, 
    "encodings.gbk": {
      "file": "encodings/gbk.py", 
      "imports": [
        "_multibytecodec", 
        "codecs", 
        "_codecs_cn"
      ]
    }, 
    "encodings.hex_codec": {
      "file": "encodings/hex_codec.py", 
      "imports": [
        "binascii", 
        "codecs"
      ]
    }, 
    "encodings.hp_roman8": {
      "file": "encodings/hp_roman8.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.hz": {
      "file": "encodings/hz.py", 
      "imports": [
        "_multibytecodec", 
        "codecs", 
        "_codecs_cn"
      ]
    }, 
    "encodings.idna": {
      "file": "encodings/idna.py", 
      "imports": [
        "codecs", 
        "unicodedata.ucd_3_2_0", 
        "re", 
        "stringprep"
      ]
    }, 
    "encodings.iso2022_jp": {
      "file": "encodings/iso2022_jp.py", 
      "imports": [
        "_multibytecodec", 
        "codecs", 
        "_codecs_iso2022"
      ]
    }, 
    "encodings.iso2022_jp_1": {
      "file": "encodings/iso2022_jp_1.py", 
      "imports": [
        "_multibytecodec", 
        "codecs", 
        "_codecs_iso2022"
      ]
    }, 
    "encodings.iso2022_jp_2": {
      "file": "encodings/iso2022_jp_2.py", 
      "imports": [
        "_multibytecodec", 
        "codecs", 
        "_codecs_iso2022"
      ]
    }, 
    "encodings.iso2022_jp_2004": {
      "file": "encodings/iso2022_jp_2004.py", 
      "imports": [
        "_multibytecodec", 
        "codecs", 
        "_codecs_iso2022"
      ]
    }, 
    "encodings.iso2022_jp_3": {
      "file": "encodings/iso2022_jp_3.py", 
      "imports": [
        "_multibytecodec", 
        "codecs", 
        "_codecs_iso2022"
      ]
    }, 
    "encodings.iso2022_jp_ext": {
      "file": "encodings/iso2022_jp_ext.py", 
      "imports": [
        "_multibytecodec", 
        "codecs", 
        "_codecs_iso2022"
      ]
    }, 
    "encodings.iso2022_kr": {
      "file": "encodings/iso2022_kr.py", 
      "imports": [
        "_multibytecodec", 
        "codecs", 
        "_codecs_iso2022"
      ]
    }, 
    "encodings.iso8859_1": {
      "file": "encodings/iso8859_1.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.iso8859_10": {
      "file": "encodings/iso8859_10.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.iso8859_11": {
      "file": "encodings/iso8859_11.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.iso8859_13": {
      "file": "encodings/iso8859_13.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.iso8859_14": {
      "file": "encodings/iso8859_14.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.iso8859_15": {
      "file": "encodings/iso8859_15.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.iso8859_16": {
      "file": "encodings/iso8859_16.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.iso8859_2": {
      "file": "encodings/iso8859_2.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.iso8859_3": {
      "file": "encodings/iso8859_3.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.iso8859_4": {
      "file": "encodings/iso8859_4.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.iso8859_5": {
      "file": "encodings/iso8859_5.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.iso8859_6": {
      "file": "encodings/iso8859_6.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.iso8859_7": {
      "file": "encodings/iso8859_7.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.iso8859_8": {
      "file": "encodings/iso8859_8.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.iso8859_9": {
      "file": "encodings/iso8859_9.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.johab": {
      "file": "encodings/johab.py", 
      "imports": [
        "_multibytecodec", 
        "codecs", 
        "_codecs_kr"
      ]
    }, 
    "encodings.koi8_r": {
      "file": "encodings/koi8_r.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.koi8_u": {
      "file": "encodings/koi8_u.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.latin_1": {
      "file": "encodings/latin_1.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.mac_arabic": {
      "file": "encodings/mac_arabic.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.mac_centeuro": {
      "file": "encodings/mac_centeuro.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.mac_croatian": {
      "file": "encodings/mac_croatian.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.mac_cyrillic": {
      "file": "encodings/mac_cyrillic.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.mac_farsi": {
      "file": "encodings/mac_farsi.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.mac_greek": {
      "file": "encodings/mac_greek.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.mac_iceland": {
      "file": "encodings/mac_iceland.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.mac_latin2": {
      "file": "encodings/mac_latin2.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.mac_roman": {
      "file": "encodings/mac_roman.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.mac_romanian": {
      "file": "encodings/mac_romanian.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.mac_turkish": {
      "file": "encodings/mac_turkish.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.mbcs": {
      "file": "encodings/mbcs.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.palmos": {
      "file": "encodings/palmos.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.ptcp154": {
      "file": "encodings/ptcp154.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.punycode": {
      "file": "encodings/punycode.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.quopri_codec": {
      "file": "encodings/quopri_codec.py", 
      "imports": [
        "cStringIO.StringIO", 
        "codecs", 
        "quopri", 
        "StringIO"
      ]
    }, 
    "encodings.raw_unicode_escape": {
      "file": "encodings/raw_unicode_escape.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.rot_13": {
      "file": "encodings/rot_13.py", 
      "imports": [
        "codecs", 
        "sys"
      ]
    }, 
    "encodings.shift_jis": {
      "file": "encodings/shift_jis.py", 
      "imports": [
        "_multibytecodec", 
        "codecs", 
        "_codecs_jp"
      ]
    }, 
    "encodings.shift_jis_2004": {
      "file": "encodings/shift_jis_2004.py", 
      "imports": [
        "_multibytecodec", 
        "codecs", 
        "_codecs_jp"
      ]
    }, 
    "encodings.shift_jisx0213": {
      "file": "encodings/shift_jisx0213.py", 
      "imports": [
        "_multibytecodec", 
        "codecs", 
        "_codecs_jp"
      ]
    }, 
    "encodings.string_escape": {
      "file": "encodings/string_escape.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.tis_620": {
      "file": "encodings/tis_620.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.undefined": {
      "file": "encodings/undefined.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.unicode_escape": {
      "file": "encodings/unicode_escape.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.unicode_internal": {
      "file": "encodings/unicode_internal.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.utf_16": {
      "file": "encodings/utf_16.py", 
      "imports": [
        "codecs", 
        "sys"
      ]
    }, 
    "encodings.utf_16_be": {
      "file": "encodings/utf_16_be.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.utf_16_le": {
      "file": "encodings/utf_16_le.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.utf_32": {
      "file": "encodings/utf_32.py", 
      "imports": [
        "codecs", 
        "sys"
      ]
    }, 
    "encodings.utf_32_be": {
      "file": "encodings/utf_32_be.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.utf_32_le": {
      "file": "encodings/utf_32_le.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.utf_7": {
      "file": "encodings/utf_7.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.utf_8": {
      "file": "encodings/utf_8.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.utf_8_sig": {
      "file": "encodings/utf_8_sig.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "encodings.uu_codec": {
      "file": "encodings/uu_codec.py", 
      "imports": [
        "binascii", 
        "binascii.a2b_uu", 
        "binascii.b2a_uu", 
        "cStringIO.StringIO", 
        "codecs"
      ]
    }, 
    "encodings.zlib_codec": {
      "file": "encodings/zlib_codec.py", 
      "imports": [
        "codecs", 
        "zlib"
      ]
    }, 
    "filecmp": {
      "file": "filecmp.py", 
      "imports": [
        "itertools.ifilter", 
        "itertools.ifilterfalse", 
        "itertools.imap", 
        "itertools.izip", 
        "sys", 
        "getopt", 
        "os", 
        "stat"
      ]
    }, 
    "fileinput": {
      "file": "fileinput.py", 
      "imports": [
        "bz2", 
        "sys", 
        "getopt", 
        "gzip", 
        "io", 
        "os"
      ]
    }, 
    "fnmatch": {
      "file": "fnmatch.py", 
      "imports": [
        "os", 
        "posixpath", 
        "re"
      ]
    }, 
    "formatter": {
      "file": "formatter.py", 
      "imports": [
        "sys"
      ]
    }, 
    "fpformat": {
      "file": "fpformat.py", 
      "imports": [
        "re", 
        "warnings"
      ]
    }, 
    "fractions": {
      "file": "fractions.py", 
      "imports": [
        "__future__", 
        "decimal", 
        "math", 
        "operator", 
        "numbers", 
        "re"
      ]
    }, 
    "ftplib": {
      "file": "ftplib.py", 
      "imports": [
        "SOCKS", 
        "ssl", 
        "sys", 
        "os", 
        "re", 
        "socket"
      ]
    }, 
    "functools": {
      "file": "functools.py", 
      "imports": [
        "_functools"
      ]
    }, 
    "future_builtins": {
      "file": "future_builtins.py", 
      "imports": [
        "itertools.ifilter", 
        "itertools.imap", 
        "itertools.izip"
      ]
    }, 
    "gdbm": {
      "file": "gdbm.py", 
      "imports": [
        "cffi", 
        "os"
      ]
    }, 
    "genericpath": {
      "file": "genericpath.py", 
      "imports": [
        "os", 
        "stat"
      ]
    }, 
    "getopt": {
      "file": "getopt.py", 
      "imports": [
        "sys", 
        "os"
      ]
    }, 
    "getpass": {
      "file": "getpass.py", 
      "imports": [
        "EasyDialogs.AskPassword", 
        "msvcrt", 
        "sys", 
        "termios", 
        "os", 
        "warnings", 
        "pwd"
      ]
    }, 
    "gettext": {
      "file": "gettext.py", 
      "imports": [
        "__builtin__", 
        "cStringIO.StringIO", 
        "copy", 
        "errno.ENOENT", 
        "sys", 
        "token", 
        "locale", 
        "os", 
        "re", 
        "StringIO", 
        "struct", 
        "tokenize"
      ]
    }, 
    "glob": {
      "file": "glob.py", 
      "imports": [
        "fnmatch", 
        "sys", 
        "os", 
        "re"
      ]
    }, 
    "greenlet": {
      "file": "greenlet.py", 
      "imports": [
        "_continuation", 
        "sys", 
        "threading.local"
      ]
    }, 
    "grp": {
      "file": "grp.py", 
      "imports": [
        "__pypy__.builtinify", 
        "_structseq", 
        "ctypes.POINTER", 
        "ctypes.Structure", 
        "ctypes.c_char_p", 
        "ctypes.c_int", 
        "ctypes_support.standard_c_lib", 
        "sys"
      ]
    }, 
    "gzip": {
      "file": "gzip.py", 
      "imports": [
        "__builtin__", 
        "errno", 
        "sys", 
        "time", 
        "zlib", 
        "io", 
        "os", 
        "struct", 
        "warnings"
      ]
    }, 
    "hashlib": {
      "file": "hashlib.py", 
      "imports": [
        "_hashlib", 
        "_hashlib.pbkdf2_hmac", 
        "_md5", 
        "_sha", 
        "binascii", 
        "logging", 
        "struct", 
        "_sha256", 
        "_sha512"
      ]
    }, 
    "heapq": {
      "file": "heapq.py", 
      "imports": [
        "_heapq.*", 
        "doctest", 
        "itertools.chain", 
        "itertools.count", 
        "itertools.imap", 
        "itertools.islice", 
        "itertools.izip", 
        "itertools.tee", 
        "operator.itemgetter"
      ]
    }, 
    "hmac": {
      "file": "hmac.py", 
      "imports": [
        "hashlib", 
        "operator._compare_digest", 
        "warnings"
      ]
    }, 
    "htmlentitydefs": {
      "file": "htmlentitydefs.py", 
      "imports": []
    }, 
    "htmllib": {
      "file": "htmllib.py", 
      "imports": [
        "formatter", 
        "htmlentitydefs", 
        "sys", 
        "sgmllib", 
        "warnings"
      ]
    }, 
    "httplib": {
      "file": "httplib.py", 
      "imports": [
        "array.array", 
        "cStringIO.StringIO", 
        "ssl", 
        "sys.py3kwarning", 
        "mimetools", 
        "os", 
        "socket", 
        "StringIO", 
        "urlparse", 
        "warnings"
      ]
    }, 
    "identity_dict": {
      "file": "identity_dict.py", 
      "imports": [
        "UserDict", 
        "__pypy__.identity_dict"
      ]
    }, 
    "ihooks": {
      "file": "ihooks.py", 
      "imports": [
        "__builtin__", 
        "imp", 
        "imp.C_BUILTIN", 
        "imp.C_EXTENSION", 
        "imp.PKG_DIRECTORY", 
        "imp.PY_COMPILED", 
        "imp.PY_FROZEN", 
        "imp.PY_SOURCE", 
        "marshal", 
        "sys", 
        "os", 
        "warnings"
      ]
    }, 
    "imaplib": {
      "file": "imaplib.py", 
      "imports": [
        "binascii", 
        "errno", 
        "getopt", 
        "getpass", 
        "hmac", 
        "ssl", 
        "subprocess", 
        "sys", 
        "time", 
        "random", 
        "re", 
        "socket"
      ]
    }, 
    "imghdr": {
      "file": "imghdr.py", 
      "imports": [
        "glob", 
        "sys", 
        "os"
      ]
    }, 
    "importlib": {
      "dir": "importlib"
    }, 
    "importlib.__init__": {
      "file": "importlib/__init__.py", 
      "imports": [
        "sys"
      ]
    }, 
    "imputil": {
      "file": "imputil.py", 
      "imports": [
        "__builtin__", 
        "dos.stat", 
        "imp", 
        "marshal", 
        "nt.stat", 
        "os2.stat", 
        "posix.stat", 
        "sys", 
        "struct", 
        "warnings"
      ]
    }, 
    "inspect": {
      "file": "inspect.py", 
      "imports": [
        "collections", 
        "dis", 
        "imp", 
        "operator.attrgetter", 
        "sys", 
        "linecache", 
        "os", 
        "re", 
        "string", 
        "tokenize", 
        "types"
      ]
    }, 
    "io": {
      "file": "io.py", 
      "imports": [
        "_io", 
        "_io.BlockingIOError", 
        "_io.BufferedRWPair", 
        "_io.BufferedRandom", 
        "_io.BufferedReader", 
        "_io.BufferedWriter", 
        "_io.BytesIO", 
        "_io.DEFAULT_BUFFER_SIZE", 
        "_io.FileIO", 
        "_io.IncrementalNewlineDecoder", 
        "_io.StringIO", 
        "_io.TextIOWrapper", 
        "_io.UnsupportedOperation", 
        "_io.open", 
        "abc"
      ]
    }, 
    "json": {
      "dir": "json"
    }, 
    "json.__init__": {
      "file": "json/__init__.py", 
      "imports": [
        "_pypyjson", 
        "json.decoder", 
        "json.encoder"
      ]
    }, 
    "json.decoder": {
      "file": "json/decoder.py", 
      "imports": [
        "_json.scanstring", 
        "json.scanner", 
        "sys", 
        "re", 
        "struct"
      ]
    }, 
    "json.encoder": {
      "file": "json/encoder.py", 
      "imports": [
        "__pypy__.builders.StringBuilder", 
        "__pypy__.builders.UnicodeBuilder", 
        "_pypyjson.raw_encode_basestring_ascii", 
        "re"
      ]
    }, 
    "json.scanner": {
      "file": "json/scanner.py", 
      "imports": [
        "_json.make_scanner", 
        "re"
      ]
    }, 
    "json.tests": {
      "dir": "json/tests"
    }, 
    "json.tests.__init__": {
      "file": "json/tests/__init__.py", 
      "imports": [
        "doctest", 
        "json", 
        "sys", 
        "os", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "json.tests.test_check_circular": {
      "file": "json/tests/test_check_circular.py", 
      "imports": [
        "json.tests"
      ]
    }, 
    "json.tests.test_decode": {
      "file": "json/tests/test_decode.py", 
      "imports": [
        "collections", 
        "decimal", 
        "json.tests", 
        "StringIO"
      ]
    }, 
    "json.tests.test_default": {
      "file": "json/tests/test_default.py", 
      "imports": [
        "json.tests"
      ]
    }, 
    "json.tests.test_dump": {
      "file": "json/tests/test_dump.py", 
      "imports": [
        "cStringIO.StringIO", 
        "json.tests"
      ]
    }, 
    "json.tests.test_encode_basestring_ascii": {
      "file": "json/tests/test_encode_basestring_ascii.py", 
      "imports": [
        "collections", 
        "json.tests"
      ]
    }, 
    "json.tests.test_fail": {
      "file": "json/tests/test_fail.py", 
      "imports": [
        "json.tests"
      ]
    }, 
    "json.tests.test_float": {
      "file": "json/tests/test_float.py", 
      "imports": [
        "json.tests", 
        "math"
      ]
    }, 
    "json.tests.test_indent": {
      "file": "json/tests/test_indent.py", 
      "imports": [
        "json.tests", 
        "StringIO", 
        "textwrap"
      ]
    }, 
    "json.tests.test_pass1": {
      "file": "json/tests/test_pass1.py", 
      "imports": [
        "json.tests"
      ]
    }, 
    "json.tests.test_pass2": {
      "file": "json/tests/test_pass2.py", 
      "imports": [
        "json.tests"
      ]
    }, 
    "json.tests.test_pass3": {
      "file": "json/tests/test_pass3.py", 
      "imports": [
        "json.tests"
      ]
    }, 
    "json.tests.test_recursion": {
      "file": "json/tests/test_recursion.py", 
      "imports": [
        "json.tests"
      ]
    }, 
    "json.tests.test_scanstring": {
      "file": "json/tests/test_scanstring.py", 
      "imports": [
        "json.tests", 
        "sys"
      ]
    }, 
    "json.tests.test_separators": {
      "file": "json/tests/test_separators.py", 
      "imports": [
        "json.tests", 
        "textwrap"
      ]
    }, 
    "json.tests.test_speedups": {
      "file": "json/tests/test_speedups.py", 
      "imports": [
        "json.tests"
      ]
    }, 
    "json.tests.test_tool": {
      "file": "json/tests/test_tool.py", 
      "imports": [
        "subprocess", 
        "sys", 
        "os", 
        "test.test_support", 
        "test.script_helper", 
        "textwrap", 
        "unittest"
      ]
    }, 
    "json.tests.test_unicode": {
      "file": "json/tests/test_unicode.py", 
      "imports": [
        "collections", 
        "json.tests"
      ]
    }, 
    "json.tool": {
      "file": "json/tool.py", 
      "imports": [
        "json", 
        "sys"
      ]
    }, 
    "keyword": {
      "file": "keyword.py", 
      "imports": [
        "sys", 
        "re"
      ]
    }, 
    "lib2to3": {
      "dir": "lib2to3"
    }, 
    "lib2to3.__init__": {
      "file": "lib2to3/__init__.py", 
      "imports": []
    }, 
    "lib2to3.__main__": {
      "file": "lib2to3/__main__.py", 
      "imports": [
        "lib2to3.main", 
        "sys"
      ]
    }, 
    "lib2to3.btm_matcher": {
      "file": "lib2to3/btm_matcher.py", 
      "imports": [
        "collections", 
        "itertools", 
        "lib2to3.btm_utils", 
        "lib2to3.pygram", 
        "lib2to3.pytree", 
        "logging"
      ]
    }, 
    "lib2to3.btm_utils": {
      "file": "lib2to3/btm_utils.py", 
      "imports": [
        "lib2to3.pgen2.grammar", 
        "lib2to3.pgen2.token", 
        "lib2to3.pygram", 
        "lib2to3.pytree"
      ]
    }, 
    "lib2to3.fixer_base": {
      "file": "lib2to3/fixer_base.py", 
      "imports": [
        "itertools", 
        "lib2to3.fixer_util", 
        "lib2to3.patcomp", 
        "lib2to3.pygram", 
        "logging"
      ]
    }, 
    "lib2to3.fixer_util": {
      "file": "lib2to3/fixer_util.py", 
      "imports": [
        "itertools.islice", 
        "lib2to3.patcomp", 
        "lib2to3.pgen2.token", 
        "lib2to3.pygram", 
        "lib2to3.pytree"
      ]
    }, 
    "lib2to3.fixes": {
      "dir": "lib2to3/fixes"
    }, 
    "lib2to3.fixes.__init__": {
      "file": "lib2to3/fixes/__init__.py", 
      "imports": []
    }, 
    "lib2to3.fixes.fix_apply": {
      "file": "lib2to3/fixes/fix_apply.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util", 
        "lib2to3.pgen2.token", 
        "lib2to3.pytree"
      ]
    }, 
    "lib2to3.fixes.fix_basestring": {
      "file": "lib2to3/fixes/fix_basestring.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util"
      ]
    }, 
    "lib2to3.fixes.fix_buffer": {
      "file": "lib2to3/fixes/fix_buffer.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util"
      ]
    }, 
    "lib2to3.fixes.fix_callable": {
      "file": "lib2to3/fixes/fix_callable.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util"
      ]
    }, 
    "lib2to3.fixes.fix_dict": {
      "file": "lib2to3/fixes/fix_dict.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util", 
        "lib2to3.patcomp", 
        "lib2to3.pgen2.token", 
        "lib2to3.pytree"
      ]
    }, 
    "lib2to3.fixes.fix_except": {
      "file": "lib2to3/fixes/fix_except.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util", 
        "lib2to3.pgen2.token", 
        "lib2to3.pytree"
      ]
    }, 
    "lib2to3.fixes.fix_exec": {
      "file": "lib2to3/fixes/fix_exec.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util", 
        "lib2to3.pytree"
      ]
    }, 
    "lib2to3.fixes.fix_execfile": {
      "file": "lib2to3/fixes/fix_execfile.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util"
      ]
    }, 
    "lib2to3.fixes.fix_exitfunc": {
      "file": "lib2to3/fixes/fix_exitfunc.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util", 
        "lib2to3.pytree"
      ]
    }, 
    "lib2to3.fixes.fix_filter": {
      "file": "lib2to3/fixes/fix_filter.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util", 
        "lib2to3.pgen2.token"
      ]
    }, 
    "lib2to3.fixes.fix_funcattrs": {
      "file": "lib2to3/fixes/fix_funcattrs.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util"
      ]
    }, 
    "lib2to3.fixes.fix_future": {
      "file": "lib2to3/fixes/fix_future.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util"
      ]
    }, 
    "lib2to3.fixes.fix_getcwdu": {
      "file": "lib2to3/fixes/fix_getcwdu.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util"
      ]
    }, 
    "lib2to3.fixes.fix_has_key": {
      "file": "lib2to3/fixes/fix_has_key.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util", 
        "lib2to3.pgen2.token", 
        "lib2to3.pytree"
      ]
    }, 
    "lib2to3.fixes.fix_idioms": {
      "file": "lib2to3/fixes/fix_idioms.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util"
      ]
    }, 
    "lib2to3.fixes.fix_import": {
      "file": "lib2to3/fixes/fix_import.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util", 
        "os"
      ]
    }, 
    "lib2to3.fixes.fix_imports": {
      "file": "lib2to3/fixes/fix_imports.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util"
      ]
    }, 
    "lib2to3.fixes.fix_imports2": {
      "file": "lib2to3/fixes/fix_imports2.py", 
      "imports": [
        "lib2to3.fixes.fix_imports"
      ]
    }, 
    "lib2to3.fixes.fix_input": {
      "file": "lib2to3/fixes/fix_input.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util", 
        "lib2to3.patcomp"
      ]
    }, 
    "lib2to3.fixes.fix_intern": {
      "file": "lib2to3/fixes/fix_intern.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util", 
        "lib2to3.pytree"
      ]
    }, 
    "lib2to3.fixes.fix_isinstance": {
      "file": "lib2to3/fixes/fix_isinstance.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util"
      ]
    }, 
    "lib2to3.fixes.fix_itertools": {
      "file": "lib2to3/fixes/fix_itertools.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util"
      ]
    }, 
    "lib2to3.fixes.fix_itertools_imports": {
      "file": "lib2to3/fixes/fix_itertools_imports.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util"
      ]
    }, 
    "lib2to3.fixes.fix_long": {
      "file": "lib2to3/fixes/fix_long.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util"
      ]
    }, 
    "lib2to3.fixes.fix_map": {
      "file": "lib2to3/fixes/fix_map.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util", 
        "lib2to3.pgen2.token", 
        "lib2to3.pygram"
      ]
    }, 
    "lib2to3.fixes.fix_metaclass": {
      "file": "lib2to3/fixes/fix_metaclass.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util", 
        "lib2to3.pygram"
      ]
    }, 
    "lib2to3.fixes.fix_methodattrs": {
      "file": "lib2to3/fixes/fix_methodattrs.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util"
      ]
    }, 
    "lib2to3.fixes.fix_ne": {
      "file": "lib2to3/fixes/fix_ne.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.pgen2.token", 
        "lib2to3.pytree"
      ]
    }, 
    "lib2to3.fixes.fix_next": {
      "file": "lib2to3/fixes/fix_next.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util", 
        "lib2to3.pgen2.token", 
        "lib2to3.pygram"
      ]
    }, 
    "lib2to3.fixes.fix_nonzero": {
      "file": "lib2to3/fixes/fix_nonzero.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util"
      ]
    }, 
    "lib2to3.fixes.fix_numliterals": {
      "file": "lib2to3/fixes/fix_numliterals.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util", 
        "lib2to3.pgen2.token"
      ]
    }, 
    "lib2to3.fixes.fix_operator": {
      "file": "lib2to3/fixes/fix_operator.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util"
      ]
    }, 
    "lib2to3.fixes.fix_paren": {
      "file": "lib2to3/fixes/fix_paren.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util"
      ]
    }, 
    "lib2to3.fixes.fix_print": {
      "file": "lib2to3/fixes/fix_print.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util", 
        "lib2to3.patcomp", 
        "lib2to3.pgen2.token", 
        "lib2to3.pytree"
      ]
    }, 
    "lib2to3.fixes.fix_raise": {
      "file": "lib2to3/fixes/fix_raise.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util", 
        "lib2to3.pgen2.token", 
        "lib2to3.pytree"
      ]
    }, 
    "lib2to3.fixes.fix_raw_input": {
      "file": "lib2to3/fixes/fix_raw_input.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util"
      ]
    }, 
    "lib2to3.fixes.fix_reduce": {
      "file": "lib2to3/fixes/fix_reduce.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util"
      ]
    }, 
    "lib2to3.fixes.fix_renames": {
      "file": "lib2to3/fixes/fix_renames.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util"
      ]
    }, 
    "lib2to3.fixes.fix_repr": {
      "file": "lib2to3/fixes/fix_repr.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util"
      ]
    }, 
    "lib2to3.fixes.fix_set_literal": {
      "file": "lib2to3/fixes/fix_set_literal.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util", 
        "lib2to3.pytree"
      ]
    }, 
    "lib2to3.fixes.fix_standarderror": {
      "file": "lib2to3/fixes/fix_standarderror.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util"
      ]
    }, 
    "lib2to3.fixes.fix_sys_exc": {
      "file": "lib2to3/fixes/fix_sys_exc.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util"
      ]
    }, 
    "lib2to3.fixes.fix_throw": {
      "file": "lib2to3/fixes/fix_throw.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util", 
        "lib2to3.pgen2.token", 
        "lib2to3.pytree"
      ]
    }, 
    "lib2to3.fixes.fix_tuple_params": {
      "file": "lib2to3/fixes/fix_tuple_params.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util", 
        "lib2to3.pgen2.token", 
        "lib2to3.pytree"
      ]
    }, 
    "lib2to3.fixes.fix_types": {
      "file": "lib2to3/fixes/fix_types.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util", 
        "lib2to3.pgen2.token"
      ]
    }, 
    "lib2to3.fixes.fix_unicode": {
      "file": "lib2to3/fixes/fix_unicode.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.pgen2.token"
      ]
    }, 
    "lib2to3.fixes.fix_urllib": {
      "file": "lib2to3/fixes/fix_urllib.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util", 
        "lib2to3.fixes.fix_imports"
      ]
    }, 
    "lib2to3.fixes.fix_ws_comma": {
      "file": "lib2to3/fixes/fix_ws_comma.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.pgen2.token", 
        "lib2to3.pytree"
      ]
    }, 
    "lib2to3.fixes.fix_xrange": {
      "file": "lib2to3/fixes/fix_xrange.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util", 
        "lib2to3.patcomp"
      ]
    }, 
    "lib2to3.fixes.fix_xreadlines": {
      "file": "lib2to3/fixes/fix_xreadlines.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util"
      ]
    }, 
    "lib2to3.fixes.fix_zip": {
      "file": "lib2to3/fixes/fix_zip.py", 
      "imports": [
        "lib2to3.fixer_base", 
        "lib2to3.fixer_util"
      ]
    }, 
    "lib2to3.main": {
      "file": "lib2to3/main.py", 
      "imports": [
        "__future__", 
        "difflib", 
        "lib2to3.refactor", 
        "sys", 
        "logging", 
        "optparse", 
        "os", 
        "shutil"
      ]
    }, 
    "lib2to3.patcomp": {
      "file": "lib2to3/patcomp.py", 
      "imports": [
        "lib2to3.pgen2.driver", 
        "lib2to3.pgen2.grammar", 
        "lib2to3.pgen2.literals", 
        "lib2to3.pgen2.parse", 
        "lib2to3.pgen2.token", 
        "lib2to3.pgen2.tokenize", 
        "lib2to3.pygram", 
        "lib2to3.pytree", 
        "os", 
        "StringIO"
      ]
    }, 
    "lib2to3.pgen2": {
      "dir": "lib2to3/pgen2"
    }, 
    "lib2to3.pgen2.__init__": {
      "file": "lib2to3/pgen2/__init__.py", 
      "imports": []
    }, 
    "lib2to3.pgen2.conv": {
      "file": "lib2to3/pgen2/conv.py", 
      "imports": [
        "lib2to3.pgen2.grammar", 
        "lib2to3.pgen2.token", 
        "re"
      ]
    }, 
    "lib2to3.pgen2.driver": {
      "file": "lib2to3/pgen2/driver.py", 
      "imports": [
        "codecs", 
        "lib2to3.pgen2.grammar", 
        "lib2to3.pgen2.parse", 
        "lib2to3.pgen2.pgen", 
        "lib2to3.pgen2.token", 
        "lib2to3.pgen2.tokenize", 
        "sys", 
        "logging", 
        "os", 
        "StringIO"
      ]
    }, 
    "lib2to3.pgen2.grammar": {
      "file": "lib2to3/pgen2/grammar.py", 
      "imports": [
        "lib2to3.pgen2.token", 
        "lib2to3.pgen2.tokenize", 
        "pickle", 
        "pprint"
      ]
    }, 
    "lib2to3.pgen2.literals": {
      "file": "lib2to3/pgen2/literals.py", 
      "imports": [
        "re"
      ]
    }, 
    "lib2to3.pgen2.parse": {
      "file": "lib2to3/pgen2/parse.py", 
      "imports": [
        "lib2to3.pgen2.token"
      ]
    }, 
    "lib2to3.pgen2.pgen": {
      "file": "lib2to3/pgen2/pgen.py", 
      "imports": [
        "lib2to3.pgen2.grammar", 
        "lib2to3.pgen2.token", 
        "lib2to3.pgen2.tokenize"
      ]
    }, 
    "lib2to3.pgen2.token": {
      "file": "lib2to3/pgen2/token.py", 
      "imports": []
    }, 
    "lib2to3.pgen2.tokenize": {
      "file": "lib2to3/pgen2/tokenize.py", 
      "imports": [
        "codecs", 
        "lib2to3.pgen2.token", 
        "sys", 
        "re", 
        "string"
      ]
    }, 
    "lib2to3.pygram": {
      "file": "lib2to3/pygram.py", 
      "imports": [
        "lib2to3.pgen2.driver", 
        "lib2to3.pgen2.token", 
        "lib2to3.pytree", 
        "os"
      ]
    }, 
    "lib2to3.pytree": {
      "file": "lib2to3/pytree.py", 
      "imports": [
        "lib2to3.pygram", 
        "sys", 
        "StringIO", 
        "warnings"
      ]
    }, 
    "lib2to3.refactor": {
      "file": "lib2to3/refactor.py", 
      "imports": [
        "__future__", 
        "codecs", 
        "collections", 
        "itertools.chain", 
        "lib2to3.btm_matcher", 
        "lib2to3.btm_utils", 
        "lib2to3.fixer_util", 
        "lib2to3.pgen2.driver", 
        "lib2to3.pgen2.token", 
        "lib2to3.pgen2.tokenize", 
        "lib2to3.pygram", 
        "lib2to3.pytree", 
        "multiprocessing", 
        "operator", 
        "sys", 
        "logging", 
        "os", 
        "StringIO"
      ]
    }, 
    "lib2to3.tests": {
      "dir": "lib2to3/tests"
    }, 
    "lib2to3.tests.__init__": {
      "file": "lib2to3/tests/__init__.py", 
      "imports": [
        "lib2to3.tests.support", 
        "os", 
        "types", 
        "unittest"
      ]
    }, 
    "lib2to3.tests.pytree_idempotency": {
      "file": "lib2to3/tests/pytree_idempotency.py", 
      "imports": [
        "lib2to3.pgen2", 
        "lib2to3.pgen2.driver", 
        "lib2to3.pytree", 
        "lib2to3.tests.support", 
        "sys", 
        "logging", 
        "os"
      ]
    }, 
    "lib2to3.tests.support": {
      "file": "lib2to3/tests/support.py", 
      "imports": [
        "lib2to3.pgen2.driver", 
        "lib2to3.pytree", 
        "lib2to3.refactor", 
        "sys", 
        "os", 
        "re", 
        "textwrap", 
        "unittest"
      ]
    }, 
    "lib2to3.tests.test_all_fixers": {
      "file": "lib2to3/tests/test_all_fixers.py", 
      "imports": [
        "lib2to3.refactor", 
        "lib2to3.tests.support", 
        "unittest"
      ]
    }, 
    "lib2to3.tests.test_fixers": {
      "file": "lib2to3/tests/test_fixers.py", 
      "imports": [
        "itertools.chain", 
        "lib2to3.fixer_util", 
        "lib2to3.fixes.fix_import", 
        "lib2to3.fixes.fix_imports", 
        "lib2to3.fixes.fix_imports2", 
        "lib2to3.fixes.fix_urllib", 
        "lib2to3.pygram", 
        "lib2to3.pytree", 
        "lib2to3.refactor", 
        "lib2to3.tests.support", 
        "operator.itemgetter", 
        "os", 
        "unittest"
      ]
    }, 
    "lib2to3.tests.test_main": {
      "file": "lib2to3/tests/test_main.py", 
      "imports": [
        "codecs", 
        "lib2to3.main", 
        "sys", 
        "logging", 
        "os", 
        "re", 
        "shutil", 
        "StringIO", 
        "tempfile", 
        "unittest"
      ]
    }, 
    "lib2to3.tests.test_parser": {
      "file": "lib2to3/tests/test_parser.py", 
      "imports": [
        "__future__", 
        "lib2to3.pgen2.parse", 
        "lib2to3.pgen2.tokenize", 
        "lib2to3.pygram", 
        "lib2to3.tests.support", 
        "sys", 
        "os"
      ]
    }, 
    "lib2to3.tests.test_pytree": {
      "file": "lib2to3/tests/test_pytree.py", 
      "imports": [
        "__future__", 
        "lib2to3.pytree", 
        "lib2to3.tests.support", 
        "sys", 
        "warnings"
      ]
    }, 
    "lib2to3.tests.test_refactor": {
      "file": "lib2to3/tests/test_refactor.py", 
      "imports": [
        "__future__", 
        "codecs", 
        "lib2to3.fixer_base", 
        "lib2to3.pgen2.token", 
        "lib2to3.pygram", 
        "lib2to3.refactor", 
        "lib2to3.tests.support", 
        "myfixes.fix_explicit.FixExplicit", 
        "myfixes.fix_first.FixFirst", 
        "myfixes.fix_last.FixLast", 
        "myfixes.fix_parrot.FixParrot", 
        "myfixes.fix_preorder.FixPreorder", 
        "operator", 
        "sys", 
        "os", 
        "shutil", 
        "StringIO", 
        "tempfile", 
        "unittest", 
        "warnings"
      ]
    }, 
    "lib2to3.tests.test_util": {
      "file": "lib2to3/tests/test_util.py", 
      "imports": [
        "lib2to3.fixer_util", 
        "lib2to3.pgen2.token", 
        "lib2to3.pytree", 
        "lib2to3.tests.support", 
        "os"
      ]
    }, 
    "linecache": {
      "file": "linecache.py", 
      "imports": [
        "sys", 
        "os"
      ]
    }, 
    "locale": {
      "file": "locale.py", 
      "imports": [
        "_locale", 
        "_locale.*", 
        "encodings", 
        "encodings.aliases", 
        "functools", 
        "operator", 
        "sys", 
        "os", 
        "re"
      ]
    }, 
    "logging": {
      "dir": "logging"
    }, 
    "logging.__init__": {
      "file": "logging/__init__.py", 
      "imports": [
        "atexit", 
        "cStringIO", 
        "codecs", 
        "collections", 
        "sys", 
        "thread", 
        "threading", 
        "time", 
        "os", 
        "traceback", 
        "warnings", 
        "weakref"
      ]
    }, 
    "logging.config": {
      "file": "logging/config.py", 
      "imports": [
        "ConfigParser", 
        "cStringIO", 
        "errno", 
        "io", 
        "json", 
        "logging", 
        "logging.handlers", 
        "select", 
        "sys", 
        "thread", 
        "threading", 
        "os", 
        "re", 
        "socket", 
        "SocketServer", 
        "struct", 
        "tempfile", 
        "traceback", 
        "types"
      ]
    }, 
    "logging.handlers": {
      "file": "logging/handlers.py", 
      "imports": [
        "codecs", 
        "email.utils", 
        "errno", 
        "httplib", 
        "logging", 
        "time", 
        "win32evtlog", 
        "win32evtlogutil", 
        "os", 
        "re", 
        "smtplib", 
        "socket", 
        "stat", 
        "struct", 
        "urllib", 
        "cPickle"
      ]
    }, 
    "macurl2path": {
      "file": "macurl2path.py", 
      "imports": [
        "os", 
        "urllib"
      ]
    }, 
    "mailbox": {
      "file": "mailbox.py", 
      "imports": [
        "calendar", 
        "copy", 
        "email", 
        "email.generator", 
        "email.message", 
        "errno", 
        "fcntl", 
        "sys", 
        "time", 
        "os", 
        "re", 
        "rfc822", 
        "socket", 
        "StringIO", 
        "warnings"
      ]
    }, 
    "mailcap": {
      "file": "mailcap.py", 
      "imports": [
        "sys", 
        "os"
      ]
    }, 
    "markupbase": {
      "file": "markupbase.py", 
      "imports": [
        "re"
      ]
    }, 
    "marshal": {
      "file": "marshal.py", 
      "imports": [
        "_marshal"
      ]
    }, 
    "md5": {
      "file": "md5.py", 
      "imports": [
        "hashlib", 
        "warnings"
      ]
    }, 
    "mhlib": {
      "file": "mhlib.py", 
      "imports": [
        "bisect", 
        "cStringIO.StringIO", 
        "sys", 
        "mimetools", 
        "multifile", 
        "os", 
        "re", 
        "shutil", 
        "StringIO", 
        "warnings"
      ]
    }, 
    "mimetools": {
      "file": "mimetools.py", 
      "imports": [
        "base64", 
        "dummy_thread", 
        "sys", 
        "thread", 
        "time", 
        "os", 
        "quopri", 
        "rfc822", 
        "socket", 
        "tempfile", 
        "uu", 
        "warnings"
      ]
    }, 
    "mimetypes": {
      "file": "mimetypes.py", 
      "imports": [
        "_winreg", 
        "getopt", 
        "sys", 
        "os", 
        "posixpath", 
        "urllib"
      ]
    }, 
    "mimify": {
      "file": "mimify.py", 
      "imports": [
        "base64", 
        "getopt", 
        "sys", 
        "os", 
        "re", 
        "warnings"
      ]
    }, 
    "modulefinder": {
      "file": "modulefinder.py", 
      "imports": [
        "__future__", 
        "dis", 
        "getopt", 
        "imp", 
        "marshal", 
        "sys", 
        "os", 
        "struct", 
        "types"
      ]
    }, 
    "multifile": {
      "file": "multifile.py", 
      "imports": [
        "warnings"
      ]
    }, 
    "mutex": {
      "file": "mutex.py", 
      "imports": [
        "collections", 
        "warnings"
      ]
    }, 
    "netrc": {
      "file": "netrc.py", 
      "imports": [
        "os", 
        "shlex", 
        "stat", 
        "pwd"
      ]
    }, 
    "new": {
      "file": "new.py", 
      "imports": [
        "types", 
        "warnings"
      ]
    }, 
    "nntplib": {
      "file": "nntplib.py", 
      "imports": [
        "netrc", 
        "os", 
        "re", 
        "socket"
      ]
    }, 
    "nturl2path": {
      "file": "nturl2path.py", 
      "imports": [
        "string", 
        "urllib"
      ]
    }, 
    "numbers": {
      "file": "numbers.py", 
      "imports": [
        "__future__", 
        "abc"
      ]
    }, 
    "opcode": {
      "file": "opcode.py", 
      "imports": []
    }, 
    "optparse": {
      "file": "optparse.py", 
      "imports": [
        "__builtin__", 
        "gettext", 
        "sys", 
        "os", 
        "textwrap", 
        "types"
      ]
    }, 
    "os": {
      "file": "os.py", 
      "imports": [
        "_emx_link.link", 
        "ce", 
        "ce.*", 
        "ce._exit", 
        "copy_reg", 
        "errno", 
        "nt", 
        "nt.*", 
        "nt._exit", 
        "ntpath", 
        "os", 
        "os2", 
        "os2.*", 
        "os2._exit", 
        "os2emxpath", 
        "posix", 
        "posix.*", 
        "posix._exit", 
        "riscos", 
        "riscos.*", 
        "riscos._exit", 
        "riscosenviron._Environ", 
        "riscospath", 
        "subprocess", 
        "sys", 
        "posixpath", 
        "UserDict", 
        "warnings"
      ]
    }, 
    "pdb": {
      "file": "pdb.py", 
      "imports": [
        "__main__", 
        "bdb", 
        "cmd", 
        "linecache", 
        "os", 
        "pdb", 
        "readline", 
        "sys", 
        "pprint", 
        "re", 
        "repr", 
        "shlex", 
        "traceback"
      ]
    }, 
    "pickle": {
      "file": "pickle.py", 
      "imports": [
        "binascii", 
        "cStringIO.StringIO", 
        "copy_reg", 
        "doctest", 
        "marshal", 
        "org.python.core.PyStringMap", 
        "sys", 
        "re", 
        "StringIO", 
        "struct", 
        "types"
      ]
    }, 
    "pickletools": {
      "file": "pickletools.py", 
      "imports": [
        "cStringIO", 
        "doctest", 
        "pickle", 
        "re", 
        "struct"
      ]
    }, 
    "pipes": {
      "file": "pipes.py", 
      "imports": [
        "os", 
        "re", 
        "string", 
        "tempfile"
      ]
    }, 
    "pkgutil": {
      "file": "pkgutil.py", 
      "imports": [
        "imp", 
        "inspect", 
        "marshal", 
        "os", 
        "sys", 
        "zipimport", 
        "zipimport.zipimporter", 
        "types"
      ]
    }, 
    "platform": {
      "file": "platform.py", 
      "imports": [
        "MacOS", 
        "_winreg", 
        "gestalt", 
        "gestalt.gestalt", 
        "java.lang", 
        "java.lang.System", 
        "os", 
        "subprocess", 
        "sys", 
        "vms_lib", 
        "win32api", 
        "win32api.GetVersionEx", 
        "win32api.RegCloseKey", 
        "win32api.RegOpenKeyEx", 
        "win32api.RegQueryValueEx", 
        "win32con.HKEY_LOCAL_MACHINE", 
        "win32con.VER_NT_WORKSTATION", 
        "win32con.VER_PLATFORM_WIN32_NT", 
        "win32con.VER_PLATFORM_WIN32_WINDOWS", 
        "win32pipe", 
        "plistlib", 
        "re", 
        "socket", 
        "string", 
        "struct", 
        "tempfile"
      ]
    }, 
    "plistlib": {
      "file": "plistlib.py", 
      "imports": [
        "Carbon.File.FSGetResourceForkName", 
        "Carbon.File.FSRef", 
        "Carbon.Files.fsRdPerm", 
        "Carbon.Files.fsRdWrPerm", 
        "Carbon.Res", 
        "binascii", 
        "cStringIO.StringIO", 
        "re", 
        "warnings", 
        "xml.parsers.expat", 
        "datetime"
      ]
    }, 
    "popen2": {
      "file": "popen2.py", 
      "imports": [
        "os", 
        "sys", 
        "warnings"
      ]
    }, 
    "poplib": {
      "file": "poplib.py", 
      "imports": [
        "hashlib", 
        "ssl", 
        "sys", 
        "re", 
        "socket"
      ]
    }, 
    "posixfile": {
      "file": "posixfile.py", 
      "imports": [
        "__builtin__", 
        "fcntl", 
        "os", 
        "posix", 
        "sys", 
        "struct", 
        "types", 
        "warnings"
      ]
    }, 
    "posixpath": {
      "file": "posixpath.py", 
      "imports": [
        "genericpath", 
        "os", 
        "sys", 
        "re", 
        "stat", 
        "warnings", 
        "pwd"
      ]
    }, 
    "pprint": {
      "file": "pprint.py", 
      "imports": [
        "cStringIO.StringIO", 
        "sys", 
        "time", 
        "StringIO", 
        "warnings"
      ]
    }, 
    "profile": {
      "file": "profile.py", 
      "imports": [
        "__main__", 
        "marshal", 
        "optparse", 
        "os", 
        "sys", 
        "time", 
        "pstats", 
        "resource"
      ]
    }, 
    "pstats": {
      "file": "pstats.py", 
      "imports": [
        "cmd", 
        "functools", 
        "marshal", 
        "os", 
        "readline", 
        "sys", 
        "time", 
        "re"
      ]
    }, 
    "pty": {
      "file": "pty.py", 
      "imports": [
        "fcntl.I_PUSH", 
        "fcntl.ioctl", 
        "os", 
        "select.select", 
        "sgi", 
        "tty"
      ]
    }, 
    "pwd": {
      "file": "pwd.py", 
      "imports": [
        "__pypy__.builtinify", 
        "_structseq", 
        "ctypes.POINTER", 
        "ctypes.Structure", 
        "ctypes.c_char_p", 
        "ctypes.c_int", 
        "ctypes.c_long", 
        "ctypes_support.standard_c_lib", 
        "os", 
        "sys"
      ]
    }, 
    "py_compile": {
      "file": "py_compile.py", 
      "imports": [
        "__builtin__", 
        "imp", 
        "marshal", 
        "os", 
        "sys", 
        "traceback"
      ]
    }, 
    "pyclbr": {
      "file": "pyclbr.py", 
      "imports": [
        "imp", 
        "operator.itemgetter", 
        "os", 
        "sys", 
        "token.DEDENT", 
        "token.NAME", 
        "token.OP", 
        "tokenize"
      ]
    }, 
    "pydoc": {
      "file": "pydoc.py", 
      "imports": [
        "BaseHTTPServer", 
        "Tkinter", 
        "__builtin__", 
        "collections", 
        "formatter", 
        "getopt", 
        "imp", 
        "inspect", 
        "locale", 
        "mimetools", 
        "nturl2path", 
        "os", 
        "pkgutil", 
        "select", 
        "sys", 
        "threading", 
        "pydoc_data.topics", 
        "re", 
        "repr", 
        "string", 
        "StringIO", 
        "tempfile", 
        "traceback", 
        "tty", 
        "types", 
        "warnings", 
        "webbrowser"
      ]
    }, 
    "pydoc_data": {
      "dir": "pydoc_data"
    }, 
    "pydoc_data.__init__": {
      "file": "pydoc_data/__init__.py", 
      "imports": []
    }, 
    "pydoc_data.topics": {
      "file": "pydoc_data/topics.py", 
      "imports": []
    }, 
    "pyrepl": {
      "dir": "pyrepl"
    }, 
    "pyrepl.__init__": {
      "file": "pyrepl/__init__.py", 
      "imports": []
    }, 
    "pyrepl.cmdrepl": {
      "file": "pyrepl/cmdrepl.py", 
      "imports": [
        "__future__", 
        "cmd", 
        "pyrepl.completer", 
        "pyrepl.completing_reader", 
        "pyrepl.reader"
      ]
    }, 
    "pyrepl.commands": {
      "file": "pyrepl/commands.py", 
      "imports": [
        "os", 
        "pyrepl.input", 
        "signal", 
        "sys"
      ]
    }, 
    "pyrepl.completer": {
      "file": "pyrepl/completer.py", 
      "imports": [
        "__builtin__", 
        "keyword", 
        "re"
      ]
    }, 
    "pyrepl.completing_reader": {
      "file": "pyrepl/completing_reader.py", 
      "imports": [
        "pyrepl.commands", 
        "pyrepl.reader", 
        "re"
      ]
    }, 
    "pyrepl.console": {
      "file": "pyrepl/console.py", 
      "imports": []
    }, 
    "pyrepl.copy_code": {
      "file": "pyrepl/copy_code.py", 
      "imports": [
        "new"
      ]
    }, 
    "pyrepl.curses": {
      "file": "pyrepl/curses.py", 
      "imports": [
        "_curses", 
        "_minimal_curses", 
        "pyrepl.curses", 
        "sys"
      ]
    }, 
    "pyrepl.fancy_termios": {
      "file": "pyrepl/fancy_termios.py", 
      "imports": [
        "termios"
      ]
    }, 
    "pyrepl.historical_reader": {
      "file": "pyrepl/historical_reader.py", 
      "imports": [
        "pyrepl.commands", 
        "pyrepl.input", 
        "pyrepl.reader", 
        "pyrepl.unix_console"
      ]
    }, 
    "pyrepl.input": {
      "file": "pyrepl/input.py", 
      "imports": [
        "pyrepl.keymap", 
        "pyrepl.unicodedata_"
      ]
    }, 
    "pyrepl.keymap": {
      "file": "pyrepl/keymap.py", 
      "imports": []
    }, 
    "pyrepl.keymaps": {
      "file": "pyrepl/keymaps.py", 
      "imports": []
    }, 
    "pyrepl.module_lister": {
      "file": "pyrepl/module_lister.py", 
      "imports": [
        "imp", 
        "os", 
        "sys"
      ]
    }, 
    "pyrepl.pygame_console": {
      "file": "pyrepl/pygame_console.py", 
      "imports": [
        "pygame", 
        "pygame.locals.*", 
        "pyrepl.console", 
        "pyrepl.pygame_keymap", 
        "pyrepl.reader", 
        "types"
      ]
    }, 
    "pyrepl.pygame_keymap": {
      "file": "pyrepl/pygame_keymap.py", 
      "imports": [
        "pygame.locals.*"
      ]
    }, 
    "pyrepl.python_reader": {
      "file": "pyrepl/python_reader.py", 
      "imports": [
        "_tkinter", 
        "atexit", 
        "cPickle", 
        "cocoasupport.CocoaInteracter", 
        "code", 
        "imp", 
        "locale", 
        "new", 
        "os", 
        "pickle", 
        "pyrepl.commands", 
        "pyrepl.completer", 
        "pyrepl.completing_reader", 
        "pyrepl.copy_code", 
        "pyrepl.historical_reader", 
        "pyrepl.module_lister", 
        "pyrepl.pygame_console", 
        "pyrepl.reader", 
        "pyrepl.unix_console", 
        "re", 
        "signal", 
        "sys", 
        "traceback", 
        "twisted.internet.abstract.FileDescriptor", 
        "twisted.internet.reactor", 
        "warnings"
      ]
    }, 
    "pyrepl.reader": {
      "file": "pyrepl/reader.py", 
      "imports": [
        "_pyrepl_utils.disp_str", 
        "_pyrepl_utils.init_unctrl_map", 
        "pyrepl.commands", 
        "pyrepl.input", 
        "pyrepl.unicodedata_", 
        "pyrepl.unix_console", 
        "re", 
        "types"
      ]
    }, 
    "pyrepl.readline": {
      "file": "pyrepl/readline.py", 
      "imports": [
        "__builtin__", 
        "os", 
        "pyrepl.commands", 
        "pyrepl.completing_reader", 
        "pyrepl.historical_reader", 
        "pyrepl.unix_console", 
        "sys", 
        "warnings"
      ]
    }, 
    "pyrepl.simple_interact": {
      "file": "pyrepl/simple_interact.py", 
      "imports": [
        "__main__", 
        "code", 
        "pyrepl.readline", 
        "sys"
      ]
    }, 
    "pyrepl.unicodedata_": {
      "file": "pyrepl/unicodedata_.py", 
      "imports": [
        "unicodedata.*"
      ]
    }, 
    "pyrepl.unix_console": {
      "file": "pyrepl/unix_console.py", 
      "imports": [
        "errno", 
        "fcntl.ioctl", 
        "os", 
        "pyrepl.console", 
        "pyrepl.curses", 
        "pyrepl.fancy_termios", 
        "pyrepl.unix_eventqueue", 
        "re", 
        "select", 
        "signal", 
        "struct", 
        "sys", 
        "termios", 
        "time"
      ]
    }, 
    "pyrepl.unix_eventqueue": {
      "file": "pyrepl/unix_eventqueue.py", 
      "imports": [
        "os", 
        "pyrepl.console", 
        "pyrepl.curses", 
        "pyrepl.keymap", 
        "termios.VERASE", 
        "termios.tcgetattr"
      ]
    }, 
    "quopri": {
      "file": "quopri.py", 
      "imports": [
        "binascii.a2b_qp", 
        "binascii.b2a_qp", 
        "cStringIO.StringIO", 
        "getopt", 
        "sys"
      ]
    }, 
    "random": {
      "file": "random.py", 
      "imports": [
        "__future__", 
        "_random", 
        "binascii.hexlify", 
        "hashlib", 
        "math.acos", 
        "math.ceil", 
        "math.cos", 
        "math.e", 
        "math.exp", 
        "math.log", 
        "math.pi", 
        "math.sin", 
        "math.sqrt", 
        "os", 
        "time", 
        "warnings"
      ]
    }, 
    "re": {
      "file": "re.py", 
      "imports": [
        "copy_reg", 
        "sys", 
        "sre_compile", 
        "sre_constants", 
        "sre_parse"
      ]
    }, 
    "repr": {
      "file": "repr.py", 
      "imports": [
        "__builtin__", 
        "itertools.islice"
      ]
    }, 
    "resource": {
      "file": "resource.py", 
      "imports": [
        "__pypy__.builtinify", 
        "_structseq", 
        "ctypes.POINTER", 
        "ctypes.Structure", 
        "ctypes.byref", 
        "ctypes.c_int", 
        "ctypes.c_long", 
        "ctypes_config_cache._resource_cache", 
        "ctypes_support.get_errno", 
        "ctypes_support.standard_c_lib", 
        "errno.EINVAL", 
        "errno.EPERM", 
        "os", 
        "sys"
      ]
    }, 
    "rexec": {
      "file": "rexec.py", 
      "imports": [
        "__builtin__", 
        "code", 
        "getopt", 
        "ihooks", 
        "imp", 
        "os", 
        "readline", 
        "sys", 
        "traceback", 
        "warnings"
      ]
    }, 
    "rfc822": {
      "file": "rfc822.py", 
      "imports": [
        "os", 
        "sys", 
        "time", 
        "warnings"
      ]
    }, 
    "rlcompleter": {
      "file": "rlcompleter.py", 
      "imports": [
        "__builtin__", 
        "__main__", 
        "keyword", 
        "re", 
        "readline"
      ]
    }, 
    "robotparser": {
      "file": "robotparser.py", 
      "imports": [
        "time", 
        "urllib", 
        "urlparse"
      ]
    }, 
    "runpy": {
      "file": "runpy.py", 
      "imports": [
        "imp", 
        "imp.get_loader", 
        "pkgutil", 
        "sys"
      ]
    }, 
    "sched": {
      "file": "sched.py", 
      "imports": [
        "collections", 
        "heapq"
      ]
    }, 
    "sets": {
      "file": "sets.py", 
      "imports": [
        "copy", 
        "itertools.ifilter", 
        "itertools.ifilterfalse", 
        "warnings"
      ]
    }, 
    "sgmllib": {
      "file": "sgmllib.py", 
      "imports": [
        "markupbase", 
        "re", 
        "sys", 
        "warnings"
      ]
    }, 
    "sha": {
      "file": "sha.py", 
      "imports": [
        "hashlib", 
        "warnings"
      ]
    }, 
    "shelve": {
      "file": "shelve.py", 
      "imports": [
        "anydbm", 
        "cStringIO.StringIO", 
        "pickle", 
        "StringIO", 
        "UserDict", 
        "cPickle"
      ]
    }, 
    "shlex": {
      "file": "shlex.py", 
      "imports": [
        "cStringIO.StringIO", 
        "collections", 
        "os", 
        "sys", 
        "StringIO"
      ]
    }, 
    "shutil": {
      "file": "shutil.py", 
      "imports": [
        "collections", 
        "distutils.errors", 
        "distutils.spawn", 
        "errno", 
        "fnmatch", 
        "os", 
        "sys", 
        "stat", 
        "tarfile", 
        "zipfile", 
        "grp", 
        "pwd"
      ]
    }, 
    "site": {
      "file": "site.py", 
      "imports": [
        "__builtin__", 
        "codecs", 
        "distutils.sysconfig", 
        "encodings", 
        "exceptions", 
        "locale", 
        "os", 
        "pydoc", 
        "sitecustomize", 
        "sys", 
        "usercustomize", 
        "zipimport", 
        "sysconfig", 
        "textwrap", 
        "traceback"
      ]
    }, 
    "smtpd": {
      "file": "smtpd.py", 
      "imports": [
        "Mailman.MailList", 
        "Mailman.Message", 
        "Mailman.Utils", 
        "__main__", 
        "asynchat", 
        "asyncore", 
        "cStringIO.StringIO", 
        "errno", 
        "getopt", 
        "os", 
        "sys", 
        "time", 
        "smtplib", 
        "socket", 
        "pwd"
      ]
    }, 
    "smtplib": {
      "file": "smtplib.py", 
      "imports": [
        "base64", 
        "email.base64mime", 
        "email.utils", 
        "hmac", 
        "re", 
        "ssl", 
        "sys", 
        "sys.stderr", 
        "socket"
      ]
    }, 
    "sndhdr": {
      "file": "sndhdr.py", 
      "imports": [
        "aifc", 
        "glob", 
        "os", 
        "sys"
      ]
    }, 
    "socket": {
      "file": "socket.py", 
      "imports": [
        "_socket", 
        "_socket.*", 
        "_ssl", 
        "_ssl.RAND_add", 
        "_ssl.RAND_egd", 
        "_ssl.RAND_status", 
        "_ssl.SSLError", 
        "_ssl.SSL_ERROR_EOF", 
        "_ssl.SSL_ERROR_INVALID_ERROR_CODE", 
        "_ssl.SSL_ERROR_SSL", 
        "_ssl.SSL_ERROR_SYSCALL", 
        "_ssl.SSL_ERROR_WANT_CONNECT", 
        "_ssl.SSL_ERROR_WANT_READ", 
        "_ssl.SSL_ERROR_WANT_WRITE", 
        "_ssl.SSL_ERROR_WANT_X509_LOOKUP", 
        "_ssl.SSL_ERROR_ZERO_RETURN", 
        "cStringIO.StringIO", 
        "errno", 
        "os", 
        "ssl", 
        "sys", 
        "StringIO", 
        "warnings"
      ]
    }, 
    "sqlite3": {
      "dir": "sqlite3"
    }, 
    "sqlite3.__init__": {
      "file": "sqlite3/__init__.py", 
      "imports": [
        "sqlite3.dbapi2"
      ]
    }, 
    "sqlite3.dbapi2": {
      "file": "sqlite3/dbapi2.py", 
      "imports": [
        "collections", 
        "time", 
        "_sqlite3", 
        "datetime"
      ]
    }, 
    "sqlite3.dump": {
      "file": "sqlite3/dump.py", 
      "imports": []
    }, 
    "sqlite3.test": {
      "dir": "sqlite3/test"
    }, 
    "sqlite3.test.__init__": {
      "file": "sqlite3/test/__init__.py", 
      "imports": []
    }, 
    "sqlite3.test.dbapi": {
      "file": "sqlite3/test/dbapi.py", 
      "imports": [
        "sqlite3", 
        "sys", 
        "threading", 
        "unittest"
      ]
    }, 
    "sqlite3.test.dump": {
      "file": "sqlite3/test/dump.py", 
      "imports": [
        "sqlite3", 
        "unittest"
      ]
    }, 
    "sqlite3.test.factory": {
      "file": "sqlite3/test/factory.py", 
      "imports": [
        "collections", 
        "sqlite3", 
        "unittest"
      ]
    }, 
    "sqlite3.test.hooks": {
      "file": "sqlite3/test/hooks.py", 
      "imports": [
        "os", 
        "sqlite3", 
        "unittest"
      ]
    }, 
    "sqlite3.test.py25tests": {
      "file": "sqlite3/test/py25tests.py", 
      "imports": [
        "__future__", 
        "sqlite3", 
        "unittest"
      ]
    }, 
    "sqlite3.test.regression": {
      "file": "sqlite3/test/regression.py", 
      "imports": [
        "sqlite3", 
        "unittest", 
        "datetime"
      ]
    }, 
    "sqlite3.test.transactions": {
      "file": "sqlite3/test/transactions.py", 
      "imports": [
        "os", 
        "sqlite3", 
        "sys", 
        "unittest"
      ]
    }, 
    "sqlite3.test.types": {
      "file": "sqlite3/test/types.py", 
      "imports": [
        "sqlite3", 
        "zlib", 
        "unittest", 
        "datetime"
      ]
    }, 
    "sqlite3.test.userfunctions": {
      "file": "sqlite3/test/userfunctions.py", 
      "imports": [
        "sqlite3", 
        "unittest"
      ]
    }, 
    "sre": {
      "file": "sre.py", 
      "imports": [
        "re", 
        "warnings"
      ]
    }, 
    "sre_compile": {
      "file": "sre_compile.py", 
      "imports": [
        "_sre", 
        "array", 
        "sys", 
        "sre_constants", 
        "sre_parse"
      ]
    }, 
    "sre_constants": {
      "file": "sre_constants.py", 
      "imports": [
        "_sre", 
        "_sre.MAXREPEAT"
      ]
    }, 
    "sre_parse": {
      "file": "sre_parse.py", 
      "imports": [
        "__pypy__.newdict", 
        "sre_constants", 
        "sys"
      ]
    }, 
    "stackless": {
      "file": "stackless.py", 
      "imports": [
        "_continuation", 
        "collections", 
        "operator", 
        "threading.local"
      ]
    }, 
    "stat": {
      "file": "stat.py", 
      "imports": []
    }, 
    "statvfs": {
      "file": "statvfs.py", 
      "imports": [
        "warnings"
      ]
    }, 
    "string": {
      "file": "string.py", 
      "imports": [
        "re", 
        "strop.lowercase", 
        "strop.maketrans", 
        "strop.uppercase", 
        "strop.whitespace"
      ]
    }, 
    "stringold": {
      "file": "stringold.py", 
      "imports": [
        "stringold", 
        "strop.lowercase", 
        "strop.maketrans", 
        "strop.uppercase", 
        "strop.whitespace", 
        "warnings"
      ]
    }, 
    "stringprep": {
      "file": "stringprep.py", 
      "imports": [
        "unicodedata.ucd_3_2_0"
      ]
    }, 
    "struct": {
      "file": "struct.py", 
      "imports": [
        "_struct.*", 
        "_struct.__doc__", 
        "_struct._clearcache"
      ]
    }, 
    "symbol": {
      "file": "symbol.py", 
      "imports": [
        "sys", 
        "token"
      ]
    }, 
    "sysconfig": {
      "file": "sysconfig.py", 
      "imports": [
        "_osx_support", 
        "imp", 
        "os", 
        "pprint", 
        "re", 
        "sys"
      ]
    }, 
    "syslog": {
      "file": "syslog.py", 
      "imports": [
        "__pypy__.builtinify", 
        "cffi.FFI", 
        "sys"
      ]
    }, 
    "tabnanny": {
      "file": "tabnanny.py", 
      "imports": [
        "getopt", 
        "os", 
        "sys", 
        "tokenize"
      ]
    }, 
    "tarfile": {
      "file": "tarfile.py", 
      "imports": [
        "StringIO", 
        "bz2", 
        "cStringIO.StringIO", 
        "calendar", 
        "copy", 
        "errno", 
        "gzip", 
        "operator", 
        "os", 
        "re", 
        "shutil", 
        "stat", 
        "struct", 
        "sys", 
        "time", 
        "zlib", 
        "warnings", 
        "grp", 
        "pwd"
      ]
    }, 
    "telnetlib": {
      "file": "telnetlib.py", 
      "imports": [
        "errno", 
        "re", 
        "select", 
        "socket", 
        "sys", 
        "thread", 
        "time.time"
      ]
    }, 
    "tempfile": {
      "file": "tempfile.py", 
      "imports": [
        "StringIO", 
        "cStringIO.StringIO", 
        "dummy_thread", 
        "errno", 
        "fcntl", 
        "io", 
        "os", 
        "random", 
        "thread"
      ]
    }, 
    "test": {
      "dir": "test"
    }, 
    "test.__init__": {
      "file": "test/__init__.py", 
      "imports": []
    }, 
    "test.audiotests": {
      "file": "test/audiotests.py", 
      "imports": [
        "array", 
        "base64", 
        "io", 
        "pickle", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.autotest": {
      "file": "test/autotest.py", 
      "imports": [
        "test.regrtest"
      ]
    }, 
    "test.bad_coding": {
      "file": "test/bad_coding.py", 
      "imports": []
    }, 
    "test.bad_coding2": {
      "file": "test/bad_coding2.py", 
      "imports": []
    }, 
    "test.bad_coding3": {
      "file": "test/bad_coding3.py", 
      "imports": []
    }, 
    "test.badsyntax_future3": {
      "file": "test/badsyntax_future3.py", 
      "imports": [
        "__future__"
      ]
    }, 
    "test.badsyntax_future4": {
      "file": "test/badsyntax_future4.py", 
      "imports": [
        "__future__"
      ]
    }, 
    "test.badsyntax_future5": {
      "file": "test/badsyntax_future5.py", 
      "imports": [
        "__future__", 
        "foo"
      ]
    }, 
    "test.badsyntax_future6": {
      "file": "test/badsyntax_future6.py", 
      "imports": [
        "__future__"
      ]
    }, 
    "test.badsyntax_future7": {
      "file": "test/badsyntax_future7.py", 
      "imports": [
        "__future__", 
        "string"
      ]
    }, 
    "test.badsyntax_future8": {
      "file": "test/badsyntax_future8.py", 
      "imports": [
        "__future__"
      ]
    }, 
    "test.badsyntax_future9": {
      "file": "test/badsyntax_future9.py", 
      "imports": [
        "__future__"
      ]
    }, 
    "test.badsyntax_nocaret": {
      "file": "test/badsyntax_nocaret.py", 
      "imports": []
    }, 
    "test.buffer_tests": {
      "file": "test/buffer_tests.py", 
      "imports": [
        "struct", 
        "sys"
      ]
    }, 
    "test.curses_tests": {
      "file": "test/curses_tests.py", 
      "imports": [
        "curses", 
        "curses.textpad"
      ]
    }, 
    "test.doctest_aliases": {
      "file": "test/doctest_aliases.py", 
      "imports": []
    }, 
    "test.double_const": {
      "file": "test/double_const.py", 
      "imports": [
        "test.test_support"
      ]
    }, 
    "test.fork_wait": {
      "file": "test/fork_wait.py", 
      "imports": [
        "os", 
        "sys", 
        "test.test_support", 
        "time", 
        "unittest"
      ]
    }, 
    "test.gdb_sample": {
      "file": "test/gdb_sample.py", 
      "imports": []
    }, 
    "test.infinite_reload": {
      "file": "test/infinite_reload.py", 
      "imports": [
        "imp", 
        "test.infinite_reload"
      ]
    }, 
    "test.inspect_fodder": {
      "file": "test/inspect_fodder.py", 
      "imports": [
        "inspect", 
        "sys"
      ]
    }, 
    "test.inspect_fodder2": {
      "file": "test/inspect_fodder2.py", 
      "imports": []
    }, 
    "test.leakers": {
      "dir": "test/leakers"
    }, 
    "test.leakers.__init__": {
      "file": "test/leakers/__init__.py", 
      "imports": []
    }, 
    "test.leakers.test_ctypes": {
      "file": "test/leakers/test_ctypes.py", 
      "imports": [
        "ctypes.POINTER", 
        "ctypes.Structure", 
        "ctypes.c_int", 
        "gc"
      ]
    }, 
    "test.leakers.test_dictself": {
      "file": "test/leakers/test_dictself.py", 
      "imports": [
        "gc"
      ]
    }, 
    "test.leakers.test_gestalt": {
      "file": "test/leakers/test_gestalt.py", 
      "imports": [
        "MacOS", 
        "gestalt.gestalt", 
        "sys"
      ]
    }, 
    "test.leakers.test_selftype": {
      "file": "test/leakers/test_selftype.py", 
      "imports": [
        "gc"
      ]
    }, 
    "test.list_tests": {
      "file": "test/list_tests.py", 
      "imports": [
        "os", 
        "sys", 
        "test.seq_tests", 
        "test.test_support"
      ]
    }, 
    "test.lock_tests": {
      "file": "test/lock_tests.py", 
      "imports": [
        "sys", 
        "test.test_support", 
        "thread.get_ident", 
        "thread.start_new_thread", 
        "threading", 
        "time", 
        "unittest"
      ]
    }, 
    "test.mapping_tests": {
      "file": "test/mapping_tests.py", 
      "imports": [
        "test.test_support", 
        "unittest", 
        "UserDict"
      ]
    }, 
    "test.mp_fork_bomb": {
      "file": "test/mp_fork_bomb.py", 
      "imports": [
        "multiprocessing"
      ]
    }, 
    "test.outstanding_bugs": {
      "file": "test/outstanding_bugs.py", 
      "imports": [
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.pickletester": {
      "file": "test/pickletester.py", 
      "imports": [
        "StringIO", 
        "__main__", 
        "cStringIO", 
        "copy_reg", 
        "locale", 
        "os", 
        "pickle", 
        "pickletools", 
        "sys", 
        "test.test_support", 
        "time", 
        "unittest", 
        "cPickle"
      ]
    }, 
    "test.profilee": {
      "file": "test/profilee.py", 
      "imports": [
        "sys"
      ]
    }, 
    "test.pyclbr_input": {
      "file": "test/pyclbr_input.py", 
      "imports": []
    }, 
    "test.pydoc_mod": {
      "file": "test/pydoc_mod.py", 
      "imports": []
    }, 
    "test.pydocfodder": {
      "file": "test/pydocfodder.py", 
      "imports": [
        "types"
      ]
    }, 
    "test.pystone": {
      "file": "test/pystone.py", 
      "imports": [
        "sys", 
        "time.time"
      ]
    }, 
    "test.re_tests": {
      "file": "test/re_tests.py", 
      "imports": []
    }, 
    "test.regrtest": {
      "file": "test/regrtest.py", 
      "imports": [
        "Queue", 
        "StringIO", 
        "_abcoll", 
        "_pyio", 
        "_strptime", 
        "copy_reg", 
        "ctypes", 
        "distutils.dir_util", 
        "doctest", 
        "filecmp", 
        "gc", 
        "getopt", 
        "imp", 
        "json", 
        "linecache", 
        "mimetypes", 
        "os", 
        "platform", 
        "random", 
        "re", 
        "shutil", 
        "stat", 
        "struct", 
        "subprocess.PIPE", 
        "subprocess.Popen", 
        "sys", 
        "sysconfig", 
        "tempfile", 
        "test.test_support", 
        "test.test_timeout", 
        "threading.Thread", 
        "time", 
        "zipimport", 
        "textwrap", 
        "trace", 
        "traceback", 
        "unittest", 
        "urllib", 
        "urllib2", 
        "urlparse", 
        "warnings", 
        "resource"
      ]
    }, 
    "test.relimport": {
      "file": "test/relimport.py", 
      "imports": [
        "test.test_import"
      ]
    }, 
    "test.reperf": {
      "file": "test/reperf.py", 
      "imports": [
        "re", 
        "time"
      ]
    }, 
    "test.sample_doctest": {
      "file": "test/sample_doctest.py", 
      "imports": [
        "doctest"
      ]
    }, 
    "test.sample_doctest_no_docstrings": {
      "file": "test/sample_doctest_no_docstrings.py", 
      "imports": []
    }, 
    "test.sample_doctest_no_doctests": {
      "file": "test/sample_doctest_no_doctests.py", 
      "imports": []
    }, 
    "test.script_helper": {
      "file": "test/script_helper.py", 
      "imports": [
        "contextlib", 
        "os", 
        "py_compile", 
        "re", 
        "shutil", 
        "subprocess", 
        "sys", 
        "tempfile", 
        "test.test_support", 
        "zipfile"
      ]
    }, 
    "test.seq_tests": {
      "file": "test/seq_tests.py", 
      "imports": [
        "itertools.chain", 
        "itertools.imap", 
        "sys", 
        "unittest"
      ]
    }, 
    "test.sortperf": {
      "file": "test/sortperf.py", 
      "imports": [
        "marshal", 
        "os", 
        "random", 
        "sys", 
        "tempfile", 
        "time"
      ]
    }, 
    "test.string_tests": {
      "file": "test/string_tests.py", 
      "imports": [
        "string", 
        "struct", 
        "sys", 
        "test.test_support", 
        "zlib", 
        "unittest", 
        "UserList", 
        "_testcapi"
      ]
    }, 
    "test.symlink_support": {
      "file": "test/symlink_support.py", 
      "imports": [
        "ctypes.wintypes", 
        "os", 
        "platform", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_MimeWriter": {
      "file": "test/test_MimeWriter.py", 
      "imports": [
        "MimeWriter", 
        "StringIO", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_SimpleHTTPServer": {
      "file": "test/test_SimpleHTTPServer.py", 
      "imports": [
        "SimpleHTTPServer", 
        "os", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_StringIO": {
      "file": "test/test_StringIO.py", 
      "imports": [
        "StringIO", 
        "array", 
        "cStringIO", 
        "sys", 
        "test.test_support", 
        "types", 
        "unittest"
      ]
    }, 
    "test.test___all__": {
      "file": "test/test___all__.py", 
      "imports": [
        "__future__", 
        "_socket", 
        "locale", 
        "os", 
        "rlcompleter", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test___future__": {
      "file": "test/test___future__.py", 
      "imports": [
        "__future__", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test__locale": {
      "file": "test/test__locale.py", 
      "imports": [
        "_locale.Error", 
        "_locale.LC_NUMERIC", 
        "_locale.RADIXCHAR", 
        "_locale.THOUSEP", 
        "_locale.localeconv", 
        "_locale.nl_langinfo", 
        "_locale.setlocale", 
        "platform", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test__osx_support": {
      "file": "test/test__osx_support.py", 
      "imports": [
        "_osx_support", 
        "os", 
        "platform", 
        "shutil", 
        "stat", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_abc": {
      "file": "test/test_abc.py", 
      "imports": [
        "abc", 
        "inspect", 
        "test.test_support", 
        "unittest", 
        "weakref"
      ]
    }, 
    "test.test_abstract_numbers": {
      "file": "test/test_abstract_numbers.py", 
      "imports": [
        "math", 
        "numbers", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_aepack": {
      "file": "test/test_aepack.py", 
      "imports": [
        "Carbon.File", 
        "os", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_aifc": {
      "file": "test/test_aifc.py", 
      "imports": [
        "aifc", 
        "io", 
        "os", 
        "struct", 
        "sys", 
        "test.audiotests", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_al": {
      "file": "test/test_al.py", 
      "imports": [
        "test.test_support"
      ]
    }, 
    "test.test_anydbm": {
      "file": "test/test_anydbm.py", 
      "imports": [
        "glob", 
        "os", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_applesingle": {
      "file": "test/test_applesingle.py", 
      "imports": [
        "applesingle", 
        "os", 
        "struct", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_argparse": {
      "file": "test/test_argparse.py", 
      "imports": [
        "StringIO", 
        "argparse", 
        "codecs", 
        "gc", 
        "inspect", 
        "os", 
        "shutil", 
        "stat", 
        "sys", 
        "tempfile", 
        "test.test_support", 
        "textwrap", 
        "unittest"
      ]
    }, 
    "test.test_array": {
      "file": "test/test_array.py", 
      "imports": [
        "array", 
        "cStringIO", 
        "copy", 
        "gc", 
        "sys", 
        "sys.maxsize", 
        "test.test_support", 
        "unittest", 
        "warnings", 
        "weakref", 
        "cPickle"
      ]
    }, 
    "test.test_ascii_formatd": {
      "file": "test/test_ascii_formatd.py", 
      "imports": [
        "ctypes.byref", 
        "ctypes.c_double", 
        "ctypes.create_string_buffer", 
        "ctypes.pythonapi", 
        "ctypes.sizeof", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_ast": {
      "file": "test/test_ast.py", 
      "imports": [
        "ast", 
        "itertools", 
        "pickle", 
        "sys", 
        "test.test_support", 
        "unittest", 
        "cPickle"
      ]
    }, 
    "test.test_asynchat": {
      "file": "test/test_asynchat.py", 
      "imports": [
        "asynchat", 
        "asyncore", 
        "socket", 
        "sys", 
        "test.test_support", 
        "threading", 
        "time", 
        "unittest"
      ]
    }, 
    "test.test_asyncore": {
      "file": "test/test_asyncore.py", 
      "imports": [
        "StringIO", 
        "asyncore", 
        "errno", 
        "os", 
        "select", 
        "socket", 
        "struct", 
        "sys", 
        "test.test_support", 
        "threading", 
        "time", 
        "unittest", 
        "warnings"
      ]
    }, 
    "test.test_atexit": {
      "file": "test/test_atexit.py", 
      "imports": [
        "StringIO", 
        "atexit", 
        "imp.reload", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_audioop": {
      "file": "test/test_audioop.py", 
      "imports": [
        "audioop", 
        "struct", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_augassign": {
      "file": "test/test_augassign.py", 
      "imports": [
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_base64": {
      "file": "test/test_base64.py", 
      "imports": [
        "base64", 
        "cStringIO.StringIO", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_bastion": {
      "file": "test/test_bastion.py", 
      "imports": []
    }, 
    "test.test_bigaddrspace": {
      "file": "test/test_bigaddrspace.py", 
      "imports": [
        "operator", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_bigmem": {
      "file": "test/test_bigmem.py", 
      "imports": [
        "operator", 
        "string", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_binascii": {
      "file": "test/test_binascii.py", 
      "imports": [
        "array", 
        "binascii", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_binhex": {
      "file": "test/test_binhex.py", 
      "imports": [
        "binhex", 
        "os", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_binop": {
      "file": "test/test_binop.py", 
      "imports": [
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_bisect": {
      "file": "test/test_bisect.py", 
      "imports": [
        "bisect", 
        "gc", 
        "random", 
        "sys", 
        "test.test_bisect", 
        "test.test_support", 
        "unittest", 
        "UserList"
      ]
    }, 
    "test.test_bool": {
      "file": "test/test_bool.py", 
      "imports": [
        "marshal", 
        "operator", 
        "os", 
        "pickle", 
        "test.test_support", 
        "unittest", 
        "cPickle"
      ]
    }, 
    "test.test_bsddb": {
      "file": "test/test_bsddb.py", 
      "imports": [
        "os", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_bsddb185": {
      "file": "test/test_bsddb185.py", 
      "imports": [
        "anydbm", 
        "os", 
        "shutil", 
        "tempfile", 
        "test.test_support", 
        "unittest", 
        "whichdb"
      ]
    }, 
    "test.test_bsddb3": {
      "file": "test/test_bsddb3.py", 
      "imports": [
        "bsddb.db", 
        "bsddb.test.test_all", 
        "os", 
        "sys", 
        "tempfile", 
        "test.test_support", 
        "time", 
        "unittest"
      ]
    }, 
    "test.test_buffer": {
      "file": "test/test_buffer.py", 
      "imports": [
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_bufio": {
      "file": "test/test_bufio.py", 
      "imports": [
        "_pyio", 
        "io", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_builtin": {
      "file": "test/test_builtin.py", 
      "imports": [
        "cStringIO", 
        "gc", 
        "marshal", 
        "math.sqrt", 
        "operator.neg", 
        "os", 
        "platform", 
        "random", 
        "string", 
        "sys", 
        "test.test_support", 
        "types", 
        "unittest", 
        "UserDict", 
        "UserList", 
        "warnings"
      ]
    }, 
    "test.test_bytes": {
      "file": "test/test_bytes.py", 
      "imports": [
        "copy", 
        "functools", 
        "os", 
        "pickle", 
        "re", 
        "sys", 
        "tempfile", 
        "test.buffer_tests", 
        "test.string_tests", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_bz2": {
      "file": "test/test_bz2.py", 
      "imports": [
        "bz2.BZ2Compressor", 
        "bz2.BZ2Decompressor", 
        "bz2.BZ2File", 
        "cStringIO.StringIO", 
        "os", 
        "subprocess", 
        "sys", 
        "test.test_support", 
        "threading", 
        "unittest"
      ]
    }, 
    "test.test_calendar": {
      "file": "test/test_calendar.py", 
      "imports": [
        "calendar", 
        "locale", 
        "test.test_support", 
        "unittest", 
        "datetime"
      ]
    }, 
    "test.test_call": {
      "file": "test/test_call.py", 
      "imports": [
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_capi": {
      "file": "test/test_capi.py", 
      "imports": [
        "__future__", 
        "random", 
        "sys", 
        "test.test_support", 
        "thread", 
        "threading", 
        "time", 
        "unittest"
      ]
    }, 
    "test.test_cd": {
      "file": "test/test_cd.py", 
      "imports": [
        "test.test_support"
      ]
    }, 
    "test.test_cfgparser": {
      "file": "test/test_cfgparser.py", 
      "imports": [
        "ConfigParser", 
        "StringIO", 
        "os", 
        "pickle", 
        "test.test_support", 
        "unittest", 
        "UserDict"
      ]
    }, 
    "test.test_cgi": {
      "file": "test/test_cgi.py", 
      "imports": [
        "StringIO", 
        "cStringIO.StringIO", 
        "cgi", 
        "collections", 
        "os", 
        "sys", 
        "tempfile", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_charmapcodec": {
      "file": "test/test_charmapcodec.py", 
      "imports": [
        "codecs", 
        "test.test_support", 
        "test.testcodec", 
        "unittest"
      ]
    }, 
    "test.test_cl": {
      "file": "test/test_cl.py", 
      "imports": [
        "test.test_support"
      ]
    }, 
    "test.test_class": {
      "file": "test/test_class.py", 
      "imports": [
        "gc", 
        "test.test_support", 
        "unittest", 
        "_testcapi"
      ]
    }, 
    "test.test_cmath": {
      "file": "test/test_cmath.py", 
      "imports": [
        "cmath", 
        "cmath.phase", 
        "cmath.pi", 
        "cmath.polar", 
        "cmath.rect", 
        "math", 
        "test.test_math", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_cmd": {
      "file": "test/test_cmd.py", 
      "imports": [
        "StringIO", 
        "cmd", 
        "re", 
        "sys", 
        "test.test_cmd", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_cmd_line": {
      "file": "test/test_cmd_line.py", 
      "imports": [
        "sys", 
        "test.script_helper", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_cmd_line_script": {
      "file": "test/test_cmd_line_script.py", 
      "imports": [
        "os", 
        "test.script_helper", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_code": {
      "file": "test/test_code.py", 
      "imports": [
        "test.test_code", 
        "test.test_support", 
        "unittest", 
        "weakref", 
        "_testcapi"
      ]
    }, 
    "test.test_codeccallbacks": {
      "file": "test/test_codeccallbacks.py", 
      "imports": [
        "codecs", 
        "htmlentitydefs", 
        "sys", 
        "test.test_support", 
        "unicodedata", 
        "unittest"
      ]
    }, 
    "test.test_codecencodings_cn": {
      "file": "test/test_codecencodings_cn.py", 
      "imports": [
        "test.test_multibytecodec_support", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_codecencodings_hk": {
      "file": "test/test_codecencodings_hk.py", 
      "imports": [
        "test.test_multibytecodec_support", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_codecencodings_iso2022": {
      "file": "test/test_codecencodings_iso2022.py", 
      "imports": [
        "test.test_multibytecodec_support", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_codecencodings_jp": {
      "file": "test/test_codecencodings_jp.py", 
      "imports": [
        "test.test_multibytecodec_support", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_codecencodings_kr": {
      "file": "test/test_codecencodings_kr.py", 
      "imports": [
        "test.test_multibytecodec_support", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_codecencodings_tw": {
      "file": "test/test_codecencodings_tw.py", 
      "imports": [
        "test.test_multibytecodec_support", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_codecmaps_cn": {
      "file": "test/test_codecmaps_cn.py", 
      "imports": [
        "test.test_multibytecodec_support", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_codecmaps_hk": {
      "file": "test/test_codecmaps_hk.py", 
      "imports": [
        "test.test_multibytecodec_support", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_codecmaps_jp": {
      "file": "test/test_codecmaps_jp.py", 
      "imports": [
        "test.test_multibytecodec_support", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_codecmaps_kr": {
      "file": "test/test_codecmaps_kr.py", 
      "imports": [
        "test.test_multibytecodec_support", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_codecmaps_tw": {
      "file": "test/test_codecmaps_tw.py", 
      "imports": [
        "test.test_multibytecodec_support", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_codecs": {
      "file": "test/test_codecs.py", 
      "imports": [
        "StringIO", 
        "array", 
        "bz2", 
        "codecs", 
        "encodings.cp1140", 
        "encodings.idna", 
        "locale", 
        "sys", 
        "test.test_support", 
        "zlib", 
        "unittest", 
        "_testcapi"
      ]
    }, 
    "test.test_codeop": {
      "file": "test/test_codeop.py", 
      "imports": [
        "cStringIO", 
        "codeop", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_coding": {
      "file": "test/test_coding.py", 
      "imports": [
        "os", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_coercion": {
      "file": "test/test_coercion.py", 
      "imports": [
        "copy", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_collections": {
      "file": "test/test_collections.py", 
      "imports": [
        "collections", 
        "copy", 
        "doctest", 
        "inspect", 
        "keyword", 
        "operator", 
        "pickle", 
        "random", 
        "re", 
        "sets", 
        "string", 
        "sys", 
        "test.mapping_tests", 
        "test.test_support", 
        "unittest", 
        "cPickle"
      ]
    }, 
    "test.test_colorsys": {
      "file": "test/test_colorsys.py", 
      "imports": [
        "colorsys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_commands": {
      "file": "test/test_commands.py", 
      "imports": [
        "os", 
        "re", 
        "tempfile", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_compare": {
      "file": "test/test_compare.py", 
      "imports": [
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_compile": {
      "file": "test/test_compile.py", 
      "imports": [
        "__builtin__", 
        "__mangled_mod", 
        "__package__.module", 
        "_ast", 
        "math", 
        "sys", 
        "test.test_support", 
        "textwrap", 
        "unittest"
      ]
    }, 
    "test.test_compileall": {
      "file": "test/test_compileall.py", 
      "imports": [
        "compileall", 
        "imp", 
        "os", 
        "py_compile", 
        "shutil", 
        "struct", 
        "tempfile", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_compiler": {
      "file": "test/test_compiler.py", 
      "imports": [
        "StringIO", 
        "compiler.ast", 
        "math.*", 
        "os", 
        "random", 
        "sys", 
        "test.test_support", 
        "time", 
        "unittest"
      ]
    }, 
    "test.test_complex": {
      "file": "test/test_complex.py", 
      "imports": [
        "math.atan2", 
        "math.copysign", 
        "math.isnan", 
        "random", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_complex_args": {
      "file": "test/test_complex_args.py", 
      "imports": [
        "test.test_support", 
        "textwrap", 
        "unittest"
      ]
    }, 
    "test.test_contains": {
      "file": "test/test_contains.py", 
      "imports": [
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_contextlib": {
      "file": "test/test_contextlib.py", 
      "imports": [
        "contextlib", 
        "sys", 
        "tempfile", 
        "test.test_support", 
        "threading", 
        "unittest"
      ]
    }, 
    "test.test_cookie": {
      "file": "test/test_cookie.py", 
      "imports": [
        "Cookie", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_cookielib": {
      "file": "test/test_cookielib.py", 
      "imports": [
        "StringIO", 
        "cookielib", 
        "mimetools", 
        "os", 
        "re", 
        "test.test_support", 
        "time", 
        "traceback", 
        "unittest", 
        "urllib2"
      ]
    }, 
    "test.test_copy": {
      "file": "test/test_copy.py", 
      "imports": [
        "copy", 
        "copy_reg", 
        "test.test_support", 
        "unittest", 
        "weakref"
      ]
    }, 
    "test.test_copy_reg": {
      "file": "test/test_copy_reg.py", 
      "imports": [
        "copy", 
        "copy_reg", 
        "test.pickletester", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_cpickle": {
      "file": "test/test_cpickle.py", 
      "imports": [
        "cStringIO", 
        "io", 
        "test.pickletester", 
        "test.test_support", 
        "unittest", 
        "cPickle"
      ]
    }, 
    "test.test_cprofile": {
      "file": "test/test_cprofile.py", 
      "imports": [
        "_lsprof", 
        "cProfile", 
        "sys", 
        "test.test_profile", 
        "test.test_support"
      ]
    }, 
    "test.test_crypt": {
      "file": "test/test_crypt.py", 
      "imports": [
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_csv": {
      "file": "test/test_csv.py", 
      "imports": [
        "StringIO", 
        "array", 
        "csv", 
        "gc", 
        "io", 
        "itertools", 
        "os", 
        "string", 
        "sys", 
        "tempfile", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_ctypes": {
      "file": "test/test_ctypes.py", 
      "imports": [
        "ctypes.test", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_curses": {
      "file": "test/test_curses.py", 
      "imports": [
        "curses.ascii", 
        "os", 
        "sys", 
        "tempfile", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_datetime": {
      "file": "test/test_datetime.py", 
      "imports": [
        "__future__", 
        "_strptime", 
        "pickle", 
        "random", 
        "sys", 
        "test.test_support", 
        "time", 
        "unittest", 
        "cPickle", 
        "datetime"
      ]
    }, 
    "test.test_dbm": {
      "file": "test/test_dbm.py", 
      "imports": [
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_decimal": {
      "file": "test/test_decimal.py", 
      "imports": [
        "copy", 
        "decimal", 
        "locale", 
        "math", 
        "numbers", 
        "operator", 
        "optparse", 
        "os", 
        "pickle", 
        "random", 
        "sys", 
        "test.test_support", 
        "threading", 
        "unittest"
      ]
    }, 
    "test.test_decorators": {
      "file": "test/test_decorators.py", 
      "imports": [
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_defaultdict": {
      "file": "test/test_defaultdict.py", 
      "imports": [
        "collections", 
        "copy", 
        "os", 
        "tempfile", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_deque": {
      "file": "test/test_deque.py", 
      "imports": [
        "collections", 
        "copy", 
        "gc", 
        "random", 
        "struct", 
        "sys", 
        "test.seq_tests", 
        "test.test_deque", 
        "test.test_support", 
        "unittest", 
        "weakref", 
        "cPickle"
      ]
    }, 
    "test.test_descr": {
      "file": "test/test_descr.py", 
      "imports": [
        "__builtin__", 
        "abc", 
        "binascii", 
        "cStringIO", 
        "copy", 
        "gc", 
        "operator", 
        "pickle", 
        "popen2", 
        "sys", 
        "test.test_support", 
        "xxsubtype", 
        "types", 
        "unittest", 
        "weakref", 
        "_testcapi", 
        "cPickle"
      ]
    }, 
    "test.test_descrtut": {
      "file": "test/test_descrtut.py", 
      "imports": [
        "pprint", 
        "test.test_descrtut", 
        "test.test_support"
      ]
    }, 
    "test.test_dict": {
      "file": "test/test_dict.py", 
      "imports": [
        "gc", 
        "random", 
        "string", 
        "test.mapping_tests", 
        "test.test_support", 
        "unittest", 
        "UserDict", 
        "weakref"
      ]
    }, 
    "test.test_dictcomps": {
      "file": "test/test_dictcomps.py", 
      "imports": [
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_dictviews": {
      "file": "test/test_dictviews.py", 
      "imports": [
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_difflib": {
      "file": "test/test_difflib.py", 
      "imports": [
        "difflib", 
        "doctest", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_dircache": {
      "file": "test/test_dircache.py", 
      "imports": [
        "os", 
        "sys", 
        "tempfile", 
        "test.test_support", 
        "time", 
        "unittest"
      ]
    }, 
    "test.test_dis": {
      "file": "test/test_dis.py", 
      "imports": [
        "StringIO", 
        "difflib", 
        "dis", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_distutils": {
      "file": "test/test_distutils.py", 
      "imports": [
        "distutils.tests", 
        "test.test_support"
      ]
    }, 
    "test.test_dl": {
      "file": "test/test_dl.py", 
      "imports": [
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_doctest": {
      "file": "test/test_doctest.py", 
      "imports": [
        "doctest", 
        "sys", 
        "test.test_doctest", 
        "test.test_support"
      ]
    }, 
    "test.test_doctest2": {
      "file": "test/test_doctest2.py", 
      "imports": [
        "doctest", 
        "sys", 
        "test.test_doctest2", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_docxmlrpc": {
      "file": "test/test_docxmlrpc.py", 
      "imports": [
        "DocXMLRPCServer", 
        "httplib", 
        "socket", 
        "sys", 
        "test.test_support", 
        "time", 
        "unittest"
      ]
    }, 
    "test.test_dumbdbm": {
      "file": "test/test_dumbdbm.py", 
      "imports": [
        "dumbdbm", 
        "os", 
        "random", 
        "stat", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_dummy_thread": {
      "file": "test/test_dummy_thread.py", 
      "imports": [
        "Queue", 
        "dummy_thread", 
        "random", 
        "test.test_support", 
        "time", 
        "unittest"
      ]
    }, 
    "test.test_dummy_threading": {
      "file": "test/test_dummy_threading.py", 
      "imports": [
        "dummy_threading", 
        "test.test_support", 
        "time", 
        "unittest"
      ]
    }, 
    "test.test_email": {
      "file": "test/test_email.py", 
      "imports": [
        "email.test.test_email", 
        "email.test.test_email_renamed", 
        "test.test_support"
      ]
    }, 
    "test.test_email_codecs": {
      "file": "test/test_email_codecs.py", 
      "imports": [
        "email.test.test_email_codecs", 
        "email.test.test_email_codecs_renamed", 
        "test.test_support"
      ]
    }, 
    "test.test_email_renamed": {
      "file": "test/test_email_renamed.py", 
      "imports": [
        "email.test.test_email_renamed", 
        "test.test_support"
      ]
    }, 
    "test.test_enumerate": {
      "file": "test/test_enumerate.py", 
      "imports": [
        "sys", 
        "test.test_iterlen", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_eof": {
      "file": "test/test_eof.py", 
      "imports": [
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_epoll": {
      "file": "test/test_epoll.py", 
      "imports": [
        "errno", 
        "select", 
        "socket", 
        "test.test_support", 
        "time", 
        "unittest"
      ]
    }, 
    "test.test_errno": {
      "file": "test/test_errno.py", 
      "imports": [
        "errno", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_exception_variations": {
      "file": "test/test_exception_variations.py", 
      "imports": [
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_exceptions": {
      "file": "test/test_exceptions.py", 
      "imports": [
        "exceptions", 
        "imp.reload", 
        "os", 
        "pickle", 
        "sys", 
        "test.test_pep352", 
        "test.test_support", 
        "unittest", 
        "_testcapi", 
        "cPickle"
      ]
    }, 
    "test.test_extcall": {
      "file": "test/test_extcall.py", 
      "imports": [
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_fcntl": {
      "file": "test/test_fcntl.py", 
      "imports": [
        "os", 
        "struct", 
        "sys", 
        "test.test_support", 
        "unittest", 
        "_testcapi"
      ]
    }, 
    "test.test_file": {
      "file": "test/test_file.py", 
      "imports": [
        "__future__", 
        "_pyio", 
        "array.array", 
        "io", 
        "os", 
        "sys", 
        "test.test_support", 
        "unittest", 
        "UserList", 
        "weakref"
      ]
    }, 
    "test.test_file2k": {
      "file": "test/test_file2k.py", 
      "imports": [
        "array.array", 
        "itertools", 
        "os", 
        "select", 
        "signal", 
        "subprocess", 
        "sys", 
        "test.test_support", 
        "threading", 
        "time", 
        "unittest", 
        "UserList", 
        "weakref"
      ]
    }, 
    "test.test_file_eintr": {
      "file": "test/test_file_eintr.py", 
      "imports": [
        "_io.FileIO", 
        "os", 
        "select", 
        "signal", 
        "subprocess", 
        "sys", 
        "test.test_support", 
        "time", 
        "unittest"
      ]
    }, 
    "test.test_filecmp": {
      "file": "test/test_filecmp.py", 
      "imports": [
        "filecmp", 
        "os", 
        "shutil", 
        "tempfile", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_fileinput": {
      "file": "test/test_fileinput.py", 
      "imports": [
        "StringIO", 
        "fileinput", 
        "re", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_fileio": {
      "file": "test/test_fileio.py", 
      "imports": [
        "__future__", 
        "_io.FileIO", 
        "array.array", 
        "errno", 
        "functools", 
        "msvcrt", 
        "os", 
        "sys", 
        "test.script_helper", 
        "test.test_support", 
        "unittest", 
        "UserList", 
        "weakref", 
        "_testcapi"
      ]
    }, 
    "test.test_float": {
      "file": "test/test_float.py", 
      "imports": [
        "fractions", 
        "locale", 
        "math", 
        "math.copysign", 
        "math.isinf", 
        "math.isnan", 
        "math.ldexp", 
        "operator", 
        "os", 
        "random", 
        "struct", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_fnmatch": {
      "file": "test/test_fnmatch.py", 
      "imports": [
        "fnmatch", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_fork1": {
      "file": "test/test_fork1.py", 
      "imports": [
        "imp", 
        "os", 
        "signal", 
        "sys", 
        "test.fork_wait", 
        "test.test_support", 
        "time"
      ]
    }, 
    "test.test_format": {
      "file": "test/test_format.py", 
      "imports": [
        "sys", 
        "test.test_support", 
        "unittest", 
        "_testcapi"
      ]
    }, 
    "test.test_fpformat": {
      "file": "test/test_fpformat.py", 
      "imports": [
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_fractions": {
      "file": "test/test_fractions.py", 
      "imports": [
        "copy", 
        "decimal", 
        "fractions", 
        "math", 
        "numbers", 
        "operator", 
        "sys", 
        "test.test_support", 
        "unittest", 
        "cPickle"
      ]
    }, 
    "test.test_frozen": {
      "file": "test/test_frozen.py", 
      "imports": [
        "__hello__", 
        "__phello__", 
        "__phello__.foo", 
        "__phello__.spam", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_ftplib": {
      "file": "test/test_ftplib.py", 
      "imports": [
        "StringIO", 
        "asynchat", 
        "asyncore", 
        "errno", 
        "ftplib", 
        "os", 
        "socket", 
        "ssl", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_funcattrs": {
      "file": "test/test_funcattrs.py", 
      "imports": [
        "test.test_support", 
        "types", 
        "unittest", 
        "UserDict"
      ]
    }, 
    "test.test_functools": {
      "file": "test/test_functools.py", 
      "imports": [
        "functools", 
        "gc", 
        "pickle", 
        "sys", 
        "test.test_support", 
        "unittest", 
        "weakref"
      ]
    }, 
    "test.test_future": {
      "file": "test/test_future.py", 
      "imports": [
        "re", 
        "test.badsyntax_future3", 
        "test.badsyntax_future4", 
        "test.badsyntax_future5", 
        "test.badsyntax_future6", 
        "test.badsyntax_future7", 
        "test.badsyntax_future8", 
        "test.badsyntax_future9", 
        "test.test_future1", 
        "test.test_future2", 
        "test.test_future3", 
        "test.test_future5", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_future1": {
      "file": "test/test_future1.py", 
      "imports": [
        "__future__"
      ]
    }, 
    "test.test_future2": {
      "file": "test/test_future2.py", 
      "imports": [
        "__future__", 
        "string"
      ]
    }, 
    "test.test_future3": {
      "file": "test/test_future3.py", 
      "imports": [
        "__future__", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_future4": {
      "file": "test/test_future4.py", 
      "imports": [
        "__future__", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_future5": {
      "file": "test/test_future5.py", 
      "imports": [
        "__future__", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_future_builtins": {
      "file": "test/test_future_builtins.py", 
      "imports": [
        "itertools.ifilter", 
        "itertools.imap", 
        "itertools.izip", 
        "test.test_support", 
        "unittest", 
        "future_builtins"
      ]
    }, 
    "test.test_gc": {
      "file": "test/test_gc.py", 
      "imports": [
        "gc", 
        "sys", 
        "test.test_support", 
        "threading", 
        "time", 
        "unittest", 
        "weakref"
      ]
    }, 
    "test.test_gdb": {
      "file": "test/test_gdb.py", 
      "imports": [
        "os", 
        "re", 
        "subprocess", 
        "sys", 
        "sysconfig", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_gdbm": {
      "file": "test/test_gdbm.py", 
      "imports": [
        "os", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_generators": {
      "file": "test/test_generators.py", 
      "imports": [
        "test.test_generators", 
        "test.test_support"
      ]
    }, 
    "test.test_genericpath": {
      "file": "test/test_genericpath.py", 
      "imports": [
        "genericpath", 
        "os", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_genexps": {
      "file": "test/test_genexps.py", 
      "imports": [
        "gc", 
        "sys", 
        "test.test_genexps", 
        "test.test_support"
      ]
    }, 
    "test.test_getargs": {
      "file": "test/test_getargs.py", 
      "imports": [
        "marshal", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_getargs2": {
      "file": "test/test_getargs2.py", 
      "imports": [
        "test.test_support", 
        "unittest", 
        "warnings", 
        "_testcapi"
      ]
    }, 
    "test.test_getopt": {
      "file": "test/test_getopt.py", 
      "imports": [
        "getopt", 
        "test.test_support", 
        "types", 
        "unittest"
      ]
    }, 
    "test.test_gettext": {
      "file": "test/test_gettext.py", 
      "imports": [
        "__builtin__", 
        "base64", 
        "gettext", 
        "os", 
        "shutil", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_gl": {
      "file": "test/test_gl.py", 
      "imports": [
        "os", 
        "test.test_support", 
        "time", 
        "unittest"
      ]
    }, 
    "test.test_glob": {
      "file": "test/test_glob.py", 
      "imports": [
        "glob", 
        "os", 
        "shutil", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_global": {
      "file": "test/test_global.py", 
      "imports": [
        "test.test_support", 
        "unittest", 
        "warnings"
      ]
    }, 
    "test.test_grammar": {
      "file": "test/test_grammar.py", 
      "imports": [
        "StringIO", 
        "sys", 
        "sys.*", 
        "sys.argv", 
        "sys.maxint", 
        "sys.path", 
        "test.test_support", 
        "time", 
        "time.time", 
        "types", 
        "unittest"
      ]
    }, 
    "test.test_grp": {
      "file": "test/test_grp.py", 
      "imports": [
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_gzip": {
      "file": "test/test_gzip.py", 
      "imports": [
        "io", 
        "os", 
        "struct", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_hash": {
      "file": "test/test_hash.py", 
      "imports": [
        "collections", 
        "os", 
        "struct", 
        "subprocess", 
        "sys", 
        "test.test_support", 
        "unittest", 
        "datetime"
      ]
    }, 
    "test.test_hashlib": {
      "file": "test/test_hashlib.py", 
      "imports": [
        "_md5", 
        "array", 
        "binascii.unhexlify", 
        "hashlib", 
        "itertools", 
        "string", 
        "sys", 
        "test.test_support", 
        "threading", 
        "unittest", 
        "warnings"
      ]
    }, 
    "test.test_heapq": {
      "file": "test/test_heapq.py", 
      "imports": [
        "gc", 
        "itertools.chain", 
        "itertools.imap", 
        "random", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_hmac": {
      "file": "test/test_hmac.py", 
      "imports": [
        "hashlib", 
        "hmac", 
        "test.test_support", 
        "unittest", 
        "warnings"
      ]
    }, 
    "test.test_hotshot": {
      "file": "test/test_hotshot.py", 
      "imports": [
        "_hotshot", 
        "gc", 
        "hotshot.log.ENTER", 
        "hotshot.log.EXIT", 
        "hotshot.log.LINE", 
        "hotshot.stats", 
        "os", 
        "pprint", 
        "sys", 
        "tempfile", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_htmllib": {
      "file": "test/test_htmllib.py", 
      "imports": [
        "formatter", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_htmlparser": {
      "file": "test/test_htmlparser.py", 
      "imports": [
        "HTMLParser", 
        "pprint", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_httplib": {
      "file": "test/test_httplib.py", 
      "imports": [
        "StringIO", 
        "array", 
        "errno", 
        "httplib", 
        "socket", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_httpservers": {
      "file": "test/test_httpservers.py", 
      "imports": [
        "BaseHTTPServer", 
        "CGIHTTPServer", 
        "SimpleHTTPServer", 
        "StringIO", 
        "base64", 
        "httplib", 
        "os", 
        "re", 
        "shutil", 
        "sys", 
        "tempfile", 
        "test.test_support", 
        "unittest", 
        "urllib"
      ]
    }, 
    "test.test_idle": {
      "file": "test/test_idle.py", 
      "imports": [
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_imageop": {
      "file": "test/test_imageop.py", 
      "imports": [
        "imgfile", 
        "os", 
        "sys", 
        "test.test_support", 
        "unittest", 
        "uu"
      ]
    }, 
    "test.test_imaplib": {
      "file": "test/test_imaplib.py", 
      "imports": [
        "SocketServer", 
        "contextlib", 
        "imaplib", 
        "os", 
        "ssl", 
        "test.test_support", 
        "time", 
        "unittest"
      ]
    }, 
    "test.test_imgfile": {
      "file": "test/test_imgfile.py", 
      "imports": [
        "os", 
        "sys", 
        "test.test_support", 
        "uu"
      ]
    }, 
    "test.test_imghdr": {
      "file": "test/test_imghdr.py", 
      "imports": [
        "imghdr", 
        "io", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_imp": {
      "file": "test/test_imp.py", 
      "imports": [
        "imp", 
        "marshal", 
        "os", 
        "test.test_support", 
        "thread", 
        "time", 
        "unittest"
      ]
    }, 
    "test.test_import": {
      "file": "test/test_import.py", 
      "imports": [
        "RAnDoM", 
        "errno", 
        "imp", 
        "marshal", 
        "os", 
        "py_compile", 
        "random", 
        "shutil", 
        "socket", 
        "stat", 
        "struct", 
        "sys", 
        "test", 
        "test.double_const", 
        "test.infinite_reload", 
        "test.relimport", 
        "test.script_helper", 
        "test.symlink_support", 
        "test.test_import", 
        "test.test_support", 
        "textwrap", 
        "unittest"
      ]
    }, 
    "test.test_importhooks": {
      "file": "test/test_importhooks.py", 
      "imports": [
        "hooktestmodule", 
        "hooktestpackage", 
        "hooktestpackage.futrel", 
        "hooktestpackage.newabs", 
        "hooktestpackage.newrel", 
        "hooktestpackage.oldabs", 
        "hooktestpackage.sub", 
        "hooktestpackage.sub.subber", 
        "hooktestpackage.sub.subber.subest", 
        "imp", 
        "os", 
        "reloadmodule", 
        "sub", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_importlib": {
      "file": "test/test_importlib.py", 
      "imports": [
        "contextlib", 
        "imp", 
        "importlib", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_index": {
      "file": "test/test_index.py", 
      "imports": [
        "operator", 
        "sys.maxint", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_inspect": {
      "file": "test/test_inspect.py", 
      "imports": [
        "__builtin__", 
        "abc", 
        "inspect", 
        "linecache", 
        "re", 
        "sys", 
        "test.inspect_fodder", 
        "test.inspect_fodder2", 
        "test.test_support", 
        "unicodedata", 
        "types", 
        "unittest", 
        "UserDict", 
        "UserList"
      ]
    }, 
    "test.test_int": {
      "file": "test/test_int.py", 
      "imports": [
        "math", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_int_literal": {
      "file": "test/test_int_literal.py", 
      "imports": [
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_io": {
      "file": "test/test_io.py", 
      "imports": [
        "__future__", 
        "_pyio", 
        "abc", 
        "array", 
        "codecs", 
        "collections", 
        "contextlib", 
        "errno", 
        "fcntl", 
        "io", 
        "itertools.count", 
        "itertools.cycle", 
        "os", 
        "random", 
        "signal", 
        "sys", 
        "test.test_support", 
        "threading", 
        "time", 
        "unittest", 
        "UserList", 
        "warnings", 
        "weakref"
      ]
    }, 
    "test.test_ioctl": {
      "file": "test/test_ioctl.py", 
      "imports": [
        "array", 
        "os", 
        "pty", 
        "struct", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_isinstance": {
      "file": "test/test_isinstance.py", 
      "imports": [
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_iter": {
      "file": "test/test_iter.py", 
      "imports": [
        "operator.add", 
        "operator.countOf", 
        "operator.indexOf", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_iterlen": {
      "file": "test/test_iterlen.py", 
      "imports": [
        "__builtin__.len", 
        "collections", 
        "itertools.repeat", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_itertools": {
      "file": "test/test_itertools.py", 
      "imports": [
        "copy", 
        "decimal", 
        "fractions", 
        "functools", 
        "gc", 
        "itertools.*", 
        "operator", 
        "pickle", 
        "random", 
        "sys", 
        "test.test_iterlen", 
        "test.test_support", 
        "unittest", 
        "weakref"
      ]
    }, 
    "test.test_json": {
      "file": "test/test_json.py", 
      "imports": [
        "json.tests", 
        "test.test_support"
      ]
    }, 
    "test.test_kqueue": {
      "file": "test/test_kqueue.py", 
      "imports": [
        "errno", 
        "select", 
        "socket", 
        "sys", 
        "test.test_support", 
        "time", 
        "unittest"
      ]
    }, 
    "test.test_largefile": {
      "file": "test/test_largefile.py", 
      "imports": [
        "__future__", 
        "_pyio", 
        "io", 
        "os", 
        "signal", 
        "stat", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_lib2to3": {
      "file": "test/test_lib2to3.py", 
      "imports": [
        "lib2to3.tests.test_fixers", 
        "lib2to3.tests.test_main", 
        "lib2to3.tests.test_parser", 
        "lib2to3.tests.test_pytree", 
        "lib2to3.tests.test_refactor", 
        "lib2to3.tests.test_util", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_linecache": {
      "file": "test/test_linecache.py", 
      "imports": [
        "linecache", 
        "os", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_linuxaudiodev": {
      "file": "test/test_linuxaudiodev.py", 
      "imports": [
        "audioop", 
        "errno", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_list": {
      "file": "test/test_list.py", 
      "imports": [
        "gc", 
        "sys", 
        "test.list_tests", 
        "test.test_support"
      ]
    }, 
    "test.test_locale": {
      "file": "test/test_locale.py", 
      "imports": [
        "codecs", 
        "locale", 
        "os", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_logging": {
      "file": "test/test_logging.py", 
      "imports": [
        "SocketServer", 
        "cStringIO", 
        "codecs", 
        "gc", 
        "json", 
        "logging", 
        "logging.config", 
        "logging.handlers", 
        "os", 
        "random", 
        "re", 
        "select", 
        "socket", 
        "struct", 
        "sys", 
        "tempfile", 
        "test.test_support", 
        "threading", 
        "time", 
        "textwrap", 
        "unittest", 
        "warnings", 
        "weakref", 
        "cPickle"
      ]
    }, 
    "test.test_long": {
      "file": "test/test_long.py", 
      "imports": [
        "math", 
        "random", 
        "sys", 
        "test.test_int", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_long_future": {
      "file": "test/test_long_future.py", 
      "imports": [
        "__future__", 
        "math", 
        "random", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_longexp": {
      "file": "test/test_longexp.py", 
      "imports": [
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_macos": {
      "file": "test/test_macos.py", 
      "imports": [
        "os", 
        "subprocess", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_macostools": {
      "file": "test/test_macostools.py", 
      "imports": [
        "Carbon.File", 
        "macostools", 
        "os", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_macpath": {
      "file": "test/test_macpath.py", 
      "imports": [
        "macpath", 
        "test.test_genericpath", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_macurl2path": {
      "file": "test/test_macurl2path.py", 
      "imports": [
        "macurl2path", 
        "unittest"
      ]
    }, 
    "test.test_mailbox": {
      "file": "test/test_mailbox.py", 
      "imports": [
        "StringIO", 
        "email", 
        "email.message", 
        "email.parser", 
        "fcntl", 
        "glob", 
        "mailbox", 
        "os", 
        "re", 
        "shutil", 
        "socket", 
        "stat", 
        "sys", 
        "tempfile", 
        "test.test_support", 
        "time", 
        "unittest"
      ]
    }, 
    "test.test_marshal": {
      "file": "test/test_marshal.py", 
      "imports": [
        "marshal", 
        "os", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_math": {
      "file": "test/test_math.py", 
      "imports": [
        "doctest", 
        "math", 
        "os", 
        "random", 
        "struct", 
        "sys", 
        "sys.float_info", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_md5": {
      "file": "test/test_md5.py", 
      "imports": [
        "md5", 
        "string", 
        "test.test_support", 
        "unittest", 
        "warnings"
      ]
    }, 
    "test.test_memoryio": {
      "file": "test/test_memoryio.py", 
      "imports": [
        "__future__", 
        "__main__", 
        "_pyio", 
        "array", 
        "io", 
        "pickle", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_memoryview": {
      "file": "test/test_memoryview.py", 
      "imports": [
        "array", 
        "gc", 
        "io", 
        "sys", 
        "test.test_support", 
        "unittest", 
        "weakref"
      ]
    }, 
    "test.test_mhlib": {
      "file": "test/test_mhlib.py", 
      "imports": [
        "StringIO", 
        "os", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_mimetools": {
      "file": "test/test_mimetools.py", 
      "imports": [
        "StringIO", 
        "string", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_mimetypes": {
      "file": "test/test_mimetypes.py", 
      "imports": [
        "StringIO", 
        "_winreg", 
        "mimetypes", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_minidom": {
      "file": "test/test_minidom.py", 
      "imports": [
        "StringIO", 
        "pickle", 
        "test.test_support", 
        "unittest", 
        "xml.parsers.expat", 
        "xml.dom.pulldom", 
        "xml.dom.minidom", 
        "xml.dom"
      ]
    }, 
    "test.test_mmap": {
      "file": "test/test_mmap.py", 
      "imports": [
        "itertools", 
        "os", 
        "re", 
        "socket", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_module": {
      "file": "test/test_module.py", 
      "imports": [
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_modulefinder": {
      "file": "test/test_modulefinder.py", 
      "imports": [
        "__future__", 
        "distutils.dir_util", 
        "modulefinder", 
        "os", 
        "sets", 
        "tempfile", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_msilib": {
      "file": "test/test_msilib.py", 
      "imports": [
        "os", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_multibytecodec": {
      "file": "test/test_multibytecodec.py", 
      "imports": [
        "StringIO", 
        "_multibytecodec", 
        "codecs", 
        "os", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_multibytecodec_support": {
      "file": "test/test_multibytecodec_support.py", 
      "imports": [
        "StringIO", 
        "codecs", 
        "htmlentitydefs", 
        "httplib", 
        "os", 
        "re", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_multifile": {
      "file": "test/test_multifile.py", 
      "imports": [
        "cStringIO", 
        "test.test_support"
      ]
    }, 
    "test.test_multiprocessing": {
      "file": "test/test_multiprocessing.py", 
      "imports": [
        "Queue", 
        "StringIO", 
        "array", 
        "ctypes.Structure", 
        "ctypes.c_double", 
        "ctypes.c_int", 
        "errno", 
        "gc", 
        "json", 
        "logging", 
        "msvcrt", 
        "multiprocessing.connection", 
        "multiprocessing.dummy", 
        "multiprocessing.forking", 
        "multiprocessing.heap", 
        "multiprocessing.managers", 
        "multiprocessing.managers.BaseManager", 
        "multiprocessing.managers.BaseProxy", 
        "multiprocessing.managers.RemoteError", 
        "multiprocessing.pool", 
        "multiprocessing.pool.MaybeEncodingError", 
        "multiprocessing.reduction", 
        "multiprocessing.sharedctypes.Value", 
        "multiprocessing.sharedctypes.copy", 
        "multiprocessing.util", 
        "os", 
        "random", 
        "signal", 
        "socket", 
        "subprocess", 
        "sys", 
        "test.script_helper", 
        "test.test_support", 
        "threading", 
        "time", 
        "unittest"
      ]
    }, 
    "test.test_mutants": {
      "file": "test/test_mutants.py", 
      "imports": [
        "os", 
        "random", 
        "test.test_support"
      ]
    }, 
    "test.test_mutex": {
      "file": "test/test_mutex.py", 
      "imports": [
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_netrc": {
      "file": "test/test_netrc.py", 
      "imports": [
        "netrc", 
        "os", 
        "sys", 
        "test.test_support", 
        "textwrap", 
        "unittest"
      ]
    }, 
    "test.test_new": {
      "file": "test/test_new.py", 
      "imports": [
        "Spam", 
        "__builtin__", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_nis": {
      "file": "test/test_nis.py", 
      "imports": [
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_nntplib": {
      "file": "test/test_nntplib.py", 
      "imports": [
        "nntplib", 
        "socket", 
        "test.test_support", 
        "threading", 
        "time", 
        "unittest"
      ]
    }, 
    "test.test_normalization": {
      "file": "test/test_normalization.py", 
      "imports": [
        "httplib", 
        "os", 
        "sys", 
        "test.test_support", 
        "unicodedata.normalize", 
        "unicodedata.unidata_version", 
        "unittest"
      ]
    }, 
    "test.test_ntpath": {
      "file": "test/test_ntpath.py", 
      "imports": [
        "nt", 
        "ntpath", 
        "os", 
        "sys", 
        "test.test_genericpath", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_old_mailbox": {
      "file": "test/test_old_mailbox.py", 
      "imports": [
        "email.parser", 
        "mailbox", 
        "os", 
        "test.test_support", 
        "time", 
        "unittest"
      ]
    }, 
    "test.test_opcodes": {
      "file": "test/test_opcodes.py", 
      "imports": [
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_openpty": {
      "file": "test/test_openpty.py", 
      "imports": [
        "os", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_operator": {
      "file": "test/test_operator.py", 
      "imports": [
        "gc", 
        "operator", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_optparse": {
      "file": "test/test_optparse.py", 
      "imports": [
        "StringIO", 
        "copy", 
        "optparse", 
        "os", 
        "re", 
        "sys", 
        "test.test_support", 
        "types", 
        "unittest"
      ]
    }, 
    "test.test_os": {
      "file": "test/test_os.py", 
      "imports": [
        "ctypes", 
        "ctypes.wintypes", 
        "errno", 
        "mmap", 
        "msvcrt", 
        "os", 
        "signal", 
        "stat", 
        "subprocess", 
        "sys", 
        "test.mapping_tests", 
        "test.script_helper", 
        "test.test_support", 
        "time", 
        "unittest", 
        "uuid", 
        "warnings", 
        "resource"
      ]
    }, 
    "test.test_ossaudiodev": {
      "file": "test/test_ossaudiodev.py", 
      "imports": [
        "audioop", 
        "errno", 
        "ossaudiodev.AFMT_S16_NE", 
        "sunau", 
        "sys", 
        "test.test_support", 
        "time", 
        "unittest"
      ]
    }, 
    "test.test_parser": {
      "file": "test/test_parser.py", 
      "imports": [
        "parser", 
        "struct", 
        "sys", 
        "test.script_helper", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_pdb": {
      "file": "test/test_pdb.py", 
      "imports": [
        "imp", 
        "os", 
        "subprocess", 
        "sys", 
        "test.test_doctest", 
        "test.test_pdb", 
        "test.test_support", 
        "textwrap", 
        "unittest"
      ]
    }, 
    "test.test_peepholer": {
      "file": "test/test_peepholer.py", 
      "imports": [
        "cStringIO.StringIO", 
        "dis", 
        "gc", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_pep247": {
      "file": "test/test_pep247.py", 
      "imports": [
        "hmac", 
        "md5", 
        "sha", 
        "test.test_support", 
        "unittest", 
        "warnings"
      ]
    }, 
    "test.test_pep263": {
      "file": "test/test_pep263.py", 
      "imports": [
        "test.bad_coding3", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_pep277": {
      "file": "test/test_pep277.py", 
      "imports": [
        "os", 
        "sys", 
        "test.test_support", 
        "unicodedata.normalize", 
        "unittest"
      ]
    }, 
    "test.test_pep292": {
      "file": "test/test_pep292.py", 
      "imports": [
        "string", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_pep352": {
      "file": "test/test_pep352.py", 
      "imports": [
        "__builtin__", 
        "exceptions", 
        "os", 
        "platform", 
        "sys", 
        "test.test_support", 
        "unittest", 
        "warnings"
      ]
    }, 
    "test.test_pickle": {
      "file": "test/test_pickle.py", 
      "imports": [
        "cStringIO.StringIO", 
        "pickle", 
        "test.pickletester", 
        "test.test_support"
      ]
    }, 
    "test.test_pickletools": {
      "file": "test/test_pickletools.py", 
      "imports": [
        "pickle", 
        "pickletools", 
        "test.pickletester", 
        "test.test_support"
      ]
    }, 
    "test.test_pipes": {
      "file": "test/test_pipes.py", 
      "imports": [
        "os", 
        "pipes", 
        "string", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_pkg": {
      "file": "test/test_pkg.py", 
      "imports": [
        "os", 
        "sys", 
        "t1", 
        "t2.sub", 
        "t2.sub.subsub", 
        "t2.sub.subsub.spam", 
        "t3.sub.subsub", 
        "t5", 
        "t6", 
        "t7", 
        "t7.sub", 
        "t7.sub.subsub", 
        "t7.sub.subsub.spam", 
        "t8", 
        "tempfile", 
        "test.test_support", 
        "textwrap", 
        "unittest"
      ]
    }, 
    "test.test_pkgimport": {
      "file": "test/test_pkgimport.py", 
      "imports": [
        "os", 
        "random", 
        "string", 
        "sys", 
        "tempfile", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_pkgutil": {
      "file": "test/test_pkgutil.py", 
      "imports": [
        "foo", 
        "imp", 
        "os", 
        "pkgutil", 
        "shutil", 
        "sys", 
        "tempfile", 
        "test.test_support", 
        "zipimport", 
        "unittest", 
        "zipfile"
      ]
    }, 
    "test.test_platform": {
      "file": "test/test_platform.py", 
      "imports": [
        "gestalt", 
        "os", 
        "platform", 
        "subprocess", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_plistlib": {
      "file": "test/test_plistlib.py", 
      "imports": [
        "StringIO", 
        "cStringIO.StringIO", 
        "os", 
        "plistlib", 
        "test.test_support", 
        "unittest", 
        "datetime"
      ]
    }, 
    "test.test_poll": {
      "file": "test/test_poll.py", 
      "imports": [
        "os", 
        "random", 
        "select", 
        "test.test_support", 
        "threading", 
        "time", 
        "unittest", 
        "_testcapi"
      ]
    }, 
    "test.test_popen": {
      "file": "test/test_popen.py", 
      "imports": [
        "os", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_popen2": {
      "file": "test/test_popen2.py", 
      "imports": [
        "os", 
        "popen2", 
        "subprocess", 
        "sys", 
        "test.test_support", 
        "unittest", 
        "warnings"
      ]
    }, 
    "test.test_poplib": {
      "file": "test/test_poplib.py", 
      "imports": [
        "asynchat", 
        "asyncore", 
        "errno", 
        "os", 
        "poplib", 
        "socket", 
        "ssl", 
        "test.test_support", 
        "time", 
        "unittest"
      ]
    }, 
    "test.test_posix": {
      "file": "test/test_posix.py", 
      "imports": [
        "errno", 
        "os", 
        "platform", 
        "shutil", 
        "stat", 
        "sys", 
        "sysconfig", 
        "tempfile", 
        "test.test_support", 
        "time", 
        "unittest", 
        "warnings", 
        "pwd"
      ]
    }, 
    "test.test_posixpath": {
      "file": "test/test_posixpath.py", 
      "imports": [
        "os", 
        "posixpath", 
        "test.test_genericpath", 
        "test.test_support", 
        "unittest", 
        "pwd"
      ]
    }, 
    "test.test_pow": {
      "file": "test/test_pow.py", 
      "imports": [
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_pprint": {
      "file": "test/test_pprint.py", 
      "imports": [
        "pprint", 
        "test.test_set", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_print": {
      "file": "test/test_print.py", 
      "imports": [
        "StringIO", 
        "__future__", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_profile": {
      "file": "test/test_profile.py", 
      "imports": [
        "StringIO", 
        "profile", 
        "pstats", 
        "sys", 
        "test.profilee", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_property": {
      "file": "test/test_property.py", 
      "imports": [
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_pstats": {
      "file": "test/test_pstats.py", 
      "imports": [
        "pstats", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_pty": {
      "file": "test/test_pty.py", 
      "imports": [
        "errno", 
        "os", 
        "pty", 
        "select", 
        "signal", 
        "socket", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_pwd": {
      "file": "test/test_pwd.py", 
      "imports": [
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_py3kwarn": {
      "file": "test/test_py3kwarn.py", 
      "imports": [
        "operator.add", 
        "operator.isCallable", 
        "operator.sequenceIncludes", 
        "sys", 
        "test.test_support", 
        "unittest", 
        "UserString", 
        "warnings"
      ]
    }, 
    "test.test_py_compile": {
      "file": "test/test_py_compile.py", 
      "imports": [
        "imp", 
        "os", 
        "py_compile", 
        "shutil", 
        "tempfile", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_pyclbr": {
      "file": "test/test_pyclbr.py", 
      "imports": [
        "commands", 
        "pyclbr", 
        "sys", 
        "test.test_support", 
        "types", 
        "unittest"
      ]
    }, 
    "test.test_pydoc": {
      "file": "test/test_pydoc.py", 
      "imports": [
        "__builtin__", 
        "collections", 
        "contextlib", 
        "difflib", 
        "inspect", 
        "keyword", 
        "nturl2path", 
        "os", 
        "pkgutil", 
        "pydoc", 
        "re", 
        "sys", 
        "test.pydoc_mod", 
        "test.pydocfodder", 
        "test.script_helper", 
        "test.test_support", 
        "types", 
        "unittest", 
        "xml.etree"
      ]
    }, 
    "test.test_pyexpat": {
      "file": "test/test_pyexpat.py", 
      "imports": [
        "StringIO", 
        "sys", 
        "test.test_support", 
        "unittest", 
        "xml.parsers.expat"
      ]
    }, 
    "test.test_queue": {
      "file": "test/test_queue.py", 
      "imports": [
        "Queue", 
        "test.test_support", 
        "time", 
        "unittest"
      ]
    }, 
    "test.test_quopri": {
      "file": "test/test_quopri.py", 
      "imports": [
        "cStringIO", 
        "quopri", 
        "subprocess", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_random": {
      "file": "test/test_random.py", 
      "imports": [
        "functools", 
        "math.exp", 
        "math.fsum", 
        "math.ldexp", 
        "math.log", 
        "math.pi", 
        "math.sin", 
        "pickle", 
        "random", 
        "sys", 
        "test.test_support", 
        "time", 
        "unittest", 
        "warnings"
      ]
    }, 
    "test.test_re": {
      "file": "test/test_re.py", 
      "imports": [
        "_sre", 
        "_sre.MAXREPEAT", 
        "array", 
        "pickle", 
        "re", 
        "sre", 
        "sre_constants", 
        "string", 
        "sys", 
        "test.re_tests", 
        "test.test_support", 
        "traceback", 
        "unittest", 
        "weakref", 
        "cPickle"
      ]
    }, 
    "test.test_readline": {
      "file": "test/test_readline.py", 
      "imports": [
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_repr": {
      "file": "test/test_repr.py", 
      "imports": [
        "areallylongpackageandmodulenametotestreprtruncation.areallylongpackageandmodulenametotestreprtruncation.areallylongpackageandmodulenametotestreprtruncation", 
        "areallylongpackageandmodulenametotestreprtruncation.areallylongpackageandmodulenametotestreprtruncation.bar", 
        "areallylongpackageandmodulenametotestreprtruncation.areallylongpackageandmodulenametotestreprtruncation.baz", 
        "areallylongpackageandmodulenametotestreprtruncation.areallylongpackageandmodulenametotestreprtruncation.foo", 
        "areallylongpackageandmodulenametotestreprtruncation.areallylongpackageandmodulenametotestreprtruncation.qux", 
        "array.array", 
        "collections", 
        "os", 
        "repr", 
        "shutil", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_resource": {
      "file": "test/test_resource.py", 
      "imports": [
        "test.test_support", 
        "time", 
        "unittest"
      ]
    }, 
    "test.test_rfc822": {
      "file": "test/test_rfc822.py", 
      "imports": [
        "StringIO", 
        "cStringIO.StringIO", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_richcmp": {
      "file": "test/test_richcmp.py", 
      "imports": [
        "operator", 
        "random", 
        "test.test_support", 
        "unittest", 
        "UserList"
      ]
    }, 
    "test.test_rlcompleter": {
      "file": "test/test_rlcompleter.py", 
      "imports": [
        "__builtin__", 
        "rlcompleter", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_robotparser": {
      "file": "test/test_robotparser.py", 
      "imports": [
        "StringIO", 
        "robotparser", 
        "test.test_support", 
        "unittest", 
        "urllib2"
      ]
    }, 
    "test.test_runpy": {
      "file": "test/test_runpy.py", 
      "imports": [
        "os", 
        "re", 
        "runpy", 
        "sys", 
        "tempfile", 
        "test.script_helper", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_sax": {
      "file": "test/test_sax.py", 
      "imports": [
        "cStringIO.StringIO", 
        "io", 
        "os", 
        "shutil", 
        "sys", 
        "test.test_support", 
        "unittest", 
        "xml.sax.xmlreader", 
        "xml.sax.saxutils", 
        "xml.sax.handler", 
        "xml.sax.expatreader", 
        "xml.sax"
      ]
    }, 
    "test.test_scope": {
      "file": "test/test_scope.py", 
      "imports": [
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_scriptpackages": {
      "file": "test/test_scriptpackages.py", 
      "imports": [
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_select": {
      "file": "test/test_select.py", 
      "imports": [
        "os", 
        "select", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_set": {
      "file": "test/test_set.py", 
      "imports": [
        "collections", 
        "copy", 
        "gc", 
        "itertools.chain", 
        "itertools.imap", 
        "operator", 
        "pickle", 
        "random", 
        "sys", 
        "test.test_support", 
        "unittest", 
        "weakref"
      ]
    }, 
    "test.test_setcomps": {
      "file": "test/test_setcomps.py", 
      "imports": [
        "gc", 
        "sys", 
        "test.test_setcomps", 
        "test.test_support"
      ]
    }, 
    "test.test_sets": {
      "file": "test/test_sets.py", 
      "imports": [
        "copy", 
        "doctest", 
        "operator", 
        "pickle", 
        "random", 
        "sets", 
        "test.test_sets", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_sgmllib": {
      "file": "test/test_sgmllib.py", 
      "imports": [
        "pprint", 
        "re", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_sha": {
      "file": "test/test_sha.py", 
      "imports": [
        "sha", 
        "test.test_support", 
        "unittest", 
        "warnings"
      ]
    }, 
    "test.test_shelve": {
      "file": "test/test_shelve.py", 
      "imports": [
        "glob", 
        "os", 
        "shelve", 
        "test.mapping_tests", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_shlex": {
      "file": "test/test_shlex.py", 
      "imports": [
        "StringIO", 
        "cStringIO.StringIO", 
        "shlex", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_shutil": {
      "file": "test/test_shutil.py", 
      "imports": [
        "distutils.spawn", 
        "errno", 
        "os", 
        "shutil", 
        "stat", 
        "sys", 
        "tarfile", 
        "tempfile", 
        "test.test_support", 
        "zlib", 
        "unittest", 
        "warnings", 
        "zipfile", 
        "grp", 
        "pwd"
      ]
    }, 
    "test.test_signal": {
      "file": "test/test_signal.py", 
      "imports": [
        "contextlib", 
        "errno", 
        "fcntl", 
        "gc", 
        "os", 
        "pickle", 
        "select", 
        "signal", 
        "subprocess", 
        "sys", 
        "test.test_support", 
        "time", 
        "traceback", 
        "unittest"
      ]
    }, 
    "test.test_site": {
      "file": "test/test_site.py", 
      "imports": [
        "__builtin__", 
        "copy", 
        "encodings", 
        "locale", 
        "os", 
        "re", 
        "site", 
        "sitecustomize", 
        "subprocess", 
        "sys", 
        "sysconfig", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_slice": {
      "file": "test/test_slice.py", 
      "imports": [
        "sys", 
        "test.test_support", 
        "unittest", 
        "cPickle"
      ]
    }, 
    "test.test_smtplib": {
      "file": "test/test_smtplib.py", 
      "imports": [
        "StringIO", 
        "asyncore", 
        "email.utils", 
        "select", 
        "smtpd", 
        "smtplib", 
        "socket", 
        "sys", 
        "test.test_support", 
        "threading", 
        "time", 
        "unittest"
      ]
    }, 
    "test.test_smtpnet": {
      "file": "test/test_smtpnet.py", 
      "imports": [
        "smtplib", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_socket": {
      "file": "test/test_socket.py", 
      "imports": [
        "Queue", 
        "array", 
        "contextlib", 
        "errno", 
        "math", 
        "os", 
        "select", 
        "signal", 
        "socket", 
        "sys", 
        "test.test_support", 
        "thread", 
        "threading", 
        "time", 
        "traceback", 
        "unittest", 
        "weakref", 
        "_testcapi"
      ]
    }, 
    "test.test_socketserver": {
      "file": "test/test_socketserver.py", 
      "imports": [
        "SocketServer", 
        "contextlib", 
        "errno", 
        "imp", 
        "os", 
        "select", 
        "signal", 
        "socket", 
        "tempfile", 
        "test.test_support", 
        "threading", 
        "unittest"
      ]
    }, 
    "test.test_softspace": {
      "file": "test/test_softspace.py", 
      "imports": [
        "StringIO", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_sort": {
      "file": "test/test_sort.py", 
      "imports": [
        "gc", 
        "random", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_spwd": {
      "file": "test/test_spwd.py", 
      "imports": [
        "os", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_sqlite": {
      "file": "test/test_sqlite.py", 
      "imports": [
        "sqlite3.test.dbapi", 
        "sqlite3.test.dump", 
        "sqlite3.test.factory", 
        "sqlite3.test.hooks", 
        "sqlite3.test.py25tests", 
        "sqlite3.test.regression", 
        "sqlite3.test.transactions", 
        "sqlite3.test.types", 
        "sqlite3.test.userfunctions", 
        "test.test_support"
      ]
    }, 
    "test.test_ssl": {
      "file": "test/test_ssl.py", 
      "imports": [
        "BaseHTTPServer", 
        "SimpleHTTPServer", 
        "_ssl", 
        "asyncore", 
        "errno", 
        "functools", 
        "gc", 
        "os", 
        "platform", 
        "pprint", 
        "select", 
        "socket", 
        "sys", 
        "test.test_support", 
        "threading", 
        "time", 
        "traceback", 
        "unittest", 
        "urllib", 
        "urlparse", 
        "weakref"
      ]
    }, 
    "test.test_startfile": {
      "file": "test/test_startfile.py", 
      "imports": [
        "os", 
        "test.test_support", 
        "time.sleep", 
        "unittest"
      ]
    }, 
    "test.test_stat": {
      "file": "test/test_stat.py", 
      "imports": [
        "os", 
        "stat", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_str": {
      "file": "test/test_str.py", 
      "imports": [
        "struct", 
        "sys", 
        "test.string_tests", 
        "test.test_support", 
        "unittest", 
        "_testcapi", 
        "datetime"
      ]
    }, 
    "test.test_strftime": {
      "file": "test/test_strftime.py", 
      "imports": [
        "calendar", 
        "java", 
        "locale", 
        "re", 
        "sys", 
        "test.test_support", 
        "time", 
        "unittest"
      ]
    }, 
    "test.test_string": {
      "file": "test/test_string.py", 
      "imports": [
        "string", 
        "test.string_tests", 
        "test.test_support", 
        "unittest", 
        "UserList"
      ]
    }, 
    "test.test_stringprep": {
      "file": "test/test_stringprep.py", 
      "imports": [
        "stringprep", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_strop": {
      "file": "test/test_strop.py", 
      "imports": [
        "strop", 
        "sys", 
        "test.test_support", 
        "unittest", 
        "warnings"
      ]
    }, 
    "test.test_strptime": {
      "file": "test/test_strptime.py", 
      "imports": [
        "_strptime", 
        "locale", 
        "re", 
        "sys", 
        "test.test_support", 
        "time", 
        "unittest", 
        "datetime"
      ]
    }, 
    "test.test_strtod": {
      "file": "test/test_strtod.py", 
      "imports": [
        "random", 
        "re", 
        "struct", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_struct": {
      "file": "test/test_struct.py", 
      "imports": [
        "array", 
        "binascii", 
        "inspect", 
        "math", 
        "os", 
        "random", 
        "struct", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_structmembers": {
      "file": "test/test_structmembers.py", 
      "imports": [
        "test.test_support", 
        "unittest", 
        "_testcapi"
      ]
    }, 
    "test.test_structseq": {
      "file": "test/test_structseq.py", 
      "imports": [
        "test.test_support", 
        "time", 
        "unittest"
      ]
    }, 
    "test.test_subprocess": {
      "file": "test/test_subprocess.py", 
      "imports": [
        "errno", 
        "os", 
        "re", 
        "signal", 
        "subprocess", 
        "sys", 
        "sysconfig", 
        "tempfile", 
        "test.test_support", 
        "threading", 
        "time", 
        "unittest", 
        "resource"
      ]
    }, 
    "test.test_sunau": {
      "file": "test/test_sunau.py", 
      "imports": [
        "sunau", 
        "sys", 
        "test.audiotests", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_sunaudiodev": {
      "file": "test/test_sunaudiodev.py", 
      "imports": [
        "os", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_sundry": {
      "file": "test/test_sundry.py", 
      "imports": [
        "CGIHTTPServer", 
        "audiodev", 
        "bdb", 
        "cgitb", 
        "code", 
        "compileall", 
        "distutils.bcppcompiler", 
        "distutils.ccompiler", 
        "distutils.command.bdist", 
        "distutils.command.bdist_dumb", 
        "distutils.command.bdist_msi", 
        "distutils.command.bdist_rpm", 
        "distutils.command.bdist_wininst", 
        "distutils.command.build", 
        "distutils.command.build_clib", 
        "distutils.command.build_ext", 
        "distutils.command.clean", 
        "distutils.command.config", 
        "distutils.command.install_data", 
        "distutils.command.install_egg_info", 
        "distutils.command.install_headers", 
        "distutils.command.install_lib", 
        "distutils.command.register", 
        "distutils.command.sdist", 
        "distutils.command.upload", 
        "distutils.cygwinccompiler", 
        "distutils.emxccompiler", 
        "distutils.filelist", 
        "distutils.msvccompiler", 
        "distutils.text_file", 
        "distutils.unixccompiler", 
        "encodings", 
        "formatter", 
        "getpass", 
        "htmlentitydefs", 
        "ihooks", 
        "imputil", 
        "keyword", 
        "linecache", 
        "mailcap", 
        "mimify", 
        "nntplib", 
        "nturl2path", 
        "opcode", 
        "os2emxpath", 
        "pdb", 
        "posixfile", 
        "pstats", 
        "py_compile", 
        "rexec", 
        "sched", 
        "sndhdr", 
        "statvfs", 
        "stringold", 
        "sunau", 
        "sunaudio", 
        "symbol", 
        "sys", 
        "tabnanny", 
        "test.test_support", 
        "token", 
        "timeit", 
        "toaiff", 
        "tty", 
        "unittest", 
        "webbrowser", 
        "xml"
      ]
    }, 
    "test.test_support": {
      "file": "test/test_support.py", 
      "imports": [
        "StringIO", 
        "Tkinter.Tk", 
        "contextlib", 
        "ctypes", 
        "ctypes.Structure", 
        "ctypes.c_int", 
        "ctypes.cdll", 
        "ctypes.pointer", 
        "ctypes.util.find_library", 
        "ctypes.wintypes", 
        "doctest", 
        "errno", 
        "functools", 
        "gc", 
        "importlib", 
        "locale", 
        "os", 
        "pdb", 
        "platform", 
        "re", 
        "shutil", 
        "socket", 
        "struct", 
        "subprocess", 
        "sys", 
        "sysconfig", 
        "test", 
        "thread", 
        "time", 
        "traceback", 
        "unittest", 
        "urllib2", 
        "urlparse", 
        "UserDict", 
        "warnings", 
        "_testcapi"
      ]
    }, 
    "test.test_symtable": {
      "file": "test/test_symtable.py", 
      "imports": [
        "symtable", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_syntax": {
      "file": "test/test_syntax.py", 
      "imports": [
        "re", 
        "test.test_support", 
        "test.test_syntax", 
        "unittest", 
        "warnings"
      ]
    }, 
    "test.test_sys": {
      "file": "test/test_sys.py", 
      "imports": [
        "__builtin__", 
        "_ast", 
        "cStringIO", 
        "codecs", 
        "encodings.iso8859_3", 
        "imp", 
        "inspect", 
        "operator", 
        "os", 
        "re", 
        "struct", 
        "subprocess", 
        "sys", 
        "test.script_helper", 
        "test.test_support", 
        "thread", 
        "threading", 
        "traceback", 
        "types", 
        "unittest", 
        "weakref", 
        "_testcapi", 
        "datetime"
      ]
    }, 
    "test.test_sys_setprofile": {
      "file": "test/test_sys_setprofile.py", 
      "imports": [
        "gc", 
        "pprint", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_sys_settrace": {
      "file": "test/test_sys_settrace.py", 
      "imports": [
        "difflib", 
        "gc", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_sysconfig": {
      "file": "test/test_sysconfig.py", 
      "imports": [
        "_osx_support", 
        "copy", 
        "os", 
        "shutil", 
        "subprocess", 
        "sys", 
        "sysconfig", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_tarfile": {
      "file": "test/test_tarfile.py", 
      "imports": [
        "StringIO", 
        "bz2", 
        "errno", 
        "gzip", 
        "hashlib", 
        "os", 
        "shutil", 
        "sys", 
        "tarfile", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_tcl": {
      "file": "test/test_tcl.py", 
      "imports": [
        "Tkinter.Tcl", 
        "_tkinter.TclError", 
        "os", 
        "subprocess.PIPE", 
        "subprocess.Popen", 
        "sys", 
        "test.test_support", 
        "unittest", 
        "_testcapi"
      ]
    }, 
    "test.test_telnetlib": {
      "file": "test/test_telnetlib.py", 
      "imports": [
        "Queue", 
        "socket", 
        "telnetlib", 
        "test.test_support", 
        "time", 
        "unittest"
      ]
    }, 
    "test.test_tempfile": {
      "file": "test/test_tempfile.py", 
      "imports": [
        "contextlib", 
        "errno", 
        "io", 
        "os", 
        "re", 
        "shutil", 
        "signal", 
        "stat", 
        "sys", 
        "tempfile", 
        "test.test_support", 
        "unittest", 
        "warnings"
      ]
    }, 
    "test.test_textwrap": {
      "file": "test/test_textwrap.py", 
      "imports": [
        "test.test_support", 
        "textwrap", 
        "unittest"
      ]
    }, 
    "test.test_thread": {
      "file": "test/test_thread.py", 
      "imports": [
        "os", 
        "random", 
        "sys", 
        "test.lock_tests", 
        "test.test_support", 
        "time", 
        "unittest", 
        "weakref"
      ]
    }, 
    "test.test_threaded_import": {
      "file": "test/test_threaded_import.py", 
      "imports": [
        "imp", 
        "random", 
        "sys", 
        "test.test_support", 
        "test.threaded_import_hangers", 
        "unittest"
      ]
    }, 
    "test.test_threadedtempfile": {
      "file": "test/test_threadedtempfile.py", 
      "imports": [
        "StringIO", 
        "tempfile", 
        "test.test_support", 
        "traceback", 
        "unittest"
      ]
    }, 
    "test.test_threading": {
      "file": "test/test_threading.py", 
      "imports": [
        "ctypes", 
        "os", 
        "random", 
        "re", 
        "subprocess", 
        "sys", 
        "test.lock_tests", 
        "test.script_helper", 
        "test.test_support", 
        "time", 
        "unittest", 
        "weakref", 
        "_testcapi"
      ]
    }, 
    "test.test_threading_local": {
      "file": "test/test_threading_local.py", 
      "imports": [
        "_threading_local", 
        "doctest", 
        "gc", 
        "test.test_support", 
        "thread._local", 
        "time", 
        "unittest", 
        "weakref"
      ]
    }, 
    "test.test_threadsignals": {
      "file": "test/test_threadsignals.py", 
      "imports": [
        "os", 
        "signal", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_time": {
      "file": "test/test_time.py", 
      "imports": [
        "os", 
        "sys", 
        "test.test_support", 
        "time", 
        "unittest"
      ]
    }, 
    "test.test_timeout": {
      "file": "test/test_timeout.py", 
      "imports": [
        "socket", 
        "test.test_support", 
        "time", 
        "unittest"
      ]
    }, 
    "test.test_tk": {
      "file": "test/test_tk.py", 
      "imports": [
        "os", 
        "runtktests", 
        "test.test_support"
      ]
    }, 
    "test.test_tokenize": {
      "file": "test/test_tokenize.py", 
      "imports": [
        "StringIO", 
        "os", 
        "test.test_support", 
        "test.test_tokenize", 
        "tokenize", 
        "unittest"
      ]
    }, 
    "test.test_tools": {
      "file": "test/test_tools.py", 
      "imports": [
        "os", 
        "shutil", 
        "subprocess", 
        "sys", 
        "sysconfig", 
        "tempfile", 
        "test.script_helper", 
        "test.test_support", 
        "textwrap", 
        "unittest"
      ]
    }, 
    "test.test_trace": {
      "file": "test/test_trace.py", 
      "imports": [
        "os", 
        "sys", 
        "test.test_support", 
        "test.tracedmodules.testmod", 
        "trace", 
        "unittest"
      ]
    }, 
    "test.test_traceback": {
      "file": "test/test_traceback.py", 
      "imports": [
        "StringIO", 
        "imp.reload", 
        "os", 
        "sys", 
        "tempfile", 
        "test.badsyntax_nocaret", 
        "test.test_support", 
        "test_bug737473", 
        "time", 
        "traceback", 
        "unittest", 
        "_testcapi"
      ]
    }, 
    "test.test_transformer": {
      "file": "test/test_transformer.py", 
      "imports": [
        "compiler", 
        "compiler.ast", 
        "compiler.transformer", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_ttk_guionly": {
      "file": "test/test_ttk_guionly.py", 
      "imports": [
        "_tkinter.TclError", 
        "os", 
        "runtktests", 
        "test.test_support", 
        "test_ttk.support.get_tk_root", 
        "ttk", 
        "unittest"
      ]
    }, 
    "test.test_ttk_textonly": {
      "file": "test/test_ttk_textonly.py", 
      "imports": [
        "os", 
        "runtktests", 
        "test.test_support"
      ]
    }, 
    "test.test_tuple": {
      "file": "test/test_tuple.py", 
      "imports": [
        "gc", 
        "test.seq_tests", 
        "test.test_support"
      ]
    }, 
    "test.test_typechecks": {
      "file": "test/test_typechecks.py", 
      "imports": [
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_types": {
      "file": "test/test_types.py", 
      "imports": [
        "array", 
        "locale", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_ucn": {
      "file": "test/test_ucn.py", 
      "imports": [
        "sys", 
        "test.test_support", 
        "unicodedata", 
        "unittest", 
        "_testcapi"
      ]
    }, 
    "test.test_unary": {
      "file": "test/test_unary.py", 
      "imports": [
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_undocumented_details": {
      "file": "test/test_undocumented_details.py", 
      "imports": [
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_unicode": {
      "file": "test/test_unicode.py", 
      "imports": [
        "codecs", 
        "imp", 
        "struct", 
        "sys", 
        "test.string_tests", 
        "test.test_support", 
        "unittest", 
        "_testcapi", 
        "datetime"
      ]
    }, 
    "test.test_unicode_file": {
      "file": "test/test_unicode_file.py", 
      "imports": [
        "glob", 
        "os", 
        "shutil", 
        "sys", 
        "test.test_support", 
        "time", 
        "unicodedata", 
        "unittest"
      ]
    }, 
    "test.test_unicodedata": {
      "file": "test/test_unicodedata.py", 
      "imports": [
        "hashlib", 
        "subprocess", 
        "sys", 
        "test.test_support", 
        "unicodedata", 
        "unittest"
      ]
    }, 
    "test.test_unittest": {
      "file": "test/test_unittest.py", 
      "imports": [
        "test.test_support", 
        "unittest.test"
      ]
    }, 
    "test.test_univnewlines": {
      "file": "test/test_univnewlines.py", 
      "imports": [
        "__future__", 
        "_pyio", 
        "io", 
        "os", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_univnewlines2k": {
      "file": "test/test_univnewlines2k.py", 
      "imports": [
        "os", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_unpack": {
      "file": "test/test_unpack.py", 
      "imports": [
        "test.test_support", 
        "test.test_unpack"
      ]
    }, 
    "test.test_urllib": {
      "file": "test/test_urllib.py", 
      "imports": [
        "StringIO", 
        "base64", 
        "httplib", 
        "mimetools", 
        "os", 
        "sys", 
        "tempfile", 
        "test.test_support", 
        "unittest", 
        "urllib", 
        "warnings"
      ]
    }, 
    "test.test_urllib2": {
      "file": "test/test_urllib2.py", 
      "imports": [
        "StringIO", 
        "base64", 
        "cookielib", 
        "copy", 
        "ftplib", 
        "httplib", 
        "mimetools", 
        "os", 
        "rfc822", 
        "socket", 
        "string", 
        "test.test_cookielib", 
        "test.test_support", 
        "test.test_urllib2", 
        "unittest", 
        "urllib", 
        "urllib2"
      ]
    }, 
    "test.test_urllib2_localnet": {
      "file": "test/test_urllib2_localnet.py", 
      "imports": [
        "BaseHTTPServer", 
        "hashlib", 
        "test.test_support", 
        "unittest", 
        "urllib2", 
        "urlparse"
      ]
    }, 
    "test.test_urllib2net": {
      "file": "test/test_urllib2net.py", 
      "imports": [
        "httplib", 
        "logging", 
        "os", 
        "socket", 
        "sys", 
        "test.test_support", 
        "test.test_urllib2", 
        "time", 
        "unittest", 
        "urllib2"
      ]
    }, 
    "test.test_urllibnet": {
      "file": "test/test_urllibnet.py", 
      "imports": [
        "os", 
        "socket", 
        "sys", 
        "test.test_support", 
        "time", 
        "unittest", 
        "urllib"
      ]
    }, 
    "test.test_urlparse": {
      "file": "test/test_urlparse.py", 
      "imports": [
        "test.test_support", 
        "unittest", 
        "urlparse"
      ]
    }, 
    "test.test_userdict": {
      "file": "test/test_userdict.py", 
      "imports": [
        "test.mapping_tests", 
        "test.test_support", 
        "UserDict"
      ]
    }, 
    "test.test_userlist": {
      "file": "test/test_userlist.py", 
      "imports": [
        "test.list_tests", 
        "test.test_support", 
        "UserList"
      ]
    }, 
    "test.test_userstring": {
      "file": "test/test_userstring.py", 
      "imports": [
        "string", 
        "test.string_tests", 
        "test.test_support", 
        "UserString", 
        "warnings"
      ]
    }, 
    "test.test_uu": {
      "file": "test/test_uu.py", 
      "imports": [
        "cStringIO", 
        "os", 
        "sys", 
        "test.test_support", 
        "unittest", 
        "uu"
      ]
    }, 
    "test.test_uuid": {
      "file": "test/test_uuid.py", 
      "imports": [
        "io", 
        "os", 
        "test.test_support", 
        "unittest", 
        "uuid"
      ]
    }, 
    "test.test_wait3": {
      "file": "test/test_wait3.py", 
      "imports": [
        "os", 
        "test.fork_wait", 
        "test.test_support", 
        "time", 
        "unittest"
      ]
    }, 
    "test.test_wait4": {
      "file": "test/test_wait4.py", 
      "imports": [
        "os", 
        "sys", 
        "test.fork_wait", 
        "test.test_support", 
        "time"
      ]
    }, 
    "test.test_warnings": {
      "file": "test/test_warnings.py", 
      "imports": [
        "StringIO", 
        "contextlib", 
        "linecache", 
        "os", 
        "subprocess", 
        "sys", 
        "test.script_helper", 
        "test.test_support", 
        "test.warning_tests", 
        "unittest", 
        "warnings"
      ]
    }, 
    "test.test_wave": {
      "file": "test/test_wave.py", 
      "imports": [
        "sys", 
        "test.audiotests", 
        "test.test_support", 
        "wave", 
        "unittest"
      ]
    }, 
    "test.test_weakref": {
      "file": "test/test_weakref.py", 
      "imports": [
        "contextlib", 
        "copy", 
        "gc", 
        "operator", 
        "sys", 
        "test.mapping_tests", 
        "test.test_support", 
        "unittest", 
        "UserList", 
        "weakref"
      ]
    }, 
    "test.test_weakset": {
      "file": "test/test_weakset.py", 
      "imports": [
        "collections", 
        "contextlib", 
        "copy", 
        "gc", 
        "operator", 
        "os", 
        "random", 
        "string", 
        "sys", 
        "test.test_support", 
        "unittest", 
        "UserString", 
        "warnings", 
        "weakref"
      ]
    }, 
    "test.test_whichdb": {
      "file": "test/test_whichdb.py", 
      "imports": [
        "glob", 
        "os", 
        "test.test_support", 
        "unittest", 
        "whichdb"
      ]
    }, 
    "test.test_winreg": {
      "file": "test/test_winreg.py", 
      "imports": [
        "_winreg.*", 
        "errno", 
        "os", 
        "platform", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_winsound": {
      "file": "test/test_winsound.py", 
      "imports": [
        "_winreg", 
        "os", 
        "subprocess", 
        "test.test_support", 
        "time", 
        "unittest"
      ]
    }, 
    "test.test_with": {
      "file": "test/test_with.py", 
      "imports": [
        "collections", 
        "contextlib", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_wsgiref": {
      "file": "test/test_wsgiref.py", 
      "imports": [
        "SocketServer", 
        "StringIO", 
        "__future__", 
        "os", 
        "re", 
        "sys", 
        "test.test_support", 
        "unittest", 
        "wsgiref.validate", 
        "wsgiref.util", 
        "wsgiref.simple_server", 
        "wsgiref.headers", 
        "wsgiref.handlers"
      ]
    }, 
    "test.test_xdrlib": {
      "file": "test/test_xdrlib.py", 
      "imports": [
        "test.test_support", 
        "unittest", 
        "xdrlib"
      ]
    }, 
    "test.test_xml_etree": {
      "file": "test/test_xml_etree.py", 
      "imports": [
        "StringIO", 
        "cgi", 
        "sys", 
        "test.test_support", 
        "test.test_xml_etree", 
        "xml.etree.ElementTree", 
        "xml.etree.ElementPath"
      ]
    }, 
    "test.test_xml_etree_c": {
      "file": "test/test_xml_etree_c.py", 
      "imports": [
        "test.test_support", 
        "test.test_xml_etree", 
        "test.test_xml_etree_c", 
        "unittest"
      ]
    }, 
    "test.test_xmllib": {
      "file": "test/test_xmllib.py", 
      "imports": [
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.test_xmlrpc": {
      "file": "test/test_xmlrpc.py", 
      "imports": [
        "SimpleXMLRPCServer", 
        "StringIO", 
        "base64", 
        "gzip", 
        "httplib", 
        "mimetools", 
        "os", 
        "re", 
        "socket", 
        "sys", 
        "test.test_support", 
        "threading", 
        "time", 
        "unittest", 
        "xmlrpclib", 
        "datetime"
      ]
    }, 
    "test.test_xpickle": {
      "file": "test/test_xpickle.py", 
      "imports": [
        "os", 
        "pickle", 
        "subprocess", 
        "sys", 
        "test.test_support", 
        "types", 
        "unittest", 
        "cPickle"
      ]
    }, 
    "test.test_xrange": {
      "file": "test/test_xrange.py", 
      "imports": [
        "itertools", 
        "pickle", 
        "sys", 
        "test.test_support", 
        "unittest", 
        "warnings"
      ]
    }, 
    "test.test_zipfile": {
      "file": "test/test_zipfile.py", 
      "imports": [
        "StringIO", 
        "email", 
        "io", 
        "os", 
        "random", 
        "struct", 
        "sys", 
        "tempfile", 
        "test.test_support", 
        "time", 
        "zlib", 
        "unittest", 
        "zipfile"
      ]
    }, 
    "test.test_zipfile64": {
      "file": "test/test_zipfile64.py", 
      "imports": [
        "os", 
        "sys", 
        "tempfile", 
        "test.test_support", 
        "time", 
        "zlib", 
        "unittest", 
        "zipfile"
      ]
    }, 
    "test.test_zipimport": {
      "file": "test/test_zipimport.py", 
      "imports": [
        "StringIO", 
        "doctest", 
        "imp", 
        "inspect", 
        "linecache", 
        "marshal", 
        "os", 
        "struct", 
        "sys", 
        "test.test_importhooks", 
        "test.test_support", 
        "time", 
        "zipimport", 
        "zlib", 
        "traceback", 
        "unittest", 
        "zipfile"
      ]
    }, 
    "test.test_zipimport_support": {
      "file": "test/test_zipimport_support.py", 
      "imports": [
        "doctest", 
        "inspect", 
        "linecache", 
        "os", 
        "pdb", 
        "sys", 
        "test.sample_doctest", 
        "test.sample_doctest_no_docstrings", 
        "test.sample_doctest_no_doctests", 
        "test.script_helper", 
        "test.test_doctest", 
        "test.test_importhooks", 
        "test.test_support", 
        "test_zipped_doctest", 
        "zip_pkg", 
        "zipimport", 
        "textwrap", 
        "warnings", 
        "zipfile"
      ]
    }, 
    "test.test_zlib": {
      "file": "test/test_zlib.py", 
      "imports": [
        "binascii", 
        "mmap", 
        "os", 
        "random", 
        "sys", 
        "test.test_support", 
        "unittest"
      ]
    }, 
    "test.testall": {
      "file": "test/testall.py", 
      "imports": [
        "sys", 
        "test.regrtest", 
        "warnings"
      ]
    }, 
    "test.testcodec": {
      "file": "test/testcodec.py", 
      "imports": [
        "codecs"
      ]
    }, 
    "test.tf_inherit_check": {
      "file": "test/tf_inherit_check.py", 
      "imports": [
        "os", 
        "sys"
      ]
    }, 
    "test.threaded_import_hangers": {
      "file": "test/threaded_import_hangers.py", 
      "imports": [
        "os", 
        "tempfile", 
        "threading"
      ]
    }, 
    "test.time_hashlib": {
      "file": "test/time_hashlib.py", 
      "imports": [
        "_hashlib", 
        "hashlib", 
        "sys", 
        "time"
      ]
    }, 
    "test.tracedmodules": {
      "dir": "test/tracedmodules"
    }, 
    "test.tracedmodules.__init__": {
      "file": "test/tracedmodules/__init__.py", 
      "imports": []
    }, 
    "test.tracedmodules.testmod": {
      "file": "test/tracedmodules/testmod.py", 
      "imports": []
    }, 
    "test.warning_tests": {
      "file": "test/warning_tests.py", 
      "imports": [
        "warnings"
      ]
    }, 
    "test.win_console_handler": {
      "file": "test/win_console_handler.py", 
      "imports": [
        "ctypes", 
        "ctypes.WINFUNCTYPE", 
        "ctypes.wintypes", 
        "mmap", 
        "signal", 
        "sys"
      ]
    }, 
    "test.xmltests": {
      "file": "test/xmltests.py", 
      "imports": [
        "sys", 
        "test.test_support"
      ]
    }, 
    "textwrap": {
      "file": "textwrap.py", 
      "imports": [
        "re", 
        "string"
      ]
    }, 
    "this": {
      "file": "this.py", 
      "imports": []
    }, 
    "timeit": {
      "file": "timeit.py", 
      "imports": [
        "gc", 
        "getopt", 
        "linecache", 
        "os", 
        "sys", 
        "time", 
        "traceback"
      ]
    }, 
    "toaiff": {
      "file": "toaiff.py", 
      "imports": [
        "os", 
        "pipes", 
        "sndhdr", 
        "tempfile", 
        "warnings"
      ]
    }, 
    "token": {
      "file": "token.py", 
      "imports": [
        "re", 
        "sys"
      ]
    }, 
    "tokenize": {
      "file": "tokenize.py", 
      "imports": [
        "itertools.chain", 
        "re", 
        "string", 
        "sys", 
        "token"
      ]
    }, 
    "tputil": {
      "file": "tputil.py", 
      "imports": [
        "__pypy__.tproxy", 
        "types"
      ]
    }, 
    "trace": {
      "file": "trace.py", 
      "imports": [
        "__main__", 
        "dis", 
        "gc", 
        "getopt", 
        "inspect", 
        "linecache", 
        "os", 
        "pickle", 
        "re", 
        "sys", 
        "threading", 
        "time", 
        "token", 
        "tokenize", 
        "cPickle"
      ]
    }, 
    "traceback": {
      "file": "traceback.py", 
      "imports": [
        "linecache", 
        "sys", 
        "types"
      ]
    }, 
    "tty": {
      "file": "tty.py", 
      "imports": [
        "termios.*"
      ]
    }, 
    "types": {
      "file": "types.py", 
      "imports": [
        "sys"
      ]
    }, 
    "unittest": {
      "dir": "unittest"
    }, 
    "unittest.__init__": {
      "file": "unittest/__init__.py", 
      "imports": [
        "unittest.case", 
        "unittest.loader", 
        "unittest.main", 
        "unittest.result", 
        "unittest.runner", 
        "unittest.signals", 
        "unittest.suite"
      ]
    }, 
    "unittest.__main__": {
      "file": "unittest/__main__.py", 
      "imports": [
        "sys", 
        "unittest.main"
      ]
    }, 
    "unittest.case": {
      "file": "unittest/case.py", 
      "imports": [
        "collections", 
        "difflib", 
        "functools", 
        "pprint", 
        "re", 
        "sys", 
        "types", 
        "unittest.result", 
        "unittest.util", 
        "warnings"
      ]
    }, 
    "unittest.loader": {
      "file": "unittest/loader.py", 
      "imports": [
        "fnmatch", 
        "functools", 
        "os", 
        "re", 
        "sys", 
        "traceback", 
        "types", 
        "unittest.case", 
        "unittest.suite"
      ]
    }, 
    "unittest.main": {
      "file": "unittest/main.py", 
      "imports": [
        "getopt", 
        "optparse", 
        "os", 
        "sys", 
        "types", 
        "unittest.loader", 
        "unittest.runner", 
        "unittest.signals"
      ]
    }, 
    "unittest.result": {
      "file": "unittest/result.py", 
      "imports": [
        "StringIO", 
        "functools", 
        "os", 
        "sys", 
        "traceback", 
        "unittest.util"
      ]
    }, 
    "unittest.runner": {
      "file": "unittest/runner.py", 
      "imports": [
        "sys", 
        "time", 
        "unittest.result", 
        "unittest.signals"
      ]
    }, 
    "unittest.signals": {
      "file": "unittest/signals.py", 
      "imports": [
        "functools", 
        "signal", 
        "weakref"
      ]
    }, 
    "unittest.suite": {
      "file": "unittest/suite.py", 
      "imports": [
        "sys", 
        "unittest.case", 
        "unittest.util"
      ]
    }, 
    "unittest.test": {
      "dir": "unittest/test"
    }, 
    "unittest.test.__init__": {
      "file": "unittest/test/__init__.py", 
      "imports": [
        "os", 
        "sys", 
        "unittest"
      ]
    }, 
    "unittest.test.dummy": {
      "file": "unittest/test/dummy.py", 
      "imports": []
    }, 
    "unittest.test.support": {
      "file": "unittest/test/support.py", 
      "imports": [
        "unittest"
      ]
    }, 
    "unittest.test.test_assertions": {
      "file": "unittest/test/test_assertions.py", 
      "imports": [
        "unittest", 
        "datetime"
      ]
    }, 
    "unittest.test.test_break": {
      "file": "unittest/test/test_break.py", 
      "imports": [
        "cStringIO.StringIO", 
        "gc", 
        "os", 
        "signal", 
        "sys", 
        "unittest", 
        "weakref"
      ]
    }, 
    "unittest.test.test_case": {
      "file": "unittest/test/test_case.py", 
      "imports": [
        "copy", 
        "difflib", 
        "pickle", 
        "pprint", 
        "re", 
        "sys", 
        "unittest", 
        "unittest.test", 
        "unittest.test.support"
      ]
    }, 
    "unittest.test.test_discovery": {
      "file": "unittest/test/test_discovery.py", 
      "imports": [
        "os", 
        "re", 
        "sys", 
        "unittest"
      ]
    }, 
    "unittest.test.test_functiontestcase": {
      "file": "unittest/test/test_functiontestcase.py", 
      "imports": [
        "unittest", 
        "unittest.test.support"
      ]
    }, 
    "unittest.test.test_loader": {
      "file": "unittest/test/test_loader.py", 
      "imports": [
        "sys", 
        "types", 
        "unittest"
      ]
    }, 
    "unittest.test.test_program": {
      "file": "unittest/test/test_program.py", 
      "imports": [
        "cStringIO.StringIO", 
        "os", 
        "sys", 
        "unittest"
      ]
    }, 
    "unittest.test.test_result": {
      "file": "unittest/test/test_result.py", 
      "imports": [
        "StringIO", 
        "sys", 
        "textwrap", 
        "traceback", 
        "unittest", 
        "unittest.test"
      ]
    }, 
    "unittest.test.test_runner": {
      "file": "unittest/test/test_runner.py", 
      "imports": [
        "StringIO", 
        "cStringIO.StringIO", 
        "pickle", 
        "unittest", 
        "unittest.test.support"
      ]
    }, 
    "unittest.test.test_setups": {
      "file": "unittest/test/test_setups.py", 
      "imports": [
        "cStringIO.StringIO", 
        "sys", 
        "unittest"
      ]
    }, 
    "unittest.test.test_skipping": {
      "file": "unittest/test/test_skipping.py", 
      "imports": [
        "unittest", 
        "unittest.test.support"
      ]
    }, 
    "unittest.test.test_suite": {
      "file": "unittest/test/test_suite.py", 
      "imports": [
        "sys", 
        "unittest", 
        "unittest.test.support"
      ]
    }, 
    "unittest.util": {
      "file": "unittest/util.py", 
      "imports": [
        "collections"
      ]
    }, 
    "urllib": {
      "file": "urllib.py", 
      "imports": [
        "StringIO", 
        "_winreg", 
        "base64", 
        "cStringIO.StringIO", 
        "email.utils", 
        "fnmatch", 
        "ftplib", 
        "getpass", 
        "httplib", 
        "mimetools", 
        "mimetypes", 
        "nturl2path", 
        "os", 
        "re", 
        "rourl2path.pathname2url", 
        "rourl2path.url2pathname", 
        "socket", 
        "ssl", 
        "string", 
        "sys", 
        "tempfile", 
        "time", 
        "urlparse", 
        "warnings", 
        "_scproxy"
      ]
    }, 
    "urllib2": {
      "file": "urllib2.py", 
      "imports": [
        "StringIO", 
        "base64", 
        "bisect", 
        "cStringIO.StringIO", 
        "cookielib", 
        "email.utils", 
        "ftplib", 
        "hashlib", 
        "httplib", 
        "mimetools", 
        "mimetypes", 
        "os", 
        "posixpath", 
        "random", 
        "re", 
        "socket", 
        "sys", 
        "time", 
        "types", 
        "urllib", 
        "urlparse", 
        "warnings"
      ]
    }, 
    "urlparse": {
      "file": "urlparse.py", 
      "imports": [
        "collections", 
        "re"
      ]
    }, 
    "user": {
      "file": "user.py", 
      "imports": [
        "os", 
        "warnings"
      ]
    }, 
    "uu": {
      "file": "uu.py", 
      "imports": [
        "binascii", 
        "optparse", 
        "os", 
        "sys"
      ]
    }, 
    "uuid": {
      "file": "uuid.py", 
      "imports": [
        "ctypes", 
        "ctypes.util", 
        "hashlib", 
        "netbios", 
        "os", 
        "random", 
        "re", 
        "socket", 
        "struct", 
        "sys", 
        "time", 
        "win32wnet"
      ]
    }, 
    "warnings": {
      "file": "warnings.py", 
      "imports": [
        "_warnings.default_action", 
        "_warnings.filters", 
        "_warnings.once_registry", 
        "_warnings.warn", 
        "_warnings.warn_explicit", 
        "linecache", 
        "re", 
        "sys", 
        "types"
      ]
    }, 
    "weakref": {
      "file": "weakref.py", 
      "imports": [
        "UserDict", 
        "_weakref.CallableProxyType", 
        "_weakref.ProxyType", 
        "_weakref.ReferenceType", 
        "_weakref.getweakrefcount", 
        "_weakref.getweakrefs", 
        "_weakref.proxy", 
        "_weakref.ref", 
        "_weakrefset", 
        "copy", 
        "exceptions.ReferenceError"
      ]
    }, 
    "webbrowser": {
      "file": "webbrowser.py", 
      "imports": [
        "copy", 
        "getopt", 
        "glob", 
        "os", 
        "shlex", 
        "socket", 
        "stat", 
        "subprocess", 
        "sys", 
        "tempfile", 
        "time", 
        "pwd"
      ]
    }, 
    "whichdb": {
      "file": "whichdb.py", 
      "imports": [
        "os", 
        "struct", 
        "sys", 
        "dbm"
      ]
    }, 
    "wsgiref": {
      "dir": "wsgiref"
    }, 
    "wsgiref.__init__": {
      "file": "wsgiref/__init__.py", 
      "imports": []
    }, 
    "wsgiref.handlers": {
      "file": "wsgiref/handlers.py", 
      "imports": [
        "os", 
        "sys", 
        "time", 
        "traceback", 
        "types", 
        "wsgiref.headers", 
        "wsgiref.util"
      ]
    }, 
    "wsgiref.headers": {
      "file": "wsgiref/headers.py", 
      "imports": [
        "re", 
        "types"
      ]
    }, 
    "wsgiref.simple_server": {
      "file": "wsgiref/simple_server.py", 
      "imports": [
        "BaseHTTPServer", 
        "StringIO", 
        "sys", 
        "urllib", 
        "webbrowser", 
        "wsgiref.handlers"
      ]
    }, 
    "wsgiref.util": {
      "file": "wsgiref/util.py", 
      "imports": [
        "StringIO", 
        "posixpath", 
        "urllib"
      ]
    }, 
    "wsgiref.validate": {
      "file": "wsgiref/validate.py", 
      "imports": [
        "re", 
        "sys", 
        "types", 
        "warnings"
      ]
    }, 
    "xdrlib": {
      "file": "xdrlib.py", 
      "imports": [
        "StringIO", 
        "cStringIO.StringIO", 
        "struct"
      ]
    }, 
    "xml": {
      "dir": "xml"
    }, 
    "xml.__init__": {
      "file": "xml/__init__.py", 
      "imports": [
        "_xmlplus", 
        "sys"
      ]
    }, 
    "xml.dom": {
      "dir": "xml/dom"
    }, 
    "xml.dom.NodeFilter": {
      "file": "xml/dom/NodeFilter.py", 
      "imports": []
    }, 
    "xml.dom.__init__": {
      "file": "xml/dom/__init__.py", 
      "imports": [
        "xml.dom.domreg"
      ]
    }, 
    "xml.dom.domreg": {
      "file": "xml/dom/domreg.py", 
      "imports": [
        "os", 
        "xml.dom.minicompat"
      ]
    }, 
    "xml.dom.expatbuilder": {
      "file": "xml/dom/expatbuilder.py", 
      "imports": [
        "xml.dom", 
        "xml.dom.NodeFilter", 
        "xml.dom.minicompat", 
        "xml.dom.minidom", 
        "xml.dom.xmlbuilder", 
        "xml.parsers.expat"
      ]
    }, 
    "xml.dom.minicompat": {
      "file": "xml/dom/minicompat.py", 
      "imports": [
        "xml.dom"
      ]
    }, 
    "xml.dom.minidom": {
      "file": "xml/dom/minidom.py", 
      "imports": [
        "StringIO", 
        "codecs", 
        "xml.dom", 
        "xml.dom.domreg", 
        "xml.dom.expatbuilder", 
        "xml.dom.minicompat", 
        "xml.dom.pulldom", 
        "xml.dom.xmlbuilder"
      ]
    }, 
    "xml.dom.pulldom": {
      "file": "xml/dom/pulldom.py", 
      "imports": [
        "StringIO", 
        "cStringIO.StringIO", 
        "types", 
        "xml.dom", 
        "xml.dom.minidom", 
        "xml.sax", 
        "xml.sax.handler"
      ]
    }, 
    "xml.dom.xmlbuilder": {
      "file": "xml/dom/xmlbuilder.py", 
      "imports": [
        "copy", 
        "posixpath", 
        "urllib2", 
        "urlparse", 
        "xml.dom", 
        "xml.dom.NodeFilter", 
        "xml.dom.expatbuilder"
      ]
    }, 
    "xml.etree": {
      "dir": "xml/etree"
    }, 
    "xml.etree.ElementInclude": {
      "file": "xml/etree/ElementInclude.py", 
      "imports": [
        "copy", 
        "xml.etree.ElementTree"
      ]
    }, 
    "xml.etree.ElementPath": {
      "file": "xml/etree/ElementPath.py", 
      "imports": [
        "re"
      ]
    }, 
    "xml.etree.ElementTree": {
      "file": "xml/etree/ElementTree.py", 
      "imports": [
        "ElementC14N._serialize_c14n", 
        "pyexpat", 
        "re", 
        "sys", 
        "warnings", 
        "xml.etree.ElementPath", 
        "xml.parsers.expat"
      ]
    }, 
    "xml.etree.__init__": {
      "file": "xml/etree/__init__.py", 
      "imports": []
    }, 
    "xml.etree.cElementTree": {
      "file": "xml/etree/cElementTree.py", 
      "imports": [
        "_elementtree"
      ]
    }, 
    "xml.parsers": {
      "dir": "xml/parsers"
    }, 
    "xml.parsers.__init__": {
      "file": "xml/parsers/__init__.py", 
      "imports": []
    }, 
    "xml.parsers.expat": {
      "file": "xml/parsers/expat.py", 
      "imports": [
        "pyexpat.*"
      ]
    }, 
    "xml.sax": {
      "dir": "xml/sax"
    }, 
    "xml.sax.__init__": {
      "file": "xml/sax/__init__.py", 
      "imports": [
        "StringIO", 
        "cStringIO.StringIO", 
        "org.python.core.imp", 
        "os", 
        "sys", 
        "xml.sax._exceptions", 
        "xml.sax.expatreader", 
        "xml.sax.handler", 
        "xml.sax.xmlreader"
      ]
    }, 
    "xml.sax._exceptions": {
      "file": "xml/sax/_exceptions.py", 
      "imports": [
        "java.lang.Exception", 
        "sys"
      ]
    }, 
    "xml.sax.expatreader": {
      "file": "xml/sax/expatreader.py", 
      "imports": [
        "_weakref", 
        "sys", 
        "weakref", 
        "xml.parsers.expat", 
        "xml.sax._exceptions", 
        "xml.sax.handler", 
        "xml.sax.saxutils", 
        "xml.sax.xmlreader"
      ]
    }, 
    "xml.sax.handler": {
      "file": "xml/sax/handler.py", 
      "imports": []
    }, 
    "xml.sax.saxutils": {
      "file": "xml/sax/saxutils.py", 
      "imports": [
        "io", 
        "os", 
        "sys", 
        "types", 
        "urllib", 
        "urlparse", 
        "xml.sax.handler", 
        "xml.sax.xmlreader"
      ]
    }, 
    "xml.sax.xmlreader": {
      "file": "xml/sax/xmlreader.py", 
      "imports": [
        "xml.sax._exceptions", 
        "xml.sax.handler", 
        "xml.sax.saxutils"
      ]
    }, 
    "xmllib": {
      "file": "xmllib.py", 
      "imports": [
        "getopt", 
        "re", 
        "string", 
        "sys", 
        "time.time", 
        "warnings"
      ]
    }, 
    "xmlrpclib": {
      "file": "xmlrpclib.py", 
      "imports": [
        "StringIO", 
        "_xmlrpclib", 
        "base64", 
        "cStringIO", 
        "errno", 
        "gzip", 
        "httplib", 
        "operator", 
        "re", 
        "socket", 
        "string", 
        "sys.modules", 
        "time", 
        "types", 
        "urllib", 
        "xml.parsers.expat", 
        "xmllib", 
        "datetime"
      ]
    }, 
    "zipfile": {
      "file": "zipfile.py", 
      "imports": [
        "binascii", 
        "cStringIO", 
        "io", 
        "os", 
        "py_compile", 
        "re", 
        "shutil", 
        "stat", 
        "string", 
        "struct", 
        "sys", 
        "textwrap", 
        "time", 
        "warnings", 
        "zlib"
      ]
    }
  }, 
  "preload": {
    "UserDict": "\"\"\"A more or less complete user-defined wrapper around dictionary objects.\"\"\"\n\nclass UserDict:\n    def __init__(self, dict=None, **kwargs):\n        self.data = {}\n        if dict is not None:\n            self.update(dict)\n        if len(kwargs):\n            self.update(kwargs)\n    def __repr__(self): return repr(self.data)\n    def __cmp__(self, dict):\n        if isinstance(dict, UserDict):\n            return cmp(self.data, dict.data)\n        else:\n            return cmp(self.data, dict)\n    __hash__ = None # Avoid Py3k warning\n    def __len__(self): return len(self.data)\n    def __getitem__(self, key):\n        if key in self.data:\n            return self.data[key]\n        if hasattr(self.__class__, \"__missing__\"):\n            return self.__class__.__missing__(self, key)\n        raise KeyError(key)\n    def __setitem__(self, key, item): self.data[key] = item\n    def __delitem__(self, key): del self.data[key]\n    def clear(self): self.data.clear()\n    def copy(self):\n        if self.__class__ is UserDict:\n            return UserDict(self.data.copy())\n        import copy\n        data = self.data\n        try:\n            self.data = {}\n            c = copy.copy(self)\n        finally:\n            self.data = data\n        c.update(self)\n        return c\n    def keys(self): return self.data.keys()\n    def items(self): return self.data.items()\n    def iteritems(self): return self.data.iteritems()\n    def iterkeys(self): return self.data.iterkeys()\n    def itervalues(self): return self.data.itervalues()\n    def values(self): return self.data.values()\n    def has_key(self, key): return key in self.data\n    def update(self, dict=None, **kwargs):\n        if dict is None:\n            pass\n        elif isinstance(dict, UserDict):\n            self.data.update(dict.data)\n        elif isinstance(dict, type({})) or not hasattr(dict, 'items'):\n            self.data.update(dict)\n        else:\n            for k, v in dict.items():\n                self[k] = v\n        if len(kwargs):\n            self.data.update(kwargs)\n    def get(self, key, failobj=None):\n        if key not in self:\n            return failobj\n        return self[key]\n    def setdefault(self, key, failobj=None):\n        if key not in self:\n            self[key] = failobj\n        return self[key]\n    def pop(self, key, *args):\n        return self.data.pop(key, *args)\n    def popitem(self):\n        return self.data.popitem()\n    def __contains__(self, key):\n        return key in self.data\n    @classmethod\n    def fromkeys(cls, iterable, value=None):\n        d = cls()\n        for key in iterable:\n            d[key] = value\n        return d\n\nclass IterableUserDict(UserDict):\n    def __iter__(self):\n        return iter(self.data)\n\ntry:\n    import _abcoll\nexcept ImportError:\n    pass    # e.g. no '_weakref' module on this pypy\nelse:\n    _abcoll.MutableMapping.register(IterableUserDict)\n\n\nclass DictMixin:\n    # Mixin defining all dictionary methods for classes that already have\n    # a minimum dictionary interface including getitem, setitem, delitem,\n    # and keys. Without knowledge of the subclass constructor, the mixin\n    # does not define __init__() or copy().  In addition to the four base\n    # methods, progressively more efficiency comes with defining\n    # __contains__(), __iter__(), and iteritems().\n\n    # second level definitions support higher levels\n    def __iter__(self):\n        for k in self.keys():\n            yield k\n    def has_key(self, key):\n        try:\n            self[key]\n        except KeyError:\n            return False\n        return True\n    def __contains__(self, key):\n        return self.has_key(key)\n\n    # third level takes advantage of second level definitions\n    def iteritems(self):\n        for k in self:\n            yield (k, self[k])\n    def iterkeys(self):\n        return self.__iter__()\n\n    # fourth level uses definitions from lower levels\n    def itervalues(self):\n        for _, v in self.iteritems():\n            yield v\n    def values(self):\n        return [v for _, v in self.iteritems()]\n    def items(self):\n        return list(self.iteritems())\n    def clear(self):\n        for key in self.keys():\n            del self[key]\n    def setdefault(self, key, default=None):\n        try:\n            return self[key]\n        except KeyError:\n            self[key] = default\n        return default\n    def pop(self, key, *args):\n        if len(args) > 1:\n            raise TypeError, \"pop expected at most 2 arguments, got \"\\\n                              + repr(1 + len(args))\n        try:\n            value = self[key]\n        except KeyError:\n            if args:\n                return args[0]\n            raise\n        del self[key]\n        return value\n    def popitem(self):\n        try:\n            k, v = self.iteritems().next()\n        except StopIteration:\n            raise KeyError, 'container is empty'\n        del self[k]\n        return (k, v)\n    def update(self, other=None, **kwargs):\n        # Make progressively weaker assumptions about \"other\"\n        if other is None:\n            pass\n        elif hasattr(other, 'iteritems'):  # iteritems saves memory and lookups\n            for k, v in other.iteritems():\n                self[k] = v\n        elif hasattr(other, 'keys'):\n            for k in other.keys():\n                self[k] = other[k]\n        else:\n            for k, v in other:\n                self[k] = v\n        if kwargs:\n            self.update(kwargs)\n    def get(self, key, default=None):\n        try:\n            return self[key]\n        except KeyError:\n            return default\n    def __repr__(self):\n        return repr(dict(self.iteritems()))\n    def __cmp__(self, other):\n        if other is None:\n            return 1\n        if isinstance(other, DictMixin):\n            other = dict(other.iteritems())\n        return cmp(dict(self.iteritems()), other)\n    def __len__(self):\n        return len(self.keys())\n", 
    "__future__": "\"\"\"Record of phased-in incompatible language changes.\n\nEach line is of the form:\n\n    FeatureName = \"_Feature(\" OptionalRelease \",\" MandatoryRelease \",\"\n                              CompilerFlag \")\"\n\nwhere, normally, OptionalRelease < MandatoryRelease, and both are 5-tuples\nof the same form as sys.version_info:\n\n    (PY_MAJOR_VERSION, # the 2 in 2.1.0a3; an int\n     PY_MINOR_VERSION, # the 1; an int\n     PY_MICRO_VERSION, # the 0; an int\n     PY_RELEASE_LEVEL, # \"alpha\", \"beta\", \"candidate\" or \"final\"; string\n     PY_RELEASE_SERIAL # the 3; an int\n    )\n\nOptionalRelease records the first release in which\n\n    from __future__ import FeatureName\n\nwas accepted.\n\nIn the case of MandatoryReleases that have not yet occurred,\nMandatoryRelease predicts the release in which the feature will become part\nof the language.\n\nElse MandatoryRelease records when the feature became part of the language;\nin releases at or after that, modules no longer need\n\n    from __future__ import FeatureName\n\nto use the feature in question, but may continue to use such imports.\n\nMandatoryRelease may also be None, meaning that a planned feature got\ndropped.\n\nInstances of class _Feature have two corresponding methods,\n.getOptionalRelease() and .getMandatoryRelease().\n\nCompilerFlag is the (bitfield) flag that should be passed in the fourth\nargument to the builtin function compile() to enable the feature in\ndynamically compiled code.  This flag is stored in the .compiler_flag\nattribute on _Future instances.  These values must match the appropriate\n#defines of CO_xxx flags in Include/compile.h.\n\nNo feature line is ever to be deleted from this file.\n\"\"\"\n\nall_feature_names = [\n    \"nested_scopes\",\n    \"generators\",\n    \"division\",\n    \"absolute_import\",\n    \"with_statement\",\n    \"print_function\",\n    \"unicode_literals\",\n]\n\n__all__ = [\"all_feature_names\"] + all_feature_names\n\n# The CO_xxx symbols are defined here under the same names used by\n# compile.h, so that an editor search will find them here.  However,\n# they're not exported in __all__, because they don't really belong to\n# this module.\nCO_NESTED            = 0x0010   # nested_scopes\nCO_GENERATOR_ALLOWED = 0        # generators (obsolete, was 0x1000)\nCO_FUTURE_DIVISION   = 0x2000   # division\nCO_FUTURE_ABSOLUTE_IMPORT = 0x4000 # perform absolute imports by default\nCO_FUTURE_WITH_STATEMENT  = 0x8000   # with statement\nCO_FUTURE_PRINT_FUNCTION  = 0x10000   # print function\nCO_FUTURE_UNICODE_LITERALS = 0x20000 # unicode string literals\n\nclass _Feature:\n    def __init__(self, optionalRelease, mandatoryRelease, compiler_flag):\n        self.optional = optionalRelease\n        self.mandatory = mandatoryRelease\n        self.compiler_flag = compiler_flag\n\n    def getOptionalRelease(self):\n        \"\"\"Return first release in which this feature was recognized.\n\n        This is a 5-tuple, of the same form as sys.version_info.\n        \"\"\"\n\n        return self.optional\n\n    def getMandatoryRelease(self):\n        \"\"\"Return release in which this feature will become mandatory.\n\n        This is a 5-tuple, of the same form as sys.version_info, or, if\n        the feature was dropped, is None.\n        \"\"\"\n\n        return self.mandatory\n\n    def __repr__(self):\n        return \"_Feature\" + repr((self.optional,\n                                  self.mandatory,\n                                  self.compiler_flag))\n\nnested_scopes = _Feature((2, 1, 0, \"beta\",  1),\n                         (2, 2, 0, \"alpha\", 0),\n                         CO_NESTED)\n\ngenerators = _Feature((2, 2, 0, \"alpha\", 1),\n                      (2, 3, 0, \"final\", 0),\n                      CO_GENERATOR_ALLOWED)\n\ndivision = _Feature((2, 2, 0, \"alpha\", 2),\n                    (3, 0, 0, \"alpha\", 0),\n                    CO_FUTURE_DIVISION)\n\nabsolute_import = _Feature((2, 5, 0, \"alpha\", 1),\n                           (3, 0, 0, \"alpha\", 0),\n                           CO_FUTURE_ABSOLUTE_IMPORT)\n\nwith_statement = _Feature((2, 5, 0, \"alpha\", 1),\n                          (2, 6, 0, \"alpha\", 0),\n                          CO_FUTURE_WITH_STATEMENT)\n\nprint_function = _Feature((2, 6, 0, \"alpha\", 2),\n                          (3, 0, 0, \"alpha\", 0),\n                          CO_FUTURE_PRINT_FUNCTION)\n\nunicode_literals = _Feature((2, 6, 0, \"alpha\", 2),\n                            (3, 0, 0, \"alpha\", 0),\n                            CO_FUTURE_UNICODE_LITERALS)\n", 
    "_abcoll": "# Copyright 2007 Google, Inc. All Rights Reserved.\n# Licensed to PSF under a Contributor Agreement.\n\n\"\"\"Abstract Base Classes (ABCs) for collections, according to PEP 3119.\n\nDON'T USE THIS MODULE DIRECTLY!  The classes here should be imported\nvia collections; they are defined here only to alleviate certain\nbootstrapping issues.  Unit tests are in test_collections.\n\"\"\"\n\nfrom abc import ABCMeta, abstractmethod\nimport sys\n\n__all__ = [\"Hashable\", \"Iterable\", \"Iterator\",\n           \"Sized\", \"Container\", \"Callable\",\n           \"Set\", \"MutableSet\",\n           \"Mapping\", \"MutableMapping\",\n           \"MappingView\", \"KeysView\", \"ItemsView\", \"ValuesView\",\n           \"Sequence\", \"MutableSequence\",\n           ]\n\n### ONE-TRICK PONIES ###\n\ndef _hasattr(C, attr):\n    try:\n        return any(attr in B.__dict__ for B in C.__mro__)\n    except AttributeError:\n        # Old-style class\n        return hasattr(C, attr)\n\n\nclass Hashable:\n    __metaclass__ = ABCMeta\n\n    @abstractmethod\n    def __hash__(self):\n        return 0\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is Hashable:\n            try:\n                for B in C.__mro__:\n                    if \"__hash__\" in B.__dict__:\n                        if B.__dict__[\"__hash__\"]:\n                            return True\n                        break\n            except AttributeError:\n                # Old-style class\n                if getattr(C, \"__hash__\", None):\n                    return True\n        return NotImplemented\n\n\nclass Iterable:\n    __metaclass__ = ABCMeta\n\n    @abstractmethod\n    def __iter__(self):\n        while False:\n            yield None\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is Iterable:\n            if _hasattr(C, \"__iter__\"):\n                return True\n        return NotImplemented\n\nIterable.register(str)\n\n\nclass Iterator(Iterable):\n\n    @abstractmethod\n    def next(self):\n        'Return the next item from the iterator. When exhausted, raise StopIteration'\n        raise StopIteration\n\n    def __iter__(self):\n        return self\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is Iterator:\n            if _hasattr(C, \"next\") and _hasattr(C, \"__iter__\"):\n                return True\n        return NotImplemented\n\n\nclass Sized:\n    __metaclass__ = ABCMeta\n\n    @abstractmethod\n    def __len__(self):\n        return 0\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is Sized:\n            if _hasattr(C, \"__len__\"):\n                return True\n        return NotImplemented\n\n\nclass Container:\n    __metaclass__ = ABCMeta\n\n    @abstractmethod\n    def __contains__(self, x):\n        return False\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is Container:\n            if _hasattr(C, \"__contains__\"):\n                return True\n        return NotImplemented\n\n\nclass Callable:\n    __metaclass__ = ABCMeta\n\n    @abstractmethod\n    def __call__(self, *args, **kwds):\n        return False\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is Callable:\n            if _hasattr(C, \"__call__\"):\n                return True\n        return NotImplemented\n\n\n### SETS ###\n\n\nclass Set(Sized, Iterable, Container):\n    \"\"\"A set is a finite, iterable container.\n\n    This class provides concrete generic implementations of all\n    methods except for __contains__, __iter__ and __len__.\n\n    To override the comparisons (presumably for speed, as the\n    semantics are fixed), all you have to do is redefine __le__ and\n    then the other operations will automatically follow suit.\n    \"\"\"\n\n    def __le__(self, other):\n        if not isinstance(other, Set):\n            return NotImplemented\n        if len(self) > len(other):\n            return False\n        for elem in self:\n            if elem not in other:\n                return False\n        return True\n\n    def __lt__(self, other):\n        if not isinstance(other, Set):\n            return NotImplemented\n        return len(self) < len(other) and self.__le__(other)\n\n    def __gt__(self, other):\n        if not isinstance(other, Set):\n            return NotImplemented\n        return len(self) > len(other) and self.__ge__(other)\n\n    def __ge__(self, other):\n        if not isinstance(other, Set):\n            return NotImplemented\n        if len(self) < len(other):\n            return False\n        for elem in other:\n            if elem not in self:\n                return False\n        return True\n\n    def __eq__(self, other):\n        if not isinstance(other, Set):\n            return NotImplemented\n        return len(self) == len(other) and self.__le__(other)\n\n    def __ne__(self, other):\n        return not (self == other)\n\n    @classmethod\n    def _from_iterable(cls, it):\n        '''Construct an instance of the class from any iterable input.\n\n        Must override this method if the class constructor signature\n        does not accept an iterable for an input.\n        '''\n        return cls(it)\n\n    def __and__(self, other):\n        if not isinstance(other, Iterable):\n            return NotImplemented\n        return self._from_iterable(value for value in other if value in self)\n\n    __rand__ = __and__\n\n    def isdisjoint(self, other):\n        'Return True if two sets have a null intersection.'\n        for value in other:\n            if value in self:\n                return False\n        return True\n\n    def __or__(self, other):\n        if not isinstance(other, Iterable):\n            return NotImplemented\n        chain = (e for s in (self, other) for e in s)\n        return self._from_iterable(chain)\n\n    __ror__ = __or__\n\n    def __sub__(self, other):\n        if not isinstance(other, Set):\n            if not isinstance(other, Iterable):\n                return NotImplemented\n            other = self._from_iterable(other)\n        return self._from_iterable(value for value in self\n                                   if value not in other)\n\n    def __rsub__(self, other):\n        if not isinstance(other, Set):\n            if not isinstance(other, Iterable):\n                return NotImplemented\n            other = self._from_iterable(other)\n        return self._from_iterable(value for value in other\n                                   if value not in self)\n\n    def __xor__(self, other):\n        if not isinstance(other, Set):\n            if not isinstance(other, Iterable):\n                return NotImplemented\n            other = self._from_iterable(other)\n        return (self - other) | (other - self)\n\n    __rxor__ = __xor__\n\n    # Sets are not hashable by default, but subclasses can change this\n    __hash__ = None\n\n    def _hash(self):\n        \"\"\"Compute the hash value of a set.\n\n        Note that we don't define __hash__: not all sets are hashable.\n        But if you define a hashable set type, its __hash__ should\n        call this function.\n\n        This must be compatible __eq__.\n\n        All sets ought to compare equal if they contain the same\n        elements, regardless of how they are implemented, and\n        regardless of the order of the elements; so there's not much\n        freedom for __eq__ or __hash__.  We match the algorithm used\n        by the built-in frozenset type.\n        \"\"\"\n        MAX = sys.maxint\n        MASK = 2 * MAX + 1\n        n = len(self)\n        h = 1927868237 * (n + 1)\n        h &= MASK\n        for x in self:\n            hx = hash(x)\n            h ^= (hx ^ (hx << 16) ^ 89869747)  * 3644798167\n            h &= MASK\n        h = h * 69069 + 907133923\n        h &= MASK\n        if h > MAX:\n            h -= MASK + 1\n        if h == -1:\n            h = 590923713\n        return h\n\nSet.register(frozenset)\n\n\nclass MutableSet(Set):\n    \"\"\"A mutable set is a finite, iterable container.\n\n    This class provides concrete generic implementations of all\n    methods except for __contains__, __iter__, __len__,\n    add(), and discard().\n\n    To override the comparisons (presumably for speed, as the\n    semantics are fixed), all you have to do is redefine __le__ and\n    then the other operations will automatically follow suit.\n    \"\"\"\n\n    @abstractmethod\n    def add(self, value):\n        \"\"\"Add an element.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def discard(self, value):\n        \"\"\"Remove an element.  Do not raise an exception if absent.\"\"\"\n        raise NotImplementedError\n\n    def remove(self, value):\n        \"\"\"Remove an element. If not a member, raise a KeyError.\"\"\"\n        if value not in self:\n            raise KeyError(value)\n        self.discard(value)\n\n    def pop(self):\n        \"\"\"Return the popped value.  Raise KeyError if empty.\"\"\"\n        it = iter(self)\n        try:\n            value = next(it)\n        except StopIteration:\n            raise KeyError\n        self.discard(value)\n        return value\n\n    def clear(self):\n        \"\"\"This is slow (creates N new iterators!) but effective.\"\"\"\n        try:\n            while True:\n                self.pop()\n        except KeyError:\n            pass\n\n    def __ior__(self, it):\n        for value in it:\n            self.add(value)\n        return self\n\n    def __iand__(self, it):\n        for value in (self - it):\n            self.discard(value)\n        return self\n\n    def __ixor__(self, it):\n        if it is self:\n            self.clear()\n        else:\n            if not isinstance(it, Set):\n                it = self._from_iterable(it)\n            for value in it:\n                if value in self:\n                    self.discard(value)\n                else:\n                    self.add(value)\n        return self\n\n    def __isub__(self, it):\n        if it is self:\n            self.clear()\n        else:\n            for value in it:\n                self.discard(value)\n        return self\n\nMutableSet.register(set)\n\n\n### MAPPINGS ###\n\n\nclass Mapping(Sized, Iterable, Container):\n\n    \"\"\"A Mapping is a generic container for associating key/value\n    pairs.\n\n    This class provides concrete generic implementations of all\n    methods except for __getitem__, __iter__, and __len__.\n\n    \"\"\"\n\n    @abstractmethod\n    def __getitem__(self, key):\n        raise KeyError\n\n    def get(self, key, default=None):\n        'D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.'\n        try:\n            return self[key]\n        except KeyError:\n            return default\n\n    def __contains__(self, key):\n        try:\n            self[key]\n        except KeyError:\n            return False\n        else:\n            return True\n\n    def iterkeys(self):\n        'D.iterkeys() -> an iterator over the keys of D'\n        return iter(self)\n\n    def itervalues(self):\n        'D.itervalues() -> an iterator over the values of D'\n        for key in self:\n            yield self[key]\n\n    def iteritems(self):\n        'D.iteritems() -> an iterator over the (key, value) items of D'\n        for key in self:\n            yield (key, self[key])\n\n    def keys(self):\n        \"D.keys() -> list of D's keys\"\n        return list(self)\n\n    def items(self):\n        \"D.items() -> list of D's (key, value) pairs, as 2-tuples\"\n        return [(key, self[key]) for key in self]\n\n    def values(self):\n        \"D.values() -> list of D's values\"\n        return [self[key] for key in self]\n\n    # Mappings are not hashable by default, but subclasses can change this\n    __hash__ = None\n\n    def __eq__(self, other):\n        if not isinstance(other, Mapping):\n            return NotImplemented\n        return dict(self.items()) == dict(other.items())\n\n    def __ne__(self, other):\n        return not (self == other)\n\nclass MappingView(Sized):\n\n    def __init__(self, mapping):\n        self._mapping = mapping\n\n    def __len__(self):\n        return len(self._mapping)\n\n    def __repr__(self):\n        return '{0.__class__.__name__}({0._mapping!r})'.format(self)\n\n\nclass KeysView(MappingView, Set):\n\n    @classmethod\n    def _from_iterable(self, it):\n        return set(it)\n\n    def __contains__(self, key):\n        return key in self._mapping\n\n    def __iter__(self):\n        for key in self._mapping:\n            yield key\n\n\nclass ItemsView(MappingView, Set):\n\n    @classmethod\n    def _from_iterable(self, it):\n        return set(it)\n\n    def __contains__(self, item):\n        key, value = item\n        try:\n            v = self._mapping[key]\n        except KeyError:\n            return False\n        else:\n            return v == value\n\n    def __iter__(self):\n        for key in self._mapping:\n            yield (key, self._mapping[key])\n\n\nclass ValuesView(MappingView):\n\n    def __contains__(self, value):\n        for key in self._mapping:\n            if value == self._mapping[key]:\n                return True\n        return False\n\n    def __iter__(self):\n        for key in self._mapping:\n            yield self._mapping[key]\n\n\nclass MutableMapping(Mapping):\n\n    \"\"\"A MutableMapping is a generic container for associating\n    key/value pairs.\n\n    This class provides concrete generic implementations of all\n    methods except for __getitem__, __setitem__, __delitem__,\n    __iter__, and __len__.\n\n    \"\"\"\n\n    @abstractmethod\n    def __setitem__(self, key, value):\n        raise KeyError\n\n    @abstractmethod\n    def __delitem__(self, key):\n        raise KeyError\n\n    __marker = object()\n\n    def pop(self, key, default=__marker):\n        '''D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n          If key is not found, d is returned if given, otherwise KeyError is raised.\n        '''\n        try:\n            value = self[key]\n        except KeyError:\n            if default is self.__marker:\n                raise\n            return default\n        else:\n            del self[key]\n            return value\n\n    def popitem(self):\n        '''D.popitem() -> (k, v), remove and return some (key, value) pair\n           as a 2-tuple; but raise KeyError if D is empty.\n        '''\n        try:\n            key = next(iter(self))\n        except StopIteration:\n            raise KeyError\n        value = self[key]\n        del self[key]\n        return key, value\n\n    def clear(self):\n        'D.clear() -> None.  Remove all items from D.'\n        try:\n            while True:\n                self.popitem()\n        except KeyError:\n            pass\n\n    def update(*args, **kwds):\n        ''' D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n            If E present and has a .keys() method, does:     for k in E: D[k] = E[k]\n            If E present and lacks .keys() method, does:     for (k, v) in E: D[k] = v\n            In either case, this is followed by: for k, v in F.items(): D[k] = v\n        '''\n        if len(args) > 2:\n            raise TypeError(\"update() takes at most 2 positional \"\n                            \"arguments ({} given)\".format(len(args)))\n        elif not args:\n            raise TypeError(\"update() takes at least 1 argument (0 given)\")\n        self = args[0]\n        other = args[1] if len(args) >= 2 else ()\n\n        if isinstance(other, Mapping):\n            for key in other:\n                self[key] = other[key]\n        elif hasattr(other, \"keys\"):\n            for key in other.keys():\n                self[key] = other[key]\n        else:\n            for key, value in other:\n                self[key] = value\n        for key, value in kwds.items():\n            self[key] = value\n\n    def setdefault(self, key, default=None):\n        'D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D'\n        try:\n            return self[key]\n        except KeyError:\n            self[key] = default\n        return default\n\nMutableMapping.register(dict)\n\n\n### SEQUENCES ###\n\n\nclass Sequence(Sized, Iterable, Container):\n    \"\"\"All the operations on a read-only sequence.\n\n    Concrete subclasses must override __new__ or __init__,\n    __getitem__, and __len__.\n    \"\"\"\n\n    @abstractmethod\n    def __getitem__(self, index):\n        raise IndexError\n\n    def __iter__(self):\n        i = 0\n        try:\n            while True:\n                v = self[i]\n                yield v\n                i += 1\n        except IndexError:\n            return\n\n    def __contains__(self, value):\n        for v in self:\n            if v == value:\n                return True\n        return False\n\n    def __reversed__(self):\n        for i in reversed(range(len(self))):\n            yield self[i]\n\n    def index(self, value):\n        '''S.index(value) -> integer -- return first index of value.\n           Raises ValueError if the value is not present.\n        '''\n        for i, v in enumerate(self):\n            if v == value:\n                return i\n        raise ValueError\n\n    def count(self, value):\n        'S.count(value) -> integer -- return number of occurrences of value'\n        return sum(1 for v in self if v == value)\n\nSequence.register(tuple)\nSequence.register(basestring)\nSequence.register(buffer)\nSequence.register(xrange)\n\n\nclass MutableSequence(Sequence):\n\n    \"\"\"All the operations on a read-only sequence.\n\n    Concrete subclasses must provide __new__ or __init__,\n    __getitem__, __setitem__, __delitem__, __len__, and insert().\n\n    \"\"\"\n\n    @abstractmethod\n    def __setitem__(self, index, value):\n        raise IndexError\n\n    @abstractmethod\n    def __delitem__(self, index):\n        raise IndexError\n\n    @abstractmethod\n    def insert(self, index, value):\n        'S.insert(index, object) -- insert object before index'\n        raise IndexError\n\n    def append(self, value):\n        'S.append(object) -- append object to the end of the sequence'\n        self.insert(len(self), value)\n\n    def reverse(self):\n        'S.reverse() -- reverse *IN PLACE*'\n        n = len(self)\n        for i in range(n//2):\n            self[i], self[n-i-1] = self[n-i-1], self[i]\n\n    def extend(self, values):\n        'S.extend(iterable) -- extend sequence by appending elements from the iterable'\n        for v in values:\n            self.append(v)\n\n    def pop(self, index=-1):\n        '''S.pop([index]) -> item -- remove and return item at index (default last).\n           Raise IndexError if list is empty or index is out of range.\n        '''\n        v = self[index]\n        del self[index]\n        return v\n\n    def remove(self, value):\n        '''S.remove(value) -- remove first occurrence of value.\n           Raise ValueError if the value is not present.\n        '''\n        del self[self.index(value)]\n\n    def __iadd__(self, values):\n        self.extend(values)\n        return self\n\nMutableSequence.register(list)\n", 
    "_structseq": "\"\"\"\nImplementation helper: a struct that looks like a tuple.  See timemodule\nand posixmodule for example uses.\n\"\"\"\n\nclass structseqfield(object):\n    \"\"\"Definition of field of a structseq.  The 'index' is for positional\n    tuple-like indexing.  Fields whose index is after a gap in the numbers\n    cannot be accessed like this, but only by name.\n    \"\"\"\n    def __init__(self, index, doc=None, default=lambda self: None):\n        self.__name__ = '?'\n        self.index    = index    # patched to None if not positional\n        self._index   = index\n        self.__doc__  = doc\n        self._default = default\n\n    def __repr__(self):\n        return '<field %s (%s)>' % (self.__name__,\n                                    self.__doc__ or 'undocumented')\n\n    def __get__(self, obj, typ=None):\n        if obj is None:\n            return self\n        if self.index is None:\n            return obj.__dict__[self.__name__]\n        else:\n            return obj[self.index]\n\n    def __set__(self, obj, value):\n        raise TypeError(\"readonly attribute\")\n\n\nclass structseqtype(type):\n\n    def __new__(metacls, classname, bases, dict):\n        assert not bases\n        fields_by_index = {}\n        for name, field in dict.items():\n            if isinstance(field, structseqfield):\n                assert field._index not in fields_by_index\n                fields_by_index[field._index] = field\n                field.__name__ = name\n        dict['n_fields'] = len(fields_by_index)\n\n        extra_fields = sorted(fields_by_index.iteritems())\n        n_sequence_fields = 0\n        while extra_fields and extra_fields[0][0] == n_sequence_fields:\n            extra_fields.pop(0)\n            n_sequence_fields += 1\n        dict['n_sequence_fields'] = n_sequence_fields\n        dict['n_unnamed_fields'] = 0     # no fully anonymous fields in PyPy\n\n        extra_fields = [field for index, field in extra_fields]\n        for field in extra_fields:\n            field.index = None     # no longer relevant\n\n        assert '__new__' not in dict\n        dict['_extra_fields'] = tuple(extra_fields)\n        dict['__new__'] = structseq_new\n        dict['__reduce__'] = structseq_reduce\n        dict['__setattr__'] = structseq_setattr\n        dict['__repr__'] = structseq_repr\n        dict['_name'] = dict.get('name', '')\n        return type.__new__(metacls, classname, (tuple,), dict)\n\n\nbuiltin_dict = dict\n\ndef structseq_new(cls, sequence, dict={}):\n    sequence = tuple(sequence)\n    dict = builtin_dict(dict)\n    N = cls.n_sequence_fields\n    if len(sequence) < N:\n        if N < cls.n_fields:\n            msg = \"at least\"\n        else:\n            msg = \"exactly\"\n        raise TypeError(\"expected a sequence with %s %d items\" % (\n            msg, N))\n    if len(sequence) > N:\n        if len(sequence) > cls.n_fields:\n            if N < cls.n_fields:\n                msg = \"at most\"\n            else:\n                msg = \"exactly\"\n            raise TypeError(\"expected a sequence with %s %d items\" % (\n                msg, cls.n_fields))\n        for field, value in zip(cls._extra_fields, sequence[N:]):\n            name = field.__name__\n            if name in dict:\n                raise TypeError(\"duplicate value for %r\" % (name,))\n            dict[name] = value\n        sequence = sequence[:N]\n    result = tuple.__new__(cls, sequence)\n    object.__setattr__(result, '__dict__', dict)\n    for field in cls._extra_fields:\n        name = field.__name__\n        if name not in dict:\n            dict[name] = field._default(result)\n    return result\n\ndef structseq_reduce(self):\n    return type(self), (tuple(self), self.__dict__)\n\ndef structseq_setattr(self, attr, value):\n    raise AttributeError(\"%r object has no attribute %r\" % (\n        self.__class__.__name__, attr))\n\ndef structseq_repr(self):\n    fields = {}\n    for field in type(self).__dict__.values():\n        if isinstance(field, structseqfield):\n            fields[field._index] = field\n    parts = [\"%s=%r\" % (fields[index].__name__, value)\n             for index, value in enumerate(self)]\n    return \"%s(%s)\" % (self._name, \", \".join(parts))\n", 
    "_weakrefset": "# Access WeakSet through the weakref module.\n# This code is separated-out because it is needed\n# by abc.py to load everything else at startup.\n\nfrom _weakref import ref\n\n__all__ = ['WeakSet']\n\n\nclass _IterationGuard(object):\n    # This context manager registers itself in the current iterators of the\n    # weak container, such as to delay all removals until the context manager\n    # exits.\n    # This technique should be relatively thread-safe (since sets are).\n\n    def __init__(self, weakcontainer):\n        # Don't create cycles\n        self.weakcontainer = ref(weakcontainer)\n\n    def __enter__(self):\n        w = self.weakcontainer()\n        if w is not None:\n            w._iterating.add(self)\n        return self\n\n    def __exit__(self, e, t, b):\n        w = self.weakcontainer()\n        if w is not None:\n            s = w._iterating\n            s.remove(self)\n            if not s:\n                w._commit_removals()\n\n\nclass WeakSet(object):\n    def __init__(self, data=None):\n        self.data = set()\n        def _remove(item, selfref=ref(self)):\n            self = selfref()\n            if self is not None:\n                if self._iterating:\n                    self._pending_removals.append(item)\n                else:\n                    self.data.discard(item)\n        self._remove = _remove\n        # A list of keys to be removed\n        self._pending_removals = []\n        self._iterating = set()\n        if data is not None:\n            self.update(data)\n\n    def _commit_removals(self):\n        l = self._pending_removals\n        discard = self.data.discard\n        while l:\n            discard(l.pop())\n\n    def __iter__(self):\n        with _IterationGuard(self):\n            for itemref in self.data:\n                item = itemref()\n                if item is not None:\n                    # Caveat: the iterator will keep a strong reference to\n                    # `item` until it is resumed or closed.\n                    yield item\n\n    def __len__(self):\n        return len(self.data) - len(self._pending_removals)\n\n    def __contains__(self, item):\n        try:\n            wr = ref(item)\n        except TypeError:\n            return False\n        return wr in self.data\n\n    def __reduce__(self):\n        return (self.__class__, (list(self),),\n                getattr(self, '__dict__', None))\n\n    __hash__ = None\n\n    def add(self, item):\n        if self._pending_removals:\n            self._commit_removals()\n        self.data.add(ref(item, self._remove))\n\n    def clear(self):\n        if self._pending_removals:\n            self._commit_removals()\n        self.data.clear()\n\n    def copy(self):\n        return self.__class__(self)\n\n    def pop(self):\n        if self._pending_removals:\n            self._commit_removals()\n        while True:\n            try:\n                itemref = self.data.pop()\n            except KeyError:\n                raise KeyError('pop from empty WeakSet')\n            item = itemref()\n            if item is not None:\n                return item\n\n    def remove(self, item):\n        if self._pending_removals:\n            self._commit_removals()\n        self.data.remove(ref(item))\n\n    def discard(self, item):\n        if self._pending_removals:\n            self._commit_removals()\n        self.data.discard(ref(item))\n\n    def update(self, other):\n        if self._pending_removals:\n            self._commit_removals()\n        for element in other:\n            self.add(element)\n\n    def __ior__(self, other):\n        self.update(other)\n        return self\n\n    def difference(self, other):\n        newset = self.copy()\n        newset.difference_update(other)\n        return newset\n    __sub__ = difference\n\n    def difference_update(self, other):\n        self.__isub__(other)\n    def __isub__(self, other):\n        if self._pending_removals:\n            self._commit_removals()\n        if self is other:\n            self.data.clear()\n        else:\n            self.data.difference_update(ref(item) for item in other)\n        return self\n\n    def intersection(self, other):\n        return self.__class__(item for item in other if item in self)\n    __and__ = intersection\n\n    def intersection_update(self, other):\n        self.__iand__(other)\n    def __iand__(self, other):\n        if self._pending_removals:\n            self._commit_removals()\n        self.data.intersection_update(ref(item) for item in other)\n        return self\n\n    def issubset(self, other):\n        return self.data.issubset(ref(item) for item in other)\n    __le__ = issubset\n\n    def __lt__(self, other):\n        return self.data < set(ref(item) for item in other)\n\n    def issuperset(self, other):\n        return self.data.issuperset(ref(item) for item in other)\n    __ge__ = issuperset\n\n    def __gt__(self, other):\n        return self.data > set(ref(item) for item in other)\n\n    def __eq__(self, other):\n        if not isinstance(other, self.__class__):\n            return NotImplemented\n        return self.data == set(ref(item) for item in other)\n\n    def __ne__(self, other):\n        opposite = self.__eq__(other)\n        if opposite is NotImplemented:\n            return NotImplemented\n        return not opposite\n\n    def symmetric_difference(self, other):\n        newset = self.copy()\n        newset.symmetric_difference_update(other)\n        return newset\n    __xor__ = symmetric_difference\n\n    def symmetric_difference_update(self, other):\n        self.__ixor__(other)\n    def __ixor__(self, other):\n        if self._pending_removals:\n            self._commit_removals()\n        if self is other:\n            self.data.clear()\n        else:\n            self.data.symmetric_difference_update(ref(item, self._remove) for item in other)\n        return self\n\n    def union(self, other):\n        return self.__class__(e for s in (self, other) for e in s)\n    __or__ = union\n\n    def isdisjoint(self, other):\n        return len(self.intersection(other)) == 0\n", 
    "abc": "# Copyright 2007 Google, Inc. All Rights Reserved.\n# Licensed to PSF under a Contributor Agreement.\n\n\"\"\"Abstract Base Classes (ABCs) according to PEP 3119.\"\"\"\n\nimport types\n\nfrom _weakrefset import WeakSet\n\n# Instance of old-style class\nclass _C: pass\n_InstanceType = type(_C())\n\n\ndef abstractmethod(funcobj):\n    \"\"\"A decorator indicating abstract methods.\n\n    Requires that the metaclass is ABCMeta or derived from it.  A\n    class that has a metaclass derived from ABCMeta cannot be\n    instantiated unless all of its abstract methods are overridden.\n    The abstract methods can be called using any of the normal\n    'super' call mechanisms.\n\n    Usage:\n\n        class C:\n            __metaclass__ = ABCMeta\n            @abstractmethod\n            def my_abstract_method(self, ...):\n                ...\n    \"\"\"\n    funcobj.__isabstractmethod__ = True\n    return funcobj\n\n\nclass abstractproperty(property):\n    \"\"\"A decorator indicating abstract properties.\n\n    Requires that the metaclass is ABCMeta or derived from it.  A\n    class that has a metaclass derived from ABCMeta cannot be\n    instantiated unless all of its abstract properties are overridden.\n    The abstract properties can be called using any of the normal\n    'super' call mechanisms.\n\n    Usage:\n\n        class C:\n            __metaclass__ = ABCMeta\n            @abstractproperty\n            def my_abstract_property(self):\n                ...\n\n    This defines a read-only property; you can also define a read-write\n    abstract property using the 'long' form of property declaration:\n\n        class C:\n            __metaclass__ = ABCMeta\n            def getx(self): ...\n            def setx(self, value): ...\n            x = abstractproperty(getx, setx)\n    \"\"\"\n    __isabstractmethod__ = True\n\n\nclass ABCMeta(type):\n\n    \"\"\"Metaclass for defining Abstract Base Classes (ABCs).\n\n    Use this metaclass to create an ABC.  An ABC can be subclassed\n    directly, and then acts as a mix-in class.  You can also register\n    unrelated concrete classes (even built-in classes) and unrelated\n    ABCs as 'virtual subclasses' -- these and their descendants will\n    be considered subclasses of the registering ABC by the built-in\n    issubclass() function, but the registering ABC won't show up in\n    their MRO (Method Resolution Order) nor will method\n    implementations defined by the registering ABC be callable (not\n    even via super()).\n\n    \"\"\"\n\n    # A global counter that is incremented each time a class is\n    # registered as a virtual subclass of anything.  It forces the\n    # negative cache to be cleared before its next use.\n    _abc_invalidation_counter = 0\n\n    def __new__(mcls, name, bases, namespace):\n        cls = super(ABCMeta, mcls).__new__(mcls, name, bases, namespace)\n        # Compute set of abstract method names\n        abstracts = set(name\n                     for name, value in namespace.items()\n                     if getattr(value, \"__isabstractmethod__\", False))\n        for base in bases:\n            for name in getattr(base, \"__abstractmethods__\", set()):\n                value = getattr(cls, name, None)\n                if getattr(value, \"__isabstractmethod__\", False):\n                    abstracts.add(name)\n        cls.__abstractmethods__ = frozenset(abstracts)\n        # Set up inheritance registry\n        cls._abc_registry = WeakSet()\n        cls._abc_cache = WeakSet()\n        cls._abc_negative_cache = WeakSet()\n        cls._abc_negative_cache_version = ABCMeta._abc_invalidation_counter\n        return cls\n\n    def register(cls, subclass):\n        \"\"\"Register a virtual subclass of an ABC.\"\"\"\n        if not isinstance(subclass, (type, types.ClassType)):\n            raise TypeError(\"Can only register classes\")\n        if issubclass(subclass, cls):\n            return  # Already a subclass\n        # Subtle: test for cycles *after* testing for \"already a subclass\";\n        # this means we allow X.register(X) and interpret it as a no-op.\n        if issubclass(cls, subclass):\n            # This would create a cycle, which is bad for the algorithm below\n            raise RuntimeError(\"Refusing to create an inheritance cycle\")\n        cls._abc_registry.add(subclass)\n        ABCMeta._abc_invalidation_counter += 1  # Invalidate negative cache\n\n    def _dump_registry(cls, file=None):\n        \"\"\"Debug helper to print the ABC registry.\"\"\"\n        print >> file, \"Class: %s.%s\" % (cls.__module__, cls.__name__)\n        print >> file, \"Inv.counter: %s\" % ABCMeta._abc_invalidation_counter\n        for name in sorted(cls.__dict__.keys()):\n            if name.startswith(\"_abc_\"):\n                value = getattr(cls, name)\n                print >> file, \"%s: %r\" % (name, value)\n\n    def __instancecheck__(cls, instance):\n        \"\"\"Override for isinstance(instance, cls).\"\"\"\n        # Inline the cache checking when it's simple.\n        subclass = getattr(instance, '__class__', None)\n        if subclass is not None and subclass in cls._abc_cache:\n            return True\n        subtype = type(instance)\n        # Old-style instances\n        if subtype is _InstanceType:\n            subtype = subclass\n        if subtype is subclass or subclass is None:\n            if (cls._abc_negative_cache_version ==\n                ABCMeta._abc_invalidation_counter and\n                subtype in cls._abc_negative_cache):\n                return False\n            # Fall back to the subclass check.\n            return cls.__subclasscheck__(subtype)\n        return (cls.__subclasscheck__(subclass) or\n                cls.__subclasscheck__(subtype))\n\n    def __subclasscheck__(cls, subclass):\n        \"\"\"Override for issubclass(subclass, cls).\"\"\"\n        # Check cache\n        if subclass in cls._abc_cache:\n            return True\n        # Check negative cache; may have to invalidate\n        if cls._abc_negative_cache_version < ABCMeta._abc_invalidation_counter:\n            # Invalidate the negative cache\n            cls._abc_negative_cache = WeakSet()\n            cls._abc_negative_cache_version = ABCMeta._abc_invalidation_counter\n        elif subclass in cls._abc_negative_cache:\n            return False\n        # Check the subclass hook\n        ok = cls.__subclasshook__(subclass)\n        if ok is not NotImplemented:\n            assert isinstance(ok, bool)\n            if ok:\n                cls._abc_cache.add(subclass)\n            else:\n                cls._abc_negative_cache.add(subclass)\n            return ok\n        # Check if it's a direct subclass\n        if cls in getattr(subclass, '__mro__', ()):\n            cls._abc_cache.add(subclass)\n            return True\n        # Check if it's a subclass of a registered class (recursive)\n        for rcls in cls._abc_registry:\n            if issubclass(subclass, rcls):\n                cls._abc_cache.add(subclass)\n                return True\n        # Check if it's a subclass of a subclass (recursive)\n        for scls in cls.__subclasses__():\n            if issubclass(subclass, scls):\n                cls._abc_cache.add(subclass)\n                return True\n        # No dice; update negative cache\n        cls._abc_negative_cache.add(subclass)\n        return False\n", 
    "base64": "#! /usr/bin/env python\n\n\"\"\"RFC 3548: Base16, Base32, Base64 Data Encodings\"\"\"\n\n# Modified 04-Oct-1995 by Jack Jansen to use binascii module\n# Modified 30-Dec-2003 by Barry Warsaw to add full RFC 3548 support\n\nimport re\nimport struct\nimport binascii\n\n\n__all__ = [\n    # Legacy interface exports traditional RFC 1521 Base64 encodings\n    'encode', 'decode', 'encodestring', 'decodestring',\n    # Generalized interface for other encodings\n    'b64encode', 'b64decode', 'b32encode', 'b32decode',\n    'b16encode', 'b16decode',\n    # Standard Base64 encoding\n    'standard_b64encode', 'standard_b64decode',\n    # Some common Base64 alternatives.  As referenced by RFC 3458, see thread\n    # starting at:\n    #\n    # http://zgp.org/pipermail/p2p-hackers/2001-September/000316.html\n    'urlsafe_b64encode', 'urlsafe_b64decode',\n    ]\n\n_translation = [chr(_x) for _x in range(256)]\nEMPTYSTRING = ''\n\n\ndef _translate(s, altchars):\n    translation = _translation[:]\n    for k, v in altchars.items():\n        translation[ord(k)] = v\n    return s.translate(''.join(translation))\n\n\n\f\n# Base64 encoding/decoding uses binascii\n\ndef b64encode(s, altchars=None):\n    \"\"\"Encode a string using Base64.\n\n    s is the string to encode.  Optional altchars must be a string of at least\n    length 2 (additional characters are ignored) which specifies an\n    alternative alphabet for the '+' and '/' characters.  This allows an\n    application to e.g. generate url or filesystem safe Base64 strings.\n\n    The encoded string is returned.\n    \"\"\"\n    # Strip off the trailing newline\n    encoded = binascii.b2a_base64(s)[:-1]\n    if altchars is not None:\n        return _translate(encoded, {'+': altchars[0], '/': altchars[1]})\n    return encoded\n\n\ndef b64decode(s, altchars=None):\n    \"\"\"Decode a Base64 encoded string.\n\n    s is the string to decode.  Optional altchars must be a string of at least\n    length 2 (additional characters are ignored) which specifies the\n    alternative alphabet used instead of the '+' and '/' characters.\n\n    The decoded string is returned.  A TypeError is raised if s were\n    incorrectly padded or if there are non-alphabet characters present in the\n    string.\n    \"\"\"\n    if altchars is not None:\n        s = _translate(s, {altchars[0]: '+', altchars[1]: '/'})\n    try:\n        return binascii.a2b_base64(s)\n    except binascii.Error, msg:\n        # Transform this exception for consistency\n        raise TypeError(msg)\n\n\ndef standard_b64encode(s):\n    \"\"\"Encode a string using the standard Base64 alphabet.\n\n    s is the string to encode.  The encoded string is returned.\n    \"\"\"\n    return b64encode(s)\n\ndef standard_b64decode(s):\n    \"\"\"Decode a string encoded with the standard Base64 alphabet.\n\n    s is the string to decode.  The decoded string is returned.  A TypeError\n    is raised if the string is incorrectly padded or if there are non-alphabet\n    characters present in the string.\n    \"\"\"\n    return b64decode(s)\n\ndef urlsafe_b64encode(s):\n    \"\"\"Encode a string using a url-safe Base64 alphabet.\n\n    s is the string to encode.  The encoded string is returned.  The alphabet\n    uses '-' instead of '+' and '_' instead of '/'.\n    \"\"\"\n    return b64encode(s, '-_')\n\ndef urlsafe_b64decode(s):\n    \"\"\"Decode a string encoded with the standard Base64 alphabet.\n\n    s is the string to decode.  The decoded string is returned.  A TypeError\n    is raised if the string is incorrectly padded or if there are non-alphabet\n    characters present in the string.\n\n    The alphabet uses '-' instead of '+' and '_' instead of '/'.\n    \"\"\"\n    return b64decode(s, '-_')\n\n\n\f\n# Base32 encoding/decoding must be done in Python\n_b32alphabet = {\n    0: 'A',  9: 'J', 18: 'S', 27: '3',\n    1: 'B', 10: 'K', 19: 'T', 28: '4',\n    2: 'C', 11: 'L', 20: 'U', 29: '5',\n    3: 'D', 12: 'M', 21: 'V', 30: '6',\n    4: 'E', 13: 'N', 22: 'W', 31: '7',\n    5: 'F', 14: 'O', 23: 'X',\n    6: 'G', 15: 'P', 24: 'Y',\n    7: 'H', 16: 'Q', 25: 'Z',\n    8: 'I', 17: 'R', 26: '2',\n    }\n\n_b32tab = _b32alphabet.items()\n_b32tab.sort()\n_b32tab = [v for k, v in _b32tab]\n_b32rev = dict([(v, long(k)) for k, v in _b32alphabet.items()])\n\n\ndef b32encode(s):\n    \"\"\"Encode a string using Base32.\n\n    s is the string to encode.  The encoded string is returned.\n    \"\"\"\n    parts = []\n    quanta, leftover = divmod(len(s), 5)\n    # Pad the last quantum with zero bits if necessary\n    if leftover:\n        s += ('\\0' * (5 - leftover))\n        quanta += 1\n    for i in range(quanta):\n        # c1 and c2 are 16 bits wide, c3 is 8 bits wide.  The intent of this\n        # code is to process the 40 bits in units of 5 bits.  So we take the 1\n        # leftover bit of c1 and tack it onto c2.  Then we take the 2 leftover\n        # bits of c2 and tack them onto c3.  The shifts and masks are intended\n        # to give us values of exactly 5 bits in width.\n        c1, c2, c3 = struct.unpack('!HHB', s[i*5:(i+1)*5])\n        c2 += (c1 & 1) << 16 # 17 bits wide\n        c3 += (c2 & 3) << 8  # 10 bits wide\n        parts.extend([_b32tab[c1 >> 11],         # bits 1 - 5\n                      _b32tab[(c1 >> 6) & 0x1f], # bits 6 - 10\n                      _b32tab[(c1 >> 1) & 0x1f], # bits 11 - 15\n                      _b32tab[c2 >> 12],         # bits 16 - 20 (1 - 5)\n                      _b32tab[(c2 >> 7) & 0x1f], # bits 21 - 25 (6 - 10)\n                      _b32tab[(c2 >> 2) & 0x1f], # bits 26 - 30 (11 - 15)\n                      _b32tab[c3 >> 5],          # bits 31 - 35 (1 - 5)\n                      _b32tab[c3 & 0x1f],        # bits 36 - 40 (1 - 5)\n                      ])\n    encoded = EMPTYSTRING.join(parts)\n    # Adjust for any leftover partial quanta\n    if leftover == 1:\n        return encoded[:-6] + '======'\n    elif leftover == 2:\n        return encoded[:-4] + '===='\n    elif leftover == 3:\n        return encoded[:-3] + '==='\n    elif leftover == 4:\n        return encoded[:-1] + '='\n    return encoded\n\n\ndef b32decode(s, casefold=False, map01=None):\n    \"\"\"Decode a Base32 encoded string.\n\n    s is the string to decode.  Optional casefold is a flag specifying whether\n    a lowercase alphabet is acceptable as input.  For security purposes, the\n    default is False.\n\n    RFC 3548 allows for optional mapping of the digit 0 (zero) to the letter O\n    (oh), and for optional mapping of the digit 1 (one) to either the letter I\n    (eye) or letter L (el).  The optional argument map01 when not None,\n    specifies which letter the digit 1 should be mapped to (when map01 is not\n    None, the digit 0 is always mapped to the letter O).  For security\n    purposes the default is None, so that 0 and 1 are not allowed in the\n    input.\n\n    The decoded string is returned.  A TypeError is raised if s were\n    incorrectly padded or if there are non-alphabet characters present in the\n    string.\n    \"\"\"\n    quanta, leftover = divmod(len(s), 8)\n    if leftover:\n        raise TypeError('Incorrect padding')\n    # Handle section 2.4 zero and one mapping.  The flag map01 will be either\n    # False, or the character to map the digit 1 (one) to.  It should be\n    # either L (el) or I (eye).\n    if map01:\n        s = _translate(s, {'0': 'O', '1': map01})\n    if casefold:\n        s = s.upper()\n    # Strip off pad characters from the right.  We need to count the pad\n    # characters because this will tell us how many null bytes to remove from\n    # the end of the decoded string.\n    padchars = 0\n    mo = re.search('(?P<pad>[=]*)$', s)\n    if mo:\n        padchars = len(mo.group('pad'))\n        if padchars > 0:\n            s = s[:-padchars]\n    # Now decode the full quanta\n    parts = []\n    acc = 0\n    shift = 35\n    for c in s:\n        val = _b32rev.get(c)\n        if val is None:\n            raise TypeError('Non-base32 digit found')\n        acc += _b32rev[c] << shift\n        shift -= 5\n        if shift < 0:\n            parts.append(binascii.unhexlify('%010x' % acc))\n            acc = 0\n            shift = 35\n    # Process the last, partial quanta\n    last = binascii.unhexlify('%010x' % acc)\n    if padchars == 0:\n        last = ''                       # No characters\n    elif padchars == 1:\n        last = last[:-1]\n    elif padchars == 3:\n        last = last[:-2]\n    elif padchars == 4:\n        last = last[:-3]\n    elif padchars == 6:\n        last = last[:-4]\n    else:\n        raise TypeError('Incorrect padding')\n    parts.append(last)\n    return EMPTYSTRING.join(parts)\n\n\n\f\n# RFC 3548, Base 16 Alphabet specifies uppercase, but hexlify() returns\n# lowercase.  The RFC also recommends against accepting input case\n# insensitively.\ndef b16encode(s):\n    \"\"\"Encode a string using Base16.\n\n    s is the string to encode.  The encoded string is returned.\n    \"\"\"\n    return binascii.hexlify(s).upper()\n\n\ndef b16decode(s, casefold=False):\n    \"\"\"Decode a Base16 encoded string.\n\n    s is the string to decode.  Optional casefold is a flag specifying whether\n    a lowercase alphabet is acceptable as input.  For security purposes, the\n    default is False.\n\n    The decoded string is returned.  A TypeError is raised if s were\n    incorrectly padded or if there are non-alphabet characters present in the\n    string.\n    \"\"\"\n    if casefold:\n        s = s.upper()\n    if re.search('[^0-9A-F]', s):\n        raise TypeError('Non-base16 digit found')\n    return binascii.unhexlify(s)\n\n\n\f\n# Legacy interface.  This code could be cleaned up since I don't believe\n# binascii has any line length limitations.  It just doesn't seem worth it\n# though.\n\nMAXLINESIZE = 76 # Excluding the CRLF\nMAXBINSIZE = (MAXLINESIZE//4)*3\n\ndef encode(input, output):\n    \"\"\"Encode a file.\"\"\"\n    while True:\n        s = input.read(MAXBINSIZE)\n        if not s:\n            break\n        while len(s) < MAXBINSIZE:\n            ns = input.read(MAXBINSIZE-len(s))\n            if not ns:\n                break\n            s += ns\n        line = binascii.b2a_base64(s)\n        output.write(line)\n\n\ndef decode(input, output):\n    \"\"\"Decode a file.\"\"\"\n    while True:\n        line = input.readline()\n        if not line:\n            break\n        s = binascii.a2b_base64(line)\n        output.write(s)\n\n\ndef encodestring(s):\n    \"\"\"Encode a string into multiple lines of base-64 data.\"\"\"\n    pieces = []\n    for i in range(0, len(s), MAXBINSIZE):\n        chunk = s[i : i + MAXBINSIZE]\n        pieces.append(binascii.b2a_base64(chunk))\n    return \"\".join(pieces)\n\n\ndef decodestring(s):\n    \"\"\"Decode a string.\"\"\"\n    return binascii.a2b_base64(s)\n\n\n\f\n# Useable as a script...\ndef test():\n    \"\"\"Small test program\"\"\"\n    import sys, getopt\n    try:\n        opts, args = getopt.getopt(sys.argv[1:], 'deut')\n    except getopt.error, msg:\n        sys.stdout = sys.stderr\n        print msg\n        print \"\"\"usage: %s [-d|-e|-u|-t] [file|-]\n        -d, -u: decode\n        -e: encode (default)\n        -t: encode and decode string 'Aladdin:open sesame'\"\"\"%sys.argv[0]\n        sys.exit(2)\n    func = encode\n    for o, a in opts:\n        if o == '-e': func = encode\n        if o == '-d': func = decode\n        if o == '-u': func = decode\n        if o == '-t': test1(); return\n    if args and args[0] != '-':\n        with open(args[0], 'rb') as f:\n            func(f, sys.stdout)\n    else:\n        func(sys.stdin, sys.stdout)\n\n\ndef test1():\n    s0 = \"Aladdin:open sesame\"\n    s1 = encodestring(s0)\n    s2 = decodestring(s1)\n    print s0, repr(s1), s2\n\n\nif __name__ == '__main__':\n    test()\n", 
    "code": "\"\"\"Utilities needed to emulate Python's interactive interpreter.\n\n\"\"\"\n\n# Inspired by similar code by Jeff Epler and Fredrik Lundh.\n\n\nimport sys\nimport traceback\nfrom codeop import CommandCompiler, compile_command\n\n__all__ = [\"InteractiveInterpreter\", \"InteractiveConsole\", \"interact\",\n           \"compile_command\"]\n\ndef softspace(file, newvalue):\n    oldvalue = 0\n    try:\n        oldvalue = file.softspace\n    except AttributeError:\n        pass\n    try:\n        file.softspace = newvalue\n    except (AttributeError, TypeError):\n        # \"attribute-less object\" or \"read-only attributes\"\n        pass\n    return oldvalue\n\nclass InteractiveInterpreter:\n    \"\"\"Base class for InteractiveConsole.\n\n    This class deals with parsing and interpreter state (the user's\n    namespace); it doesn't deal with input buffering or prompting or\n    input file naming (the filename is always passed in explicitly).\n\n    \"\"\"\n\n    def __init__(self, locals=None):\n        \"\"\"Constructor.\n\n        The optional 'locals' argument specifies the dictionary in\n        which code will be executed; it defaults to a newly created\n        dictionary with key \"__name__\" set to \"__console__\" and key\n        \"__doc__\" set to None.\n\n        \"\"\"\n        if locals is None:\n            locals = {\"__name__\": \"__console__\", \"__doc__\": None}\n        self.locals = locals\n        self.compile = CommandCompiler()\n\n    def runsource(self, source, filename=\"<input>\", symbol=\"single\"):\n        \"\"\"Compile and run some source in the interpreter.\n\n        Arguments are as for compile_command().\n\n        One several things can happen:\n\n        1) The input is incorrect; compile_command() raised an\n        exception (SyntaxError or OverflowError).  A syntax traceback\n        will be printed by calling the showsyntaxerror() method.\n\n        2) The input is incomplete, and more input is required;\n        compile_command() returned None.  Nothing happens.\n\n        3) The input is complete; compile_command() returned a code\n        object.  The code is executed by calling self.runcode() (which\n        also handles run-time exceptions, except for SystemExit).\n\n        The return value is True in case 2, False in the other cases (unless\n        an exception is raised).  The return value can be used to\n        decide whether to use sys.ps1 or sys.ps2 to prompt the next\n        line.\n\n        \"\"\"\n        try:\n            code = self.compile(source, filename, symbol)\n        except (OverflowError, SyntaxError, ValueError):\n            # Case 1\n            self.showsyntaxerror(filename)\n            return False\n\n        if code is None:\n            # Case 2\n            return True\n\n        # Case 3\n        self.runcode(code)\n        return False\n\n    def runcode(self, code):\n        \"\"\"Execute a code object.\n\n        When an exception occurs, self.showtraceback() is called to\n        display a traceback.  All exceptions are caught except\n        SystemExit, which is reraised.\n\n        A note about KeyboardInterrupt: this exception may occur\n        elsewhere in this code, and may not always be caught.  The\n        caller should be prepared to deal with it.\n\n        \"\"\"\n        try:\n            exec code in self.locals\n        except SystemExit:\n            raise\n        except:\n            self.showtraceback()\n        else:\n            if softspace(sys.stdout, 0):\n                print\n\n    def showsyntaxerror(self, filename=None):\n        \"\"\"Display the syntax error that just occurred.\n\n        This doesn't display a stack trace because there isn't one.\n\n        If a filename is given, it is stuffed in the exception instead\n        of what was there before (because Python's parser always uses\n        \"<string>\" when reading from a string).\n\n        The output is written by self.write(), below.\n\n        \"\"\"\n        type, value, sys.last_traceback = sys.exc_info()\n        sys.last_type = type\n        sys.last_value = value\n        if filename and type is SyntaxError:\n            # Work hard to stuff the correct filename in the exception\n            try:\n                msg, (dummy_filename, lineno, offset, line) = value\n            except:\n                # Not the format we expect; leave it alone\n                pass\n            else:\n                # Stuff in the right filename\n                value = SyntaxError(msg, (filename, lineno, offset, line))\n                sys.last_value = value\n        list = traceback.format_exception_only(type, value)\n        map(self.write, list)\n\n    def showtraceback(self):\n        \"\"\"Display the exception that just occurred.\n\n        We remove the first stack item because it is our own code.\n\n        The output is written by self.write(), below.\n\n        \"\"\"\n        try:\n            type, value, tb = sys.exc_info()\n            sys.last_type = type\n            sys.last_value = value\n            sys.last_traceback = tb\n            tblist = traceback.extract_tb(tb)\n            del tblist[:1]\n            list = traceback.format_list(tblist)\n            if list:\n                list.insert(0, \"Traceback (most recent call last):\\n\")\n            list[len(list):] = traceback.format_exception_only(type, value)\n        finally:\n            tblist = tb = None\n        map(self.write, list)\n\n    def write(self, data):\n        \"\"\"Write a string.\n\n        The base implementation writes to sys.stderr; a subclass may\n        replace this with a different implementation.\n\n        \"\"\"\n        sys.stderr.write(data)\n\n\nclass InteractiveConsole(InteractiveInterpreter):\n    \"\"\"Closely emulate the behavior of the interactive Python interpreter.\n\n    This class builds on InteractiveInterpreter and adds prompting\n    using the familiar sys.ps1 and sys.ps2, and input buffering.\n\n    \"\"\"\n\n    def __init__(self, locals=None, filename=\"<console>\"):\n        \"\"\"Constructor.\n\n        The optional locals argument will be passed to the\n        InteractiveInterpreter base class.\n\n        The optional filename argument should specify the (file)name\n        of the input stream; it will show up in tracebacks.\n\n        \"\"\"\n        InteractiveInterpreter.__init__(self, locals)\n        self.filename = filename\n        self.resetbuffer()\n\n    def resetbuffer(self):\n        \"\"\"Reset the input buffer.\"\"\"\n        self.buffer = []\n\n    def interact(self, banner=None):\n        \"\"\"Closely emulate the interactive Python console.\n\n        The optional banner argument specify the banner to print\n        before the first interaction; by default it prints a banner\n        similar to the one printed by the real Python interpreter,\n        followed by the current class name in parentheses (so as not\n        to confuse this with the real interpreter -- since it's so\n        close!).\n\n        \"\"\"\n        try:\n            sys.ps1\n        except AttributeError:\n            sys.ps1 = \">>> \"\n        try:\n            sys.ps2\n        except AttributeError:\n            sys.ps2 = \"... \"\n        cprt = 'Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.'\n        if banner is None:\n            self.write(\"Python %s on %s\\n%s\\n(%s)\\n\" %\n                       (sys.version, sys.platform, cprt,\n                        self.__class__.__name__))\n        else:\n            self.write(\"%s\\n\" % str(banner))\n        more = 0\n        while 1:\n            try:\n                if more:\n                    prompt = sys.ps2\n                else:\n                    prompt = sys.ps1\n                try:\n                    line = self.raw_input(prompt)\n                    # Can be None if sys.stdin was redefined\n                    encoding = getattr(sys.stdin, \"encoding\", None)\n                    if encoding and not isinstance(line, unicode):\n                        line = line.decode(encoding)\n                except EOFError:\n                    self.write(\"\\n\")\n                    break\n                else:\n                    more = self.push(line)\n            except KeyboardInterrupt:\n                self.write(\"\\nKeyboardInterrupt\\n\")\n                self.resetbuffer()\n                more = 0\n\n    def push(self, line):\n        \"\"\"Push a line to the interpreter.\n\n        The line should not have a trailing newline; it may have\n        internal newlines.  The line is appended to a buffer and the\n        interpreter's runsource() method is called with the\n        concatenated contents of the buffer as source.  If this\n        indicates that the command was executed or invalid, the buffer\n        is reset; otherwise, the command is incomplete, and the buffer\n        is left as it was after the line was appended.  The return\n        value is 1 if more input is required, 0 if the line was dealt\n        with in some way (this is the same as runsource()).\n\n        \"\"\"\n        self.buffer.append(line)\n        source = \"\\n\".join(self.buffer)\n        more = self.runsource(source, self.filename)\n        if not more:\n            self.resetbuffer()\n        return more\n\n    def raw_input(self, prompt=\"\"):\n        \"\"\"Write a prompt and read a line.\n\n        The returned line does not include the trailing newline.\n        When the user enters the EOF key sequence, EOFError is raised.\n\n        The base implementation uses the built-in function\n        raw_input(); a subclass may replace this with a different\n        implementation.\n\n        \"\"\"\n        return raw_input(prompt)\n\n\ndef interact(banner=None, readfunc=None, local=None):\n    \"\"\"Closely emulate the interactive Python interpreter.\n\n    This is a backwards compatible interface to the InteractiveConsole\n    class.  When readfunc is not specified, it attempts to import the\n    readline module to enable GNU readline if it is available.\n\n    Arguments (all optional, all default to None):\n\n    banner -- passed to InteractiveConsole.interact()\n    readfunc -- if not None, replaces InteractiveConsole.raw_input()\n    local -- passed to InteractiveInterpreter.__init__()\n\n    \"\"\"\n    console = InteractiveConsole(local)\n    if readfunc is not None:\n        console.raw_input = readfunc\n    else:\n        try:\n            import readline\n        except ImportError:\n            pass\n    console.interact(banner)\n\n\nif __name__ == \"__main__\":\n    interact()\n", 
    "codecs": "\"\"\" codecs -- Python Codec Registry, API and helpers.\n\n\nWritten by Marc-Andre Lemburg (mal@lemburg.com).\n\n(c) Copyright CNRI, All Rights Reserved. NO WARRANTY.\n\n\"\"\"#\"\n\nimport __builtin__, sys\n\n### Registry and builtin stateless codec functions\n\ntry:\n    from _codecs import *\nexcept ImportError, why:\n    raise SystemError('Failed to load the builtin codecs: %s' % why)\n\n__all__ = [\"register\", \"lookup\", \"open\", \"EncodedFile\", \"BOM\", \"BOM_BE\",\n           \"BOM_LE\", \"BOM32_BE\", \"BOM32_LE\", \"BOM64_BE\", \"BOM64_LE\",\n           \"BOM_UTF8\", \"BOM_UTF16\", \"BOM_UTF16_LE\", \"BOM_UTF16_BE\",\n           \"BOM_UTF32\", \"BOM_UTF32_LE\", \"BOM_UTF32_BE\",\n           \"strict_errors\", \"ignore_errors\", \"replace_errors\",\n           \"xmlcharrefreplace_errors\",\n           \"register_error\", \"lookup_error\"]\n\n### Constants\n\n#\n# Byte Order Mark (BOM = ZERO WIDTH NO-BREAK SPACE = U+FEFF)\n# and its possible byte string values\n# for UTF8/UTF16/UTF32 output and little/big endian machines\n#\n\n# UTF-8\nBOM_UTF8 = '\\xef\\xbb\\xbf'\n\n# UTF-16, little endian\nBOM_LE = BOM_UTF16_LE = '\\xff\\xfe'\n\n# UTF-16, big endian\nBOM_BE = BOM_UTF16_BE = '\\xfe\\xff'\n\n# UTF-32, little endian\nBOM_UTF32_LE = '\\xff\\xfe\\x00\\x00'\n\n# UTF-32, big endian\nBOM_UTF32_BE = '\\x00\\x00\\xfe\\xff'\n\nif sys.byteorder == 'little':\n\n    # UTF-16, native endianness\n    BOM = BOM_UTF16 = BOM_UTF16_LE\n\n    # UTF-32, native endianness\n    BOM_UTF32 = BOM_UTF32_LE\n\nelse:\n\n    # UTF-16, native endianness\n    BOM = BOM_UTF16 = BOM_UTF16_BE\n\n    # UTF-32, native endianness\n    BOM_UTF32 = BOM_UTF32_BE\n\n# Old broken names (don't use in new code)\nBOM32_LE = BOM_UTF16_LE\nBOM32_BE = BOM_UTF16_BE\nBOM64_LE = BOM_UTF32_LE\nBOM64_BE = BOM_UTF32_BE\n\n\n### Codec base classes (defining the API)\n\nclass CodecInfo(tuple):\n\n    def __new__(cls, encode, decode, streamreader=None, streamwriter=None,\n        incrementalencoder=None, incrementaldecoder=None, name=None):\n        self = tuple.__new__(cls, (encode, decode, streamreader, streamwriter))\n        self.name = name\n        self.encode = encode\n        self.decode = decode\n        self.incrementalencoder = incrementalencoder\n        self.incrementaldecoder = incrementaldecoder\n        self.streamwriter = streamwriter\n        self.streamreader = streamreader\n        return self\n\n    def __repr__(self):\n        return \"<%s.%s object for encoding %s at 0x%x>\" % (self.__class__.__module__, self.__class__.__name__, self.name, id(self))\n\nclass Codec:\n\n    \"\"\" Defines the interface for stateless encoders/decoders.\n\n        The .encode()/.decode() methods may use different error\n        handling schemes by providing the errors argument. These\n        string values are predefined:\n\n         'strict' - raise a ValueError error (or a subclass)\n         'ignore' - ignore the character and continue with the next\n         'replace' - replace with a suitable replacement character;\n                    Python will use the official U+FFFD REPLACEMENT\n                    CHARACTER for the builtin Unicode codecs on\n                    decoding and '?' on encoding.\n         'xmlcharrefreplace' - Replace with the appropriate XML\n                               character reference (only for encoding).\n         'backslashreplace'  - Replace with backslashed escape sequences\n                               (only for encoding).\n\n        The set of allowed values can be extended via register_error.\n\n    \"\"\"\n    def encode(self, input, errors='strict'):\n\n        \"\"\" Encodes the object input and returns a tuple (output\n            object, length consumed).\n\n            errors defines the error handling to apply. It defaults to\n            'strict' handling.\n\n            The method may not store state in the Codec instance. Use\n            StreamCodec for codecs which have to keep state in order to\n            make encoding/decoding efficient.\n\n            The encoder must be able to handle zero length input and\n            return an empty object of the output object type in this\n            situation.\n\n        \"\"\"\n        raise NotImplementedError\n\n    def decode(self, input, errors='strict'):\n\n        \"\"\" Decodes the object input and returns a tuple (output\n            object, length consumed).\n\n            input must be an object which provides the bf_getreadbuf\n            buffer slot. Python strings, buffer objects and memory\n            mapped files are examples of objects providing this slot.\n\n            errors defines the error handling to apply. It defaults to\n            'strict' handling.\n\n            The method may not store state in the Codec instance. Use\n            StreamCodec for codecs which have to keep state in order to\n            make encoding/decoding efficient.\n\n            The decoder must be able to handle zero length input and\n            return an empty object of the output object type in this\n            situation.\n\n        \"\"\"\n        raise NotImplementedError\n\nclass IncrementalEncoder(object):\n    \"\"\"\n    An IncrementalEncoder encodes an input in multiple steps. The input can be\n    passed piece by piece to the encode() method. The IncrementalEncoder remembers\n    the state of the Encoding process between calls to encode().\n    \"\"\"\n    def __init__(self, errors='strict'):\n        \"\"\"\n        Creates an IncrementalEncoder instance.\n\n        The IncrementalEncoder may use different error handling schemes by\n        providing the errors keyword argument. See the module docstring\n        for a list of possible values.\n        \"\"\"\n        self.errors = errors\n        self.buffer = \"\"\n\n    def encode(self, input, final=False):\n        \"\"\"\n        Encodes input and returns the resulting object.\n        \"\"\"\n        raise NotImplementedError\n\n    def reset(self):\n        \"\"\"\n        Resets the encoder to the initial state.\n        \"\"\"\n\n    def getstate(self):\n        \"\"\"\n        Return the current state of the encoder.\n        \"\"\"\n        return 0\n\n    def setstate(self, state):\n        \"\"\"\n        Set the current state of the encoder. state must have been\n        returned by getstate().\n        \"\"\"\n\nclass BufferedIncrementalEncoder(IncrementalEncoder):\n    \"\"\"\n    This subclass of IncrementalEncoder can be used as the baseclass for an\n    incremental encoder if the encoder must keep some of the output in a\n    buffer between calls to encode().\n    \"\"\"\n    def __init__(self, errors='strict'):\n        IncrementalEncoder.__init__(self, errors)\n        self.buffer = \"\" # unencoded input that is kept between calls to encode()\n\n    def _buffer_encode(self, input, errors, final):\n        # Overwrite this method in subclasses: It must encode input\n        # and return an (output, length consumed) tuple\n        raise NotImplementedError\n\n    def encode(self, input, final=False):\n        # encode input (taking the buffer into account)\n        data = self.buffer + input\n        (result, consumed) = self._buffer_encode(data, self.errors, final)\n        # keep unencoded input until the next call\n        self.buffer = data[consumed:]\n        return result\n\n    def reset(self):\n        IncrementalEncoder.reset(self)\n        self.buffer = \"\"\n\n    def getstate(self):\n        return self.buffer or 0\n\n    def setstate(self, state):\n        self.buffer = state or \"\"\n\nclass IncrementalDecoder(object):\n    \"\"\"\n    An IncrementalDecoder decodes an input in multiple steps. The input can be\n    passed piece by piece to the decode() method. The IncrementalDecoder\n    remembers the state of the decoding process between calls to decode().\n    \"\"\"\n    def __init__(self, errors='strict'):\n        \"\"\"\n        Creates a IncrementalDecoder instance.\n\n        The IncrementalDecoder may use different error handling schemes by\n        providing the errors keyword argument. See the module docstring\n        for a list of possible values.\n        \"\"\"\n        self.errors = errors\n\n    def decode(self, input, final=False):\n        \"\"\"\n        Decodes input and returns the resulting object.\n        \"\"\"\n        raise NotImplementedError\n\n    def reset(self):\n        \"\"\"\n        Resets the decoder to the initial state.\n        \"\"\"\n\n    def getstate(self):\n        \"\"\"\n        Return the current state of the decoder.\n\n        This must be a (buffered_input, additional_state_info) tuple.\n        buffered_input must be a bytes object containing bytes that\n        were passed to decode() that have not yet been converted.\n        additional_state_info must be a non-negative integer\n        representing the state of the decoder WITHOUT yet having\n        processed the contents of buffered_input.  In the initial state\n        and after reset(), getstate() must return (b\"\", 0).\n        \"\"\"\n        return (b\"\", 0)\n\n    def setstate(self, state):\n        \"\"\"\n        Set the current state of the decoder.\n\n        state must have been returned by getstate().  The effect of\n        setstate((b\"\", 0)) must be equivalent to reset().\n        \"\"\"\n\nclass BufferedIncrementalDecoder(IncrementalDecoder):\n    \"\"\"\n    This subclass of IncrementalDecoder can be used as the baseclass for an\n    incremental decoder if the decoder must be able to handle incomplete byte\n    sequences.\n    \"\"\"\n    def __init__(self, errors='strict'):\n        IncrementalDecoder.__init__(self, errors)\n        self.buffer = \"\" # undecoded input that is kept between calls to decode()\n\n    def _buffer_decode(self, input, errors, final):\n        # Overwrite this method in subclasses: It must decode input\n        # and return an (output, length consumed) tuple\n        raise NotImplementedError\n\n    def decode(self, input, final=False):\n        # decode input (taking the buffer into account)\n        data = self.buffer + input\n        (result, consumed) = self._buffer_decode(data, self.errors, final)\n        # keep undecoded input until the next call\n        self.buffer = data[consumed:]\n        return result\n\n    def reset(self):\n        IncrementalDecoder.reset(self)\n        self.buffer = \"\"\n\n    def getstate(self):\n        # additional state info is always 0\n        return (self.buffer, 0)\n\n    def setstate(self, state):\n        # ignore additional state info\n        self.buffer = state[0]\n\n#\n# The StreamWriter and StreamReader class provide generic working\n# interfaces which can be used to implement new encoding submodules\n# very easily. See encodings/utf_8.py for an example on how this is\n# done.\n#\n\nclass StreamWriter(Codec):\n\n    def __init__(self, stream, errors='strict'):\n\n        \"\"\" Creates a StreamWriter instance.\n\n            stream must be a file-like object open for writing\n            (binary) data.\n\n            The StreamWriter may use different error handling\n            schemes by providing the errors keyword argument. These\n            parameters are predefined:\n\n             'strict' - raise a ValueError (or a subclass)\n             'ignore' - ignore the character and continue with the next\n             'replace'- replace with a suitable replacement character\n             'xmlcharrefreplace' - Replace with the appropriate XML\n                                   character reference.\n             'backslashreplace'  - Replace with backslashed escape\n                                   sequences (only for encoding).\n\n            The set of allowed parameter values can be extended via\n            register_error.\n        \"\"\"\n        self.stream = stream\n        self.errors = errors\n\n    def write(self, object):\n\n        \"\"\" Writes the object's contents encoded to self.stream.\n        \"\"\"\n        data, consumed = self.encode(object, self.errors)\n        self.stream.write(data)\n\n    def writelines(self, list):\n\n        \"\"\" Writes the concatenated list of strings to the stream\n            using .write().\n        \"\"\"\n        self.write(''.join(list))\n\n    def reset(self):\n\n        \"\"\" Flushes and resets the codec buffers used for keeping state.\n\n            Calling this method should ensure that the data on the\n            output is put into a clean state, that allows appending\n            of new fresh data without having to rescan the whole\n            stream to recover state.\n\n        \"\"\"\n        pass\n\n    def seek(self, offset, whence=0):\n        self.stream.seek(offset, whence)\n        if whence == 0 and offset == 0:\n            self.reset()\n\n    def __getattr__(self, name,\n                    getattr=getattr):\n\n        \"\"\" Inherit all other methods from the underlying stream.\n        \"\"\"\n        return getattr(self.stream, name)\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, type, value, tb):\n        self.stream.close()\n\n###\n\nclass StreamReader(Codec):\n\n    def __init__(self, stream, errors='strict'):\n\n        \"\"\" Creates a StreamReader instance.\n\n            stream must be a file-like object open for reading\n            (binary) data.\n\n            The StreamReader may use different error handling\n            schemes by providing the errors keyword argument. These\n            parameters are predefined:\n\n             'strict' - raise a ValueError (or a subclass)\n             'ignore' - ignore the character and continue with the next\n             'replace'- replace with a suitable replacement character;\n\n            The set of allowed parameter values can be extended via\n            register_error.\n        \"\"\"\n        self.stream = stream\n        self.errors = errors\n        self.bytebuffer = \"\"\n        # For str->str decoding this will stay a str\n        # For str->unicode decoding the first read will promote it to unicode\n        self.charbuffer = \"\"\n        self.linebuffer = None\n\n    def decode(self, input, errors='strict'):\n        raise NotImplementedError\n\n    def read(self, size=-1, chars=-1, firstline=False):\n\n        \"\"\" Decodes data from the stream self.stream and returns the\n            resulting object.\n\n            chars indicates the number of characters to read from the\n            stream. read() will never return more than chars\n            characters, but it might return less, if there are not enough\n            characters available.\n\n            size indicates the approximate maximum number of bytes to\n            read from the stream for decoding purposes. The decoder\n            can modify this setting as appropriate. The default value\n            -1 indicates to read and decode as much as possible.  size\n            is intended to prevent having to decode huge files in one\n            step.\n\n            If firstline is true, and a UnicodeDecodeError happens\n            after the first line terminator in the input only the first line\n            will be returned, the rest of the input will be kept until the\n            next call to read().\n\n            The method should use a greedy read strategy meaning that\n            it should read as much data as is allowed within the\n            definition of the encoding and the given size, e.g.  if\n            optional encoding endings or state markers are available\n            on the stream, these should be read too.\n        \"\"\"\n        # If we have lines cached, first merge them back into characters\n        if self.linebuffer:\n            self.charbuffer = \"\".join(self.linebuffer)\n            self.linebuffer = None\n\n        # read until we get the required number of characters (if available)\n        while True:\n            # can the request be satisfied from the character buffer?\n            if chars >= 0:\n                if len(self.charbuffer) >= chars:\n                    break\n            elif size >= 0:\n                if len(self.charbuffer) >= size:\n                    break\n            # we need more data\n            if size < 0:\n                newdata = self.stream.read()\n            else:\n                newdata = self.stream.read(size)\n            # decode bytes (those remaining from the last call included)\n            data = self.bytebuffer + newdata\n            try:\n                newchars, decodedbytes = self.decode(data, self.errors)\n            except UnicodeDecodeError, exc:\n                if firstline:\n                    newchars, decodedbytes = self.decode(data[:exc.start], self.errors)\n                    lines = newchars.splitlines(True)\n                    if len(lines)<=1:\n                        raise\n                else:\n                    raise\n            # keep undecoded bytes until the next call\n            self.bytebuffer = data[decodedbytes:]\n            # put new characters in the character buffer\n            self.charbuffer += newchars\n            # there was no data available\n            if not newdata:\n                break\n        if chars < 0:\n            # Return everything we've got\n            result = self.charbuffer\n            self.charbuffer = \"\"\n        else:\n            # Return the first chars characters\n            result = self.charbuffer[:chars]\n            self.charbuffer = self.charbuffer[chars:]\n        return result\n\n    def readline(self, size=None, keepends=True):\n\n        \"\"\" Read one line from the input stream and return the\n            decoded data.\n\n            size, if given, is passed as size argument to the\n            read() method.\n\n        \"\"\"\n        # If we have lines cached from an earlier read, return\n        # them unconditionally\n        if self.linebuffer:\n            line = self.linebuffer[0]\n            del self.linebuffer[0]\n            if len(self.linebuffer) == 1:\n                # revert to charbuffer mode; we might need more data\n                # next time\n                self.charbuffer = self.linebuffer[0]\n                self.linebuffer = None\n            if not keepends:\n                line = line.splitlines(False)[0]\n            return line\n\n        readsize = size or 72\n        line = \"\"\n        # If size is given, we call read() only once\n        while True:\n            data = self.read(readsize, firstline=True)\n            if data:\n                # If we're at a \"\\r\" read one extra character (which might\n                # be a \"\\n\") to get a proper line ending. If the stream is\n                # temporarily exhausted we return the wrong line ending.\n                if data.endswith(\"\\r\"):\n                    data += self.read(size=1, chars=1)\n\n            line += data\n            lines = line.splitlines(True)\n            if lines:\n                if len(lines) > 1:\n                    # More than one line result; the first line is a full line\n                    # to return\n                    line = lines[0]\n                    del lines[0]\n                    if len(lines) > 1:\n                        # cache the remaining lines\n                        lines[-1] += self.charbuffer\n                        self.linebuffer = lines\n                        self.charbuffer = None\n                    else:\n                        # only one remaining line, put it back into charbuffer\n                        self.charbuffer = lines[0] + self.charbuffer\n                    if not keepends:\n                        line = line.splitlines(False)[0]\n                    break\n                line0withend = lines[0]\n                line0withoutend = lines[0].splitlines(False)[0]\n                if line0withend != line0withoutend: # We really have a line end\n                    # Put the rest back together and keep it until the next call\n                    self.charbuffer = \"\".join(lines[1:]) + self.charbuffer\n                    if keepends:\n                        line = line0withend\n                    else:\n                        line = line0withoutend\n                    break\n            # we didn't get anything or this was our only try\n            if not data or size is not None:\n                if line and not keepends:\n                    line = line.splitlines(False)[0]\n                break\n            if readsize<8000:\n                readsize *= 2\n        return line\n\n    def readlines(self, sizehint=None, keepends=True):\n\n        \"\"\" Read all lines available on the input stream\n            and return them as list of lines.\n\n            Line breaks are implemented using the codec's decoder\n            method and are included in the list entries.\n\n            sizehint, if given, is ignored since there is no efficient\n            way to finding the true end-of-line.\n\n        \"\"\"\n        data = self.read()\n        return data.splitlines(keepends)\n\n    def reset(self):\n\n        \"\"\" Resets the codec buffers used for keeping state.\n\n            Note that no stream repositioning should take place.\n            This method is primarily intended to be able to recover\n            from decoding errors.\n\n        \"\"\"\n        self.bytebuffer = \"\"\n        self.charbuffer = u\"\"\n        self.linebuffer = None\n\n    def seek(self, offset, whence=0):\n        \"\"\" Set the input stream's current position.\n\n            Resets the codec buffers used for keeping state.\n        \"\"\"\n        self.stream.seek(offset, whence)\n        self.reset()\n\n    def next(self):\n\n        \"\"\" Return the next decoded line from the input stream.\"\"\"\n        line = self.readline()\n        if line:\n            return line\n        raise StopIteration\n\n    def __iter__(self):\n        return self\n\n    def __getattr__(self, name,\n                    getattr=getattr):\n\n        \"\"\" Inherit all other methods from the underlying stream.\n        \"\"\"\n        return getattr(self.stream, name)\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, type, value, tb):\n        self.stream.close()\n\n###\n\nclass StreamReaderWriter:\n\n    \"\"\" StreamReaderWriter instances allow wrapping streams which\n        work in both read and write modes.\n\n        The design is such that one can use the factory functions\n        returned by the codec.lookup() function to construct the\n        instance.\n\n    \"\"\"\n    # Optional attributes set by the file wrappers below\n    encoding = 'unknown'\n\n    def __init__(self, stream, Reader, Writer, errors='strict'):\n\n        \"\"\" Creates a StreamReaderWriter instance.\n\n            stream must be a Stream-like object.\n\n            Reader, Writer must be factory functions or classes\n            providing the StreamReader, StreamWriter interface resp.\n\n            Error handling is done in the same way as defined for the\n            StreamWriter/Readers.\n\n        \"\"\"\n        self.stream = stream\n        self.reader = Reader(stream, errors)\n        self.writer = Writer(stream, errors)\n        self.errors = errors\n\n    def read(self, size=-1):\n\n        return self.reader.read(size)\n\n    def readline(self, size=None):\n\n        return self.reader.readline(size)\n\n    def readlines(self, sizehint=None):\n\n        return self.reader.readlines(sizehint)\n\n    def next(self):\n\n        \"\"\" Return the next decoded line from the input stream.\"\"\"\n        return self.reader.next()\n\n    def __iter__(self):\n        return self\n\n    def write(self, data):\n\n        return self.writer.write(data)\n\n    def writelines(self, list):\n\n        return self.writer.writelines(list)\n\n    def reset(self):\n\n        self.reader.reset()\n        self.writer.reset()\n\n    def seek(self, offset, whence=0):\n        self.stream.seek(offset, whence)\n        self.reader.reset()\n        if whence == 0 and offset == 0:\n            self.writer.reset()\n\n    def __getattr__(self, name,\n                    getattr=getattr):\n\n        \"\"\" Inherit all other methods from the underlying stream.\n        \"\"\"\n        return getattr(self.stream, name)\n\n    # these are needed to make \"with codecs.open(...)\" work properly\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, type, value, tb):\n        self.stream.close()\n\n###\n\nclass StreamRecoder:\n\n    \"\"\" StreamRecoder instances provide a frontend - backend\n        view of encoding data.\n\n        They use the complete set of APIs returned by the\n        codecs.lookup() function to implement their task.\n\n        Data written to the stream is first decoded into an\n        intermediate format (which is dependent on the given codec\n        combination) and then written to the stream using an instance\n        of the provided Writer class.\n\n        In the other direction, data is read from the stream using a\n        Reader instance and then return encoded data to the caller.\n\n    \"\"\"\n    # Optional attributes set by the file wrappers below\n    data_encoding = 'unknown'\n    file_encoding = 'unknown'\n\n    def __init__(self, stream, encode, decode, Reader, Writer,\n                 errors='strict'):\n\n        \"\"\" Creates a StreamRecoder instance which implements a two-way\n            conversion: encode and decode work on the frontend (the\n            input to .read() and output of .write()) while\n            Reader and Writer work on the backend (reading and\n            writing to the stream).\n\n            You can use these objects to do transparent direct\n            recodings from e.g. latin-1 to utf-8 and back.\n\n            stream must be a file-like object.\n\n            encode, decode must adhere to the Codec interface, Reader,\n            Writer must be factory functions or classes providing the\n            StreamReader, StreamWriter interface resp.\n\n            encode and decode are needed for the frontend translation,\n            Reader and Writer for the backend translation. Unicode is\n            used as intermediate encoding.\n\n            Error handling is done in the same way as defined for the\n            StreamWriter/Readers.\n\n        \"\"\"\n        self.stream = stream\n        self.encode = encode\n        self.decode = decode\n        self.reader = Reader(stream, errors)\n        self.writer = Writer(stream, errors)\n        self.errors = errors\n\n    def read(self, size=-1):\n\n        data = self.reader.read(size)\n        data, bytesencoded = self.encode(data, self.errors)\n        return data\n\n    def readline(self, size=None):\n\n        if size is None:\n            data = self.reader.readline()\n        else:\n            data = self.reader.readline(size)\n        data, bytesencoded = self.encode(data, self.errors)\n        return data\n\n    def readlines(self, sizehint=None):\n\n        data = self.reader.read()\n        data, bytesencoded = self.encode(data, self.errors)\n        return data.splitlines(1)\n\n    def next(self):\n\n        \"\"\" Return the next decoded line from the input stream.\"\"\"\n        data = self.reader.next()\n        data, bytesencoded = self.encode(data, self.errors)\n        return data\n\n    def __iter__(self):\n        return self\n\n    def write(self, data):\n\n        data, bytesdecoded = self.decode(data, self.errors)\n        return self.writer.write(data)\n\n    def writelines(self, list):\n\n        data = ''.join(list)\n        data, bytesdecoded = self.decode(data, self.errors)\n        return self.writer.write(data)\n\n    def reset(self):\n\n        self.reader.reset()\n        self.writer.reset()\n\n    def __getattr__(self, name,\n                    getattr=getattr):\n\n        \"\"\" Inherit all other methods from the underlying stream.\n        \"\"\"\n        return getattr(self.stream, name)\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, type, value, tb):\n        self.stream.close()\n\n### Shortcuts\n\ndef open(filename, mode='rb', encoding=None, errors='strict', buffering=1):\n\n    \"\"\" Open an encoded file using the given mode and return\n        a wrapped version providing transparent encoding/decoding.\n\n        Note: The wrapped version will only accept the object format\n        defined by the codecs, i.e. Unicode objects for most builtin\n        codecs. Output is also codec dependent and will usually be\n        Unicode as well.\n\n        Files are always opened in binary mode, even if no binary mode\n        was specified. This is done to avoid data loss due to encodings\n        using 8-bit values. The default file mode is 'rb' meaning to\n        open the file in binary read mode.\n\n        encoding specifies the encoding which is to be used for the\n        file.\n\n        errors may be given to define the error handling. It defaults\n        to 'strict' which causes ValueErrors to be raised in case an\n        encoding error occurs.\n\n        buffering has the same meaning as for the builtin open() API.\n        It defaults to line buffered.\n\n        The returned wrapped file object provides an extra attribute\n        .encoding which allows querying the used encoding. This\n        attribute is only available if an encoding was specified as\n        parameter.\n\n    \"\"\"\n    if encoding is not None:\n        if 'U' in mode:\n            # No automatic conversion of '\\n' is done on reading and writing\n            mode = mode.strip().replace('U', '')\n            if mode[:1] not in set('rwa'):\n                mode = 'r' + mode\n        if 'b' not in mode:\n            # Force opening of the file in binary mode\n            mode = mode + 'b'\n    file = __builtin__.open(filename, mode, buffering)\n    if encoding is None:\n        return file\n    info = lookup(encoding)\n    srw = StreamReaderWriter(file, info.streamreader, info.streamwriter, errors)\n    # Add attributes to simplify introspection\n    srw.encoding = encoding\n    return srw\n\ndef EncodedFile(file, data_encoding, file_encoding=None, errors='strict'):\n\n    \"\"\" Return a wrapped version of file which provides transparent\n        encoding translation.\n\n        Strings written to the wrapped file are interpreted according\n        to the given data_encoding and then written to the original\n        file as string using file_encoding. The intermediate encoding\n        will usually be Unicode but depends on the specified codecs.\n\n        Strings are read from the file using file_encoding and then\n        passed back to the caller as string using data_encoding.\n\n        If file_encoding is not given, it defaults to data_encoding.\n\n        errors may be given to define the error handling. It defaults\n        to 'strict' which causes ValueErrors to be raised in case an\n        encoding error occurs.\n\n        The returned wrapped file object provides two extra attributes\n        .data_encoding and .file_encoding which reflect the given\n        parameters of the same name. The attributes can be used for\n        introspection by Python programs.\n\n    \"\"\"\n    if file_encoding is None:\n        file_encoding = data_encoding\n    data_info = lookup(data_encoding)\n    file_info = lookup(file_encoding)\n    sr = StreamRecoder(file, data_info.encode, data_info.decode,\n                       file_info.streamreader, file_info.streamwriter, errors)\n    # Add attributes to simplify introspection\n    sr.data_encoding = data_encoding\n    sr.file_encoding = file_encoding\n    return sr\n\n### Helpers for codec lookup\n\ndef getencoder(encoding):\n\n    \"\"\" Lookup up the codec for the given encoding and return\n        its encoder function.\n\n        Raises a LookupError in case the encoding cannot be found.\n\n    \"\"\"\n    return lookup(encoding).encode\n\ndef getdecoder(encoding):\n\n    \"\"\" Lookup up the codec for the given encoding and return\n        its decoder function.\n\n        Raises a LookupError in case the encoding cannot be found.\n\n    \"\"\"\n    return lookup(encoding).decode\n\ndef getincrementalencoder(encoding):\n\n    \"\"\" Lookup up the codec for the given encoding and return\n        its IncrementalEncoder class or factory function.\n\n        Raises a LookupError in case the encoding cannot be found\n        or the codecs doesn't provide an incremental encoder.\n\n    \"\"\"\n    encoder = lookup(encoding).incrementalencoder\n    if encoder is None:\n        raise LookupError(encoding)\n    return encoder\n\ndef getincrementaldecoder(encoding):\n\n    \"\"\" Lookup up the codec for the given encoding and return\n        its IncrementalDecoder class or factory function.\n\n        Raises a LookupError in case the encoding cannot be found\n        or the codecs doesn't provide an incremental decoder.\n\n    \"\"\"\n    decoder = lookup(encoding).incrementaldecoder\n    if decoder is None:\n        raise LookupError(encoding)\n    return decoder\n\ndef getreader(encoding):\n\n    \"\"\" Lookup up the codec for the given encoding and return\n        its StreamReader class or factory function.\n\n        Raises a LookupError in case the encoding cannot be found.\n\n    \"\"\"\n    return lookup(encoding).streamreader\n\ndef getwriter(encoding):\n\n    \"\"\" Lookup up the codec for the given encoding and return\n        its StreamWriter class or factory function.\n\n        Raises a LookupError in case the encoding cannot be found.\n\n    \"\"\"\n    return lookup(encoding).streamwriter\n\ndef iterencode(iterator, encoding, errors='strict', **kwargs):\n    \"\"\"\n    Encoding iterator.\n\n    Encodes the input strings from the iterator using a IncrementalEncoder.\n\n    errors and kwargs are passed through to the IncrementalEncoder\n    constructor.\n    \"\"\"\n    encoder = getincrementalencoder(encoding)(errors, **kwargs)\n    for input in iterator:\n        output = encoder.encode(input)\n        if output:\n            yield output\n    output = encoder.encode(\"\", True)\n    if output:\n        yield output\n\ndef iterdecode(iterator, encoding, errors='strict', **kwargs):\n    \"\"\"\n    Decoding iterator.\n\n    Decodes the input strings from the iterator using a IncrementalDecoder.\n\n    errors and kwargs are passed through to the IncrementalDecoder\n    constructor.\n    \"\"\"\n    decoder = getincrementaldecoder(encoding)(errors, **kwargs)\n    for input in iterator:\n        output = decoder.decode(input)\n        if output:\n            yield output\n    output = decoder.decode(\"\", True)\n    if output:\n        yield output\n\n### Helpers for charmap-based codecs\n\ndef make_identity_dict(rng):\n\n    \"\"\" make_identity_dict(rng) -> dict\n\n        Return a dictionary where elements of the rng sequence are\n        mapped to themselves.\n\n    \"\"\"\n    res = {}\n    for i in rng:\n        res[i]=i\n    return res\n\ndef make_encoding_map(decoding_map):\n\n    \"\"\" Creates an encoding map from a decoding map.\n\n        If a target mapping in the decoding map occurs multiple\n        times, then that target is mapped to None (undefined mapping),\n        causing an exception when encountered by the charmap codec\n        during translation.\n\n        One example where this happens is cp875.py which decodes\n        multiple character to \\u001a.\n\n    \"\"\"\n    m = {}\n    for k,v in decoding_map.items():\n        if not v in m:\n            m[v] = k\n        else:\n            m[v] = None\n    return m\n\n### error handlers\n\ntry:\n    strict_errors = lookup_error(\"strict\")\n    ignore_errors = lookup_error(\"ignore\")\n    replace_errors = lookup_error(\"replace\")\n    xmlcharrefreplace_errors = lookup_error(\"xmlcharrefreplace\")\n    backslashreplace_errors = lookup_error(\"backslashreplace\")\nexcept LookupError:\n    # In --disable-unicode builds, these error handler are missing\n    strict_errors = None\n    ignore_errors = None\n    replace_errors = None\n    xmlcharrefreplace_errors = None\n    backslashreplace_errors = None\n\n# Tell modulefinder that using codecs probably needs the encodings\n# package\n_false = 0\nif _false:\n    import encodings\n\n### Tests\n\nif __name__ == '__main__':\n\n    # Make stdout translate Latin-1 output into UTF-8 output\n    sys.stdout = EncodedFile(sys.stdout, 'latin-1', 'utf-8')\n\n    # Have stdin translate Latin-1 input into UTF-8 input\n    sys.stdin = EncodedFile(sys.stdin, 'utf-8', 'latin-1')\n", 
    "codeop": "r\"\"\"Utilities to compile possibly incomplete Python source code.\n\nThis module provides two interfaces, broadly similar to the builtin\nfunction compile(), which take program text, a filename and a 'mode'\nand:\n\n- Return code object if the command is complete and valid\n- Return None if the command is incomplete\n- Raise SyntaxError, ValueError or OverflowError if the command is a\n  syntax error (OverflowError and ValueError can be produced by\n  malformed literals).\n\nApproach:\n\nFirst, check if the source consists entirely of blank lines and\ncomments; if so, replace it with 'pass', because the built-in\nparser doesn't always do the right thing for these.\n\nCompile three times: as is, with \\n, and with \\n\\n appended.  If it\ncompiles as is, it's complete.  If it compiles with one \\n appended,\nwe expect more.  If it doesn't compile either way, we compare the\nerror we get when compiling with \\n or \\n\\n appended.  If the errors\nare the same, the code is broken.  But if the errors are different, we\nexpect more.  Not intuitive; not even guaranteed to hold in future\nreleases; but this matches the compiler's behavior from Python 1.4\nthrough 2.2, at least.\n\nCaveat:\n\nIt is possible (but not likely) that the parser stops parsing with a\nsuccessful outcome before reaching the end of the source; in this\ncase, trailing symbols may be ignored instead of causing an error.\nFor example, a backslash followed by two newlines may be followed by\narbitrary garbage.  This will be fixed once the API for the parser is\nbetter.\n\nThe two interfaces are:\n\ncompile_command(source, filename, symbol):\n\n    Compiles a single command in the manner described above.\n\nCommandCompiler():\n\n    Instances of this class have __call__ methods identical in\n    signature to compile_command; the difference is that if the\n    instance compiles program text containing a __future__ statement,\n    the instance 'remembers' and compiles all subsequent program texts\n    with the statement in force.\n\nThe module also provides another class:\n\nCompile():\n\n    Instances of this class act like the built-in function compile,\n    but with 'memory' in the sense described above.\n\"\"\"\n\nimport __future__\n\n_features = [getattr(__future__, fname)\n             for fname in __future__.all_feature_names]\n\n__all__ = [\"compile_command\", \"Compile\", \"CommandCompiler\"]\n\nPyCF_DONT_IMPLY_DEDENT = 0x200          # Matches pythonrun.h\n\ndef _maybe_compile(compiler, source, filename, symbol):\n    # Check for source consisting of only blank lines and comments\n    for line in source.split(\"\\n\"):\n        line = line.strip()\n        if line and line[0] != '#':\n            break               # Leave it alone\n    else:\n        if symbol != \"eval\":\n            source = \"pass\"     # Replace it with a 'pass' statement\n\n    err = err1 = err2 = None\n    code = code1 = code2 = None\n\n    try:\n        code = compiler(source, filename, symbol)\n    except SyntaxError, err:\n        pass\n\n    try:\n        code1 = compiler(source + \"\\n\", filename, symbol)\n    except SyntaxError, err1:\n        pass\n\n    try:\n        code2 = compiler(source + \"\\n\\n\", filename, symbol)\n    except SyntaxError, err2:\n        pass\n\n    if code:\n        return code\n    if not code1 and repr(err1) == repr(err2):\n        raise SyntaxError, err1\n\ndef _compile(source, filename, symbol):\n    return compile(source, filename, symbol, PyCF_DONT_IMPLY_DEDENT)\n\ndef compile_command(source, filename=\"<input>\", symbol=\"single\"):\n    r\"\"\"Compile a command and determine whether it is incomplete.\n\n    Arguments:\n\n    source -- the source string; may contain \\n characters\n    filename -- optional filename from which source was read; default\n                \"<input>\"\n    symbol -- optional grammar start symbol; \"single\" (default) or \"eval\"\n\n    Return value / exceptions raised:\n\n    - Return a code object if the command is complete and valid\n    - Return None if the command is incomplete\n    - Raise SyntaxError, ValueError or OverflowError if the command is a\n      syntax error (OverflowError and ValueError can be produced by\n      malformed literals).\n    \"\"\"\n    return _maybe_compile(_compile, source, filename, symbol)\n\nclass Compile:\n    \"\"\"Instances of this class behave much like the built-in compile\n    function, but if one is used to compile text containing a future\n    statement, it \"remembers\" and compiles all subsequent program texts\n    with the statement in force.\"\"\"\n    def __init__(self):\n        self.flags = PyCF_DONT_IMPLY_DEDENT\n\n    def __call__(self, source, filename, symbol):\n        codeob = compile(source, filename, symbol, self.flags, 1)\n        for feature in _features:\n            if codeob.co_flags & feature.compiler_flag:\n                self.flags |= feature.compiler_flag\n        return codeob\n\nclass CommandCompiler:\n    \"\"\"Instances of this class have __call__ methods identical in\n    signature to compile_command; the difference is that if the\n    instance compiles program text containing a __future__ statement,\n    the instance 'remembers' and compiles all subsequent program texts\n    with the statement in force.\"\"\"\n\n    def __init__(self,):\n        self.compiler = Compile()\n\n    def __call__(self, source, filename=\"<input>\", symbol=\"single\"):\n        r\"\"\"Compile a command and determine whether it is incomplete.\n\n        Arguments:\n\n        source -- the source string; may contain \\n characters\n        filename -- optional filename from which source was read;\n                    default \"<input>\"\n        symbol -- optional grammar start symbol; \"single\" (default) or\n                  \"eval\"\n\n        Return value / exceptions raised:\n\n        - Return a code object if the command is complete and valid\n        - Return None if the command is incomplete\n        - Raise SyntaxError, ValueError or OverflowError if the command is a\n          syntax error (OverflowError and ValueError can be produced by\n          malformed literals).\n        \"\"\"\n        return _maybe_compile(self.compiler, source, filename, symbol)\n", 
    "copy": "\"\"\"Generic (shallow and deep) copying operations.\n\nInterface summary:\n\n        import copy\n\n        x = copy.copy(y)        # make a shallow copy of y\n        x = copy.deepcopy(y)    # make a deep copy of y\n\nFor module specific errors, copy.Error is raised.\n\nThe difference between shallow and deep copying is only relevant for\ncompound objects (objects that contain other objects, like lists or\nclass instances).\n\n- A shallow copy constructs a new compound object and then (to the\n  extent possible) inserts *the same objects* into it that the\n  original contains.\n\n- A deep copy constructs a new compound object and then, recursively,\n  inserts *copies* into it of the objects found in the original.\n\nTwo problems often exist with deep copy operations that don't exist\nwith shallow copy operations:\n\n a) recursive objects (compound objects that, directly or indirectly,\n    contain a reference to themselves) may cause a recursive loop\n\n b) because deep copy copies *everything* it may copy too much, e.g.\n    administrative data structures that should be shared even between\n    copies\n\nPython's deep copy operation avoids these problems by:\n\n a) keeping a table of objects already copied during the current\n    copying pass\n\n b) letting user-defined classes override the copying operation or the\n    set of components copied\n\nThis version does not copy types like module, class, function, method,\nnor stack trace, stack frame, nor file, socket, window, nor array, nor\nany similar types.\n\nClasses can use the same interfaces to control copying that they use\nto control pickling: they can define methods called __getinitargs__(),\n__getstate__() and __setstate__().  See the documentation for module\n\"pickle\" for information on these methods.\n\"\"\"\n\nimport types\nimport weakref\nfrom copy_reg import dispatch_table\n\nclass Error(Exception):\n    pass\nerror = Error   # backward compatibility\n\ntry:\n    from org.python.core import PyStringMap\nexcept ImportError:\n    PyStringMap = None\n\n__all__ = [\"Error\", \"copy\", \"deepcopy\"]\n\ndef copy(x):\n    \"\"\"Shallow copy operation on arbitrary Python objects.\n\n    See the module's __doc__ string for more info.\n    \"\"\"\n\n    cls = type(x)\n\n    copier = _copy_dispatch.get(cls)\n    if copier:\n        return copier(x)\n\n    copier = getattr(cls, \"__copy__\", None)\n    if copier:\n        return copier(x)\n\n    reductor = dispatch_table.get(cls)\n    if reductor:\n        rv = reductor(x)\n    else:\n        reductor = getattr(x, \"__reduce_ex__\", None)\n        if reductor:\n            rv = reductor(2)\n        else:\n            reductor = getattr(x, \"__reduce__\", None)\n            if reductor:\n                rv = reductor()\n            else:\n                raise Error(\"un(shallow)copyable object of type %s\" % cls)\n\n    return _reconstruct(x, rv, 0)\n\n\n_copy_dispatch = d = {}\n\ndef _copy_immutable(x):\n    return x\nfor t in (type(None), int, long, float, bool, str, tuple,\n          frozenset, type, xrange, types.ClassType,\n          types.BuiltinFunctionType, type(Ellipsis),\n          types.FunctionType, weakref.ref):\n    d[t] = _copy_immutable\nfor name in (\"ComplexType\", \"UnicodeType\", \"CodeType\"):\n    t = getattr(types, name, None)\n    if t is not None:\n        d[t] = _copy_immutable\n\ndef _copy_with_constructor(x):\n    return type(x)(x)\nfor t in (list, dict, set):\n    d[t] = _copy_with_constructor\n\ndef _copy_with_copy_method(x):\n    return x.copy()\nif PyStringMap is not None:\n    d[PyStringMap] = _copy_with_copy_method\n\ndef _copy_inst(x):\n    if hasattr(x, '__copy__'):\n        return x.__copy__()\n    if hasattr(x, '__getinitargs__'):\n        args = x.__getinitargs__()\n        y = x.__class__(*args)\n    else:\n        y = _EmptyClass()\n        y.__class__ = x.__class__\n    if hasattr(x, '__getstate__'):\n        state = x.__getstate__()\n    else:\n        state = x.__dict__\n    if hasattr(y, '__setstate__'):\n        y.__setstate__(state)\n    else:\n        y.__dict__.update(state)\n    return y\nd[types.InstanceType] = _copy_inst\n\ndel d\n\ndef deepcopy(x, memo=None, _nil=[]):\n    \"\"\"Deep copy operation on arbitrary Python objects.\n\n    See the module's __doc__ string for more info.\n    \"\"\"\n\n    if memo is None:\n        memo = {}\n\n    d = id(x)\n    y = memo.get(d, _nil)\n    if y is not _nil:\n        return y\n\n    cls = type(x)\n\n    copier = _deepcopy_dispatch.get(cls)\n    if copier:\n        y = copier(x, memo)\n    else:\n        try:\n            issc = issubclass(cls, type)\n        except TypeError: # cls is not a class (old Boost; see SF #502085)\n            issc = 0\n        if issc:\n            y = _deepcopy_atomic(x, memo)\n        else:\n            copier = getattr(x, \"__deepcopy__\", None)\n            if copier:\n                y = copier(memo)\n            else:\n                reductor = dispatch_table.get(cls)\n                if reductor:\n                    rv = reductor(x)\n                else:\n                    reductor = getattr(x, \"__reduce_ex__\", None)\n                    if reductor:\n                        rv = reductor(2)\n                    else:\n                        reductor = getattr(x, \"__reduce__\", None)\n                        if reductor:\n                            rv = reductor()\n                        else:\n                            raise Error(\n                                \"un(deep)copyable object of type %s\" % cls)\n                y = _reconstruct(x, rv, 1, memo)\n\n    memo[d] = y\n    _keep_alive(x, memo) # Make sure x lives at least as long as d\n    return y\n\n_deepcopy_dispatch = d = {}\n\ndef _deepcopy_atomic(x, memo):\n    return x\nd[type(None)] = _deepcopy_atomic\nd[type(Ellipsis)] = _deepcopy_atomic\nd[int] = _deepcopy_atomic\nd[long] = _deepcopy_atomic\nd[float] = _deepcopy_atomic\nd[bool] = _deepcopy_atomic\ntry:\n    d[complex] = _deepcopy_atomic\nexcept NameError:\n    pass\nd[str] = _deepcopy_atomic\ntry:\n    d[unicode] = _deepcopy_atomic\nexcept NameError:\n    pass\ntry:\n    d[types.CodeType] = _deepcopy_atomic\nexcept AttributeError:\n    pass\nd[type] = _deepcopy_atomic\nd[xrange] = _deepcopy_atomic\nd[types.ClassType] = _deepcopy_atomic\nd[types.BuiltinFunctionType] = _deepcopy_atomic\nd[types.FunctionType] = _deepcopy_atomic\nd[weakref.ref] = _deepcopy_atomic\n\ndef _deepcopy_list(x, memo):\n    y = []\n    memo[id(x)] = y\n    for a in x:\n        y.append(deepcopy(a, memo))\n    return y\nd[list] = _deepcopy_list\n\ndef _deepcopy_tuple(x, memo):\n    y = []\n    for a in x:\n        y.append(deepcopy(a, memo))\n    d = id(x)\n    try:\n        return memo[d]\n    except KeyError:\n        pass\n    for i in range(len(x)):\n        if x[i] is not y[i]:\n            y = tuple(y)\n            break\n    else:\n        y = x\n    memo[d] = y\n    return y\nd[tuple] = _deepcopy_tuple\n\ndef _deepcopy_dict(x, memo):\n    y = {}\n    memo[id(x)] = y\n    for key, value in x.iteritems():\n        y[deepcopy(key, memo)] = deepcopy(value, memo)\n    return y\nd[dict] = _deepcopy_dict\nif PyStringMap is not None:\n    d[PyStringMap] = _deepcopy_dict\n\ndef _deepcopy_method(x, memo): # Copy instance methods\n    return type(x)(x.im_func, deepcopy(x.im_self, memo), x.im_class)\n_deepcopy_dispatch[types.MethodType] = _deepcopy_method\n\ndef _keep_alive(x, memo):\n    \"\"\"Keeps a reference to the object x in the memo.\n\n    Because we remember objects by their id, we have\n    to assure that possibly temporary objects are kept\n    alive by referencing them.\n    We store a reference at the id of the memo, which should\n    normally not be used unless someone tries to deepcopy\n    the memo itself...\n    \"\"\"\n    try:\n        memo[id(memo)].append(x)\n    except KeyError:\n        # aha, this is the first one :-)\n        memo[id(memo)]=[x]\n\ndef _deepcopy_inst(x, memo):\n    if hasattr(x, '__deepcopy__'):\n        return x.__deepcopy__(memo)\n    if hasattr(x, '__getinitargs__'):\n        args = x.__getinitargs__()\n        args = deepcopy(args, memo)\n        y = x.__class__(*args)\n    else:\n        y = _EmptyClass()\n        y.__class__ = x.__class__\n    memo[id(x)] = y\n    if hasattr(x, '__getstate__'):\n        state = x.__getstate__()\n    else:\n        state = x.__dict__\n    state = deepcopy(state, memo)\n    if hasattr(y, '__setstate__'):\n        y.__setstate__(state)\n    else:\n        y.__dict__.update(state)\n    return y\nd[types.InstanceType] = _deepcopy_inst\n\ndef _reconstruct(x, info, deep, memo=None):\n    if isinstance(info, str):\n        return x\n    assert isinstance(info, tuple)\n    if memo is None:\n        memo = {}\n    n = len(info)\n    assert n in (2, 3, 4, 5)\n    callable, args = info[:2]\n    if n > 2:\n        state = info[2]\n    else:\n        state = {}\n    if n > 3:\n        listiter = info[3]\n    else:\n        listiter = None\n    if n > 4:\n        dictiter = info[4]\n    else:\n        dictiter = None\n    if deep:\n        args = deepcopy(args, memo)\n    y = callable(*args)\n    memo[id(x)] = y\n\n    if state:\n        if deep:\n            state = deepcopy(state, memo)\n        if hasattr(y, '__setstate__'):\n            y.__setstate__(state)\n        else:\n            if isinstance(state, tuple) and len(state) == 2:\n                state, slotstate = state\n            else:\n                slotstate = None\n            if state is not None:\n                y.__dict__.update(state)\n            if slotstate is not None:\n                for key, value in slotstate.iteritems():\n                    setattr(y, key, value)\n\n    if listiter is not None:\n        for item in listiter:\n            if deep:\n                item = deepcopy(item, memo)\n            y.append(item)\n    if dictiter is not None:\n        for key, value in dictiter:\n            if deep:\n                key = deepcopy(key, memo)\n                value = deepcopy(value, memo)\n            y[key] = value\n    return y\n\ndel d\n\ndel types\n\n# Helper for instance creation without calling __init__\nclass _EmptyClass:\n    pass\n\ndef _test():\n    l = [None, 1, 2L, 3.14, 'xyzzy', (1, 2L), [3.14, 'abc'],\n         {'abc': 'ABC'}, (), [], {}]\n    l1 = copy(l)\n    print l1==l\n    l1 = map(copy, l)\n    print l1==l\n    l1 = deepcopy(l)\n    print l1==l\n    class C:\n        def __init__(self, arg=None):\n            self.a = 1\n            self.arg = arg\n            if __name__ == '__main__':\n                import sys\n                file = sys.argv[0]\n            else:\n                file = __file__\n            self.fp = open(file)\n            self.fp.close()\n        def __getstate__(self):\n            return {'a': self.a, 'arg': self.arg}\n        def __setstate__(self, state):\n            for key, value in state.iteritems():\n                setattr(self, key, value)\n        def __deepcopy__(self, memo=None):\n            new = self.__class__(deepcopy(self.arg, memo))\n            new.a = self.a\n            return new\n    c = C('argument sketch')\n    l.append(c)\n    l2 = copy(l)\n    print l == l2\n    print l\n    print l2\n    l2 = deepcopy(l)\n    print l == l2\n    print l\n    print l2\n    l.append({l[1]: l, 'xyz': l[2]})\n    l3 = copy(l)\n    import repr\n    print map(repr.repr, l)\n    print map(repr.repr, l1)\n    print map(repr.repr, l2)\n    print map(repr.repr, l3)\n    l3 = deepcopy(l)\n    import repr\n    print map(repr.repr, l)\n    print map(repr.repr, l1)\n    print map(repr.repr, l2)\n    print map(repr.repr, l3)\n    class odict(dict):\n        def __init__(self, d = {}):\n            self.a = 99\n            dict.__init__(self, d)\n        def __setitem__(self, k, i):\n            dict.__setitem__(self, k, i)\n            self.a\n    o = odict({\"A\" : \"B\"})\n    x = deepcopy(o)\n    print(o, x)\n\nif __name__ == '__main__':\n    _test()\n", 
    "copy_reg": "\"\"\"Helper to provide extensibility for pickle/cPickle.\n\nThis is only useful to add pickle support for extension types defined in\nC, not for instances of user-defined classes.\n\"\"\"\n\nfrom types import ClassType as _ClassType\n\n__all__ = [\"pickle\", \"constructor\",\n           \"add_extension\", \"remove_extension\", \"clear_extension_cache\"]\n\ndispatch_table = {}\n\ndef pickle(ob_type, pickle_function, constructor_ob=None):\n    if type(ob_type) is _ClassType:\n        raise TypeError(\"copy_reg is not intended for use with classes\")\n\n    if not hasattr(pickle_function, '__call__'):\n        raise TypeError(\"reduction functions must be callable\")\n    dispatch_table[ob_type] = pickle_function\n\n    # The constructor_ob function is a vestige of safe for unpickling.\n    # There is no reason for the caller to pass it anymore.\n    if constructor_ob is not None:\n        constructor(constructor_ob)\n\ndef constructor(object):\n    if not hasattr(object, '__call__'):\n        raise TypeError(\"constructors must be callable\")\n\n# Example: provide pickling support for complex numbers.\n\ntry:\n    complex\nexcept NameError:\n    pass\nelse:\n\n    def pickle_complex(c):\n        return complex, (c.real, c.imag)\n\n    pickle(complex, pickle_complex, complex)\n\n# Support for pickling new-style objects\n\ndef _reconstructor(cls, base, state):\n    if base is object:\n        obj = object.__new__(cls)\n    else:\n        obj = base.__new__(cls, state)\n        if base.__init__ != object.__init__:\n            base.__init__(obj, state)\n    return obj\n\n_HEAPTYPE = 1<<9\n\n# Python code for object.__reduce_ex__ for protocols 0 and 1\n\ndef _reduce_ex(self, proto):\n    assert proto < 2\n    for base in self.__class__.__mro__:\n        if hasattr(base, '__flags__') and not base.__flags__ & _HEAPTYPE:\n            break\n    else:\n        base = object # not really reachable\n    if base is object:\n        state = None\n    else:\n        if base is self.__class__:\n            raise TypeError, \"can't pickle %s objects\" % base.__name__\n        state = base(self)\n    args = (self.__class__, base, state)\n    try:\n        getstate = self.__getstate__\n    except AttributeError:\n        if getattr(self, \"__slots__\", None):\n            raise TypeError(\"a class that defines __slots__ without \"\n                            \"defining __getstate__ cannot be pickled\")\n        try:\n            dict = self.__dict__\n        except AttributeError:\n            dict = None\n    else:\n        dict = getstate()\n    if dict:\n        return _reconstructor, args, dict\n    else:\n        return _reconstructor, args\n\n# Helper for __reduce_ex__ protocol 2\n\ndef __newobj__(cls, *args):\n    return cls.__new__(cls, *args)\n\ndef _slotnames(cls):\n    \"\"\"Return a list of slot names for a given class.\n\n    This needs to find slots defined by the class and its bases, so we\n    can't simply return the __slots__ attribute.  We must walk down\n    the Method Resolution Order and concatenate the __slots__ of each\n    class found there.  (This assumes classes don't modify their\n    __slots__ attribute to misrepresent their slots after the class is\n    defined.)\n    \"\"\"\n\n    # Get the value from a cache in the class if possible\n    names = cls.__dict__.get(\"__slotnames__\")\n    if names is not None:\n        return names\n\n    # Not cached -- calculate the value\n    names = []\n    if not hasattr(cls, \"__slots__\"):\n        # This class has no slots\n        pass\n    else:\n        # Slots found -- gather slot names from all base classes\n        for c in cls.__mro__:\n            if \"__slots__\" in c.__dict__:\n                slots = c.__dict__['__slots__']\n                # if class has a single slot, it can be given as a string\n                if isinstance(slots, basestring):\n                    slots = (slots,)\n                for name in slots:\n                    # special descriptors\n                    if name in (\"__dict__\", \"__weakref__\"):\n                        continue\n                    # mangled names\n                    elif name.startswith('__') and not name.endswith('__'):\n                        names.append('_%s%s' % (c.__name__, name))\n                    else:\n                        names.append(name)\n\n    # Cache the outcome in the class if at all possible\n    try:\n        cls.__slotnames__ = names\n    except:\n        pass # But don't die if we can't\n\n    return names\n\n# A registry of extension codes.  This is an ad-hoc compression\n# mechanism.  Whenever a global reference to <module>, <name> is about\n# to be pickled, the (<module>, <name>) tuple is looked up here to see\n# if it is a registered extension code for it.  Extension codes are\n# universal, so that the meaning of a pickle does not depend on\n# context.  (There are also some codes reserved for local use that\n# don't have this restriction.)  Codes are positive ints; 0 is\n# reserved.\n\n_extension_registry = {}                # key -> code\n_inverted_registry = {}                 # code -> key\n_extension_cache = {}                   # code -> object\n# Don't ever rebind those names:  cPickle grabs a reference to them when\n# it's initialized, and won't see a rebinding.\n\ndef add_extension(module, name, code):\n    \"\"\"Register an extension code.\"\"\"\n    code = int(code)\n    if not 1 <= code <= 0x7fffffff:\n        raise ValueError, \"code out of range\"\n    key = (module, name)\n    if (_extension_registry.get(key) == code and\n        _inverted_registry.get(code) == key):\n        return # Redundant registrations are benign\n    if key in _extension_registry:\n        raise ValueError(\"key %s is already registered with code %s\" %\n                         (key, _extension_registry[key]))\n    if code in _inverted_registry:\n        raise ValueError(\"code %s is already in use for key %s\" %\n                         (code, _inverted_registry[code]))\n    _extension_registry[key] = code\n    _inverted_registry[code] = key\n\ndef remove_extension(module, name, code):\n    \"\"\"Unregister an extension code.  For testing only.\"\"\"\n    key = (module, name)\n    if (_extension_registry.get(key) != code or\n        _inverted_registry.get(code) != key):\n        raise ValueError(\"key %s is not registered with code %s\" %\n                         (key, code))\n    del _extension_registry[key]\n    del _inverted_registry[code]\n    if code in _extension_cache:\n        del _extension_cache[code]\n\ndef clear_extension_cache():\n    _extension_cache.clear()\n\n# Standard extension code assignments\n\n# Reserved ranges\n\n# First  Last Count  Purpose\n#     1   127   127  Reserved for Python standard library\n#   128   191    64  Reserved for Zope\n#   192   239    48  Reserved for 3rd parties\n#   240   255    16  Reserved for private use (will never be assigned)\n#   256   Inf   Inf  Reserved for future assignment\n\n# Extension codes are assigned by the Python Software Foundation.\n", 
    "encodings.__init__": "\"\"\" Standard \"encodings\" Package\n\n    Standard Python encoding modules are stored in this package\n    directory.\n\n    Codec modules must have names corresponding to normalized encoding\n    names as defined in the normalize_encoding() function below, e.g.\n    'utf-8' must be implemented by the module 'utf_8.py'.\n\n    Each codec module must export the following interface:\n\n    * getregentry() -> codecs.CodecInfo object\n    The getregentry() API must a CodecInfo object with encoder, decoder,\n    incrementalencoder, incrementaldecoder, streamwriter and streamreader\n    atttributes which adhere to the Python Codec Interface Standard.\n\n    In addition, a module may optionally also define the following\n    APIs which are then used by the package's codec search function:\n\n    * getaliases() -> sequence of encoding name strings to use as aliases\n\n    Alias names returned by getaliases() must be normalized encoding\n    names as defined by normalize_encoding().\n\nWritten by Marc-Andre Lemburg (mal@lemburg.com).\n\n(c) Copyright CNRI, All Rights Reserved. NO WARRANTY.\n\n\"\"\"#\"\n\nimport codecs\nfrom encodings import aliases\nimport __builtin__\n\n_cache = {}\n_unknown = '--unknown--'\n_import_tail = ['*']\n_norm_encoding_map = ('                                              . '\n                      '0123456789       ABCDEFGHIJKLMNOPQRSTUVWXYZ     '\n                      ' abcdefghijklmnopqrstuvwxyz                     '\n                      '                                                '\n                      '                                                '\n                      '                ')\n_aliases = aliases.aliases\n\nclass CodecRegistryError(LookupError, SystemError):\n    pass\n\ndef normalize_encoding(encoding):\n\n    \"\"\" Normalize an encoding name.\n\n        Normalization works as follows: all non-alphanumeric\n        characters except the dot used for Python package names are\n        collapsed and replaced with a single underscore, e.g. '  -;#'\n        becomes '_'. Leading and trailing underscores are removed.\n\n        Note that encoding names should be ASCII only; if they do use\n        non-ASCII characters, these must be Latin-1 compatible.\n\n    \"\"\"\n    # Make sure we have an 8-bit string, because .translate() works\n    # differently for Unicode strings.\n    if hasattr(__builtin__, \"unicode\") and isinstance(encoding, unicode):\n        # Note that .encode('latin-1') does *not* use the codec\n        # registry, so this call doesn't recurse. (See unicodeobject.c\n        # PyUnicode_AsEncodedString() for details)\n        encoding = encoding.encode('latin-1')\n    return '_'.join(encoding.translate(_norm_encoding_map).split())\n\ndef search_function(encoding):\n\n    # Cache lookup\n    entry = _cache.get(encoding, _unknown)\n    if entry is not _unknown:\n        return entry\n\n    # Import the module:\n    #\n    # First try to find an alias for the normalized encoding\n    # name and lookup the module using the aliased name, then try to\n    # lookup the module using the standard import scheme, i.e. first\n    # try in the encodings package, then at top-level.\n    #\n    norm_encoding = normalize_encoding(encoding)\n    aliased_encoding = _aliases.get(norm_encoding) or \\\n                       _aliases.get(norm_encoding.replace('.', '_'))\n    if aliased_encoding is not None:\n        modnames = [aliased_encoding,\n                    norm_encoding]\n    else:\n        modnames = [norm_encoding]\n    for modname in modnames:\n        if not modname or '.' in modname:\n            continue\n        try:\n            # Import is absolute to prevent the possibly malicious import of a\n            # module with side-effects that is not in the 'encodings' package.\n            mod = __import__('encodings.' + modname, fromlist=_import_tail,\n                             level=0)\n        except ImportError:\n            pass\n        else:\n            break\n    else:\n        mod = None\n\n    try:\n        getregentry = mod.getregentry\n    except AttributeError:\n        # Not a codec module\n        mod = None\n\n    if mod is None:\n        # Cache misses\n        _cache[encoding] = None\n        return None\n\n    # Now ask the module for the registry entry\n    entry = getregentry()\n    if not isinstance(entry, codecs.CodecInfo):\n        if not 4 <= len(entry) <= 7:\n            raise CodecRegistryError,\\\n                 'module \"%s\" (%s) failed to register' % \\\n                  (mod.__name__, mod.__file__)\n        if not hasattr(entry[0], '__call__') or \\\n           not hasattr(entry[1], '__call__') or \\\n           (entry[2] is not None and not hasattr(entry[2], '__call__')) or \\\n           (entry[3] is not None and not hasattr(entry[3], '__call__')) or \\\n           (len(entry) > 4 and entry[4] is not None and not hasattr(entry[4], '__call__')) or \\\n           (len(entry) > 5 and entry[5] is not None and not hasattr(entry[5], '__call__')):\n            raise CodecRegistryError,\\\n                'incompatible codecs in module \"%s\" (%s)' % \\\n                (mod.__name__, mod.__file__)\n        if len(entry)<7 or entry[6] is None:\n            entry += (None,)*(6-len(entry)) + (mod.__name__.split(\".\", 1)[1],)\n        entry = codecs.CodecInfo(*entry)\n\n    # Cache the codec registry entry\n    _cache[encoding] = entry\n\n    # Register its aliases (without overwriting previously registered\n    # aliases)\n    try:\n        codecaliases = mod.getaliases()\n    except AttributeError:\n        pass\n    else:\n        for alias in codecaliases:\n            if alias not in _aliases:\n                _aliases[alias] = modname\n\n    # Return the registry entry\n    return entry\n\n# Register the search_function in the Python codec registry\ncodecs.register(search_function)\n", 
    "encodings.aliases": "\"\"\" Encoding Aliases Support\n\n    This module is used by the encodings package search function to\n    map encodings names to module names.\n\n    Note that the search function normalizes the encoding names before\n    doing the lookup, so the mapping will have to map normalized\n    encoding names to module names.\n\n    Contents:\n\n        The following aliases dictionary contains mappings of all IANA\n        character set names for which the Python core library provides\n        codecs. In addition to these, a few Python specific codec\n        aliases have also been added.\n\n\"\"\"\naliases = {\n\n    # Please keep this list sorted alphabetically by value !\n\n    # ascii codec\n    '646'                : 'ascii',\n    'ansi_x3.4_1968'     : 'ascii',\n    'ansi_x3_4_1968'     : 'ascii', # some email headers use this non-standard name\n    'ansi_x3.4_1986'     : 'ascii',\n    'cp367'              : 'ascii',\n    'csascii'            : 'ascii',\n    'ibm367'             : 'ascii',\n    'iso646_us'          : 'ascii',\n    'iso_646.irv_1991'   : 'ascii',\n    'iso_ir_6'           : 'ascii',\n    'us'                 : 'ascii',\n    'us_ascii'           : 'ascii',\n\n    # base64_codec codec\n    'base64'             : 'base64_codec',\n    'base_64'            : 'base64_codec',\n\n    # big5 codec\n    'big5_tw'            : 'big5',\n    'csbig5'             : 'big5',\n\n    # big5hkscs codec\n    'big5_hkscs'         : 'big5hkscs',\n    'hkscs'              : 'big5hkscs',\n\n    # bz2_codec codec\n    'bz2'                : 'bz2_codec',\n\n    # cp037 codec\n    '037'                : 'cp037',\n    'csibm037'           : 'cp037',\n    'ebcdic_cp_ca'       : 'cp037',\n    'ebcdic_cp_nl'       : 'cp037',\n    'ebcdic_cp_us'       : 'cp037',\n    'ebcdic_cp_wt'       : 'cp037',\n    'ibm037'             : 'cp037',\n    'ibm039'             : 'cp037',\n\n    # cp1026 codec\n    '1026'               : 'cp1026',\n    'csibm1026'          : 'cp1026',\n    'ibm1026'            : 'cp1026',\n\n    # cp1140 codec\n    '1140'               : 'cp1140',\n    'ibm1140'            : 'cp1140',\n\n    # cp1250 codec\n    '1250'               : 'cp1250',\n    'windows_1250'       : 'cp1250',\n\n    # cp1251 codec\n    '1251'               : 'cp1251',\n    'windows_1251'       : 'cp1251',\n\n    # cp1252 codec\n    '1252'               : 'cp1252',\n    'windows_1252'       : 'cp1252',\n\n    # cp1253 codec\n    '1253'               : 'cp1253',\n    'windows_1253'       : 'cp1253',\n\n    # cp1254 codec\n    '1254'               : 'cp1254',\n    'windows_1254'       : 'cp1254',\n\n    # cp1255 codec\n    '1255'               : 'cp1255',\n    'windows_1255'       : 'cp1255',\n\n    # cp1256 codec\n    '1256'               : 'cp1256',\n    'windows_1256'       : 'cp1256',\n\n    # cp1257 codec\n    '1257'               : 'cp1257',\n    'windows_1257'       : 'cp1257',\n\n    # cp1258 codec\n    '1258'               : 'cp1258',\n    'windows_1258'       : 'cp1258',\n\n    # cp424 codec\n    '424'                : 'cp424',\n    'csibm424'           : 'cp424',\n    'ebcdic_cp_he'       : 'cp424',\n    'ibm424'             : 'cp424',\n\n    # cp437 codec\n    '437'                : 'cp437',\n    'cspc8codepage437'   : 'cp437',\n    'ibm437'             : 'cp437',\n\n    # cp500 codec\n    '500'                : 'cp500',\n    'csibm500'           : 'cp500',\n    'ebcdic_cp_be'       : 'cp500',\n    'ebcdic_cp_ch'       : 'cp500',\n    'ibm500'             : 'cp500',\n\n    # cp775 codec\n    '775'                : 'cp775',\n    'cspc775baltic'      : 'cp775',\n    'ibm775'             : 'cp775',\n\n    # cp850 codec\n    '850'                : 'cp850',\n    'cspc850multilingual' : 'cp850',\n    'ibm850'             : 'cp850',\n\n    # cp852 codec\n    '852'                : 'cp852',\n    'cspcp852'           : 'cp852',\n    'ibm852'             : 'cp852',\n\n    # cp855 codec\n    '855'                : 'cp855',\n    'csibm855'           : 'cp855',\n    'ibm855'             : 'cp855',\n\n    # cp857 codec\n    '857'                : 'cp857',\n    'csibm857'           : 'cp857',\n    'ibm857'             : 'cp857',\n\n    # cp858 codec\n    '858'                : 'cp858',\n    'csibm858'           : 'cp858',\n    'ibm858'             : 'cp858',\n\n    # cp860 codec\n    '860'                : 'cp860',\n    'csibm860'           : 'cp860',\n    'ibm860'             : 'cp860',\n\n    # cp861 codec\n    '861'                : 'cp861',\n    'cp_is'              : 'cp861',\n    'csibm861'           : 'cp861',\n    'ibm861'             : 'cp861',\n\n    # cp862 codec\n    '862'                : 'cp862',\n    'cspc862latinhebrew' : 'cp862',\n    'ibm862'             : 'cp862',\n\n    # cp863 codec\n    '863'                : 'cp863',\n    'csibm863'           : 'cp863',\n    'ibm863'             : 'cp863',\n\n    # cp864 codec\n    '864'                : 'cp864',\n    'csibm864'           : 'cp864',\n    'ibm864'             : 'cp864',\n\n    # cp865 codec\n    '865'                : 'cp865',\n    'csibm865'           : 'cp865',\n    'ibm865'             : 'cp865',\n\n    # cp866 codec\n    '866'                : 'cp866',\n    'csibm866'           : 'cp866',\n    'ibm866'             : 'cp866',\n\n    # cp869 codec\n    '869'                : 'cp869',\n    'cp_gr'              : 'cp869',\n    'csibm869'           : 'cp869',\n    'ibm869'             : 'cp869',\n\n    # cp932 codec\n    '932'                : 'cp932',\n    'ms932'              : 'cp932',\n    'mskanji'            : 'cp932',\n    'ms_kanji'           : 'cp932',\n\n    # cp949 codec\n    '949'                : 'cp949',\n    'ms949'              : 'cp949',\n    'uhc'                : 'cp949',\n\n    # cp950 codec\n    '950'                : 'cp950',\n    'ms950'              : 'cp950',\n\n    # euc_jis_2004 codec\n    'jisx0213'           : 'euc_jis_2004',\n    'eucjis2004'         : 'euc_jis_2004',\n    'euc_jis2004'        : 'euc_jis_2004',\n\n    # euc_jisx0213 codec\n    'eucjisx0213'        : 'euc_jisx0213',\n\n    # euc_jp codec\n    'eucjp'              : 'euc_jp',\n    'ujis'               : 'euc_jp',\n    'u_jis'              : 'euc_jp',\n\n    # euc_kr codec\n    'euckr'              : 'euc_kr',\n    'korean'             : 'euc_kr',\n    'ksc5601'            : 'euc_kr',\n    'ks_c_5601'          : 'euc_kr',\n    'ks_c_5601_1987'     : 'euc_kr',\n    'ksx1001'            : 'euc_kr',\n    'ks_x_1001'          : 'euc_kr',\n\n    # gb18030 codec\n    'gb18030_2000'       : 'gb18030',\n\n    # gb2312 codec\n    'chinese'            : 'gb2312',\n    'csiso58gb231280'    : 'gb2312',\n    'euc_cn'             : 'gb2312',\n    'euccn'              : 'gb2312',\n    'eucgb2312_cn'       : 'gb2312',\n    'gb2312_1980'        : 'gb2312',\n    'gb2312_80'          : 'gb2312',\n    'iso_ir_58'          : 'gb2312',\n\n    # gbk codec\n    '936'                : 'gbk',\n    'cp936'              : 'gbk',\n    'ms936'              : 'gbk',\n\n    # hex_codec codec\n    'hex'                : 'hex_codec',\n\n    # hp_roman8 codec\n    'roman8'             : 'hp_roman8',\n    'r8'                 : 'hp_roman8',\n    'csHPRoman8'         : 'hp_roman8',\n\n    # hz codec\n    'hzgb'               : 'hz',\n    'hz_gb'              : 'hz',\n    'hz_gb_2312'         : 'hz',\n\n    # iso2022_jp codec\n    'csiso2022jp'        : 'iso2022_jp',\n    'iso2022jp'          : 'iso2022_jp',\n    'iso_2022_jp'        : 'iso2022_jp',\n\n    # iso2022_jp_1 codec\n    'iso2022jp_1'        : 'iso2022_jp_1',\n    'iso_2022_jp_1'      : 'iso2022_jp_1',\n\n    # iso2022_jp_2 codec\n    'iso2022jp_2'        : 'iso2022_jp_2',\n    'iso_2022_jp_2'      : 'iso2022_jp_2',\n\n    # iso2022_jp_2004 codec\n    'iso_2022_jp_2004'   : 'iso2022_jp_2004',\n    'iso2022jp_2004'     : 'iso2022_jp_2004',\n\n    # iso2022_jp_3 codec\n    'iso2022jp_3'        : 'iso2022_jp_3',\n    'iso_2022_jp_3'      : 'iso2022_jp_3',\n\n    # iso2022_jp_ext codec\n    'iso2022jp_ext'      : 'iso2022_jp_ext',\n    'iso_2022_jp_ext'    : 'iso2022_jp_ext',\n\n    # iso2022_kr codec\n    'csiso2022kr'        : 'iso2022_kr',\n    'iso2022kr'          : 'iso2022_kr',\n    'iso_2022_kr'        : 'iso2022_kr',\n\n    # iso8859_10 codec\n    'csisolatin6'        : 'iso8859_10',\n    'iso_8859_10'        : 'iso8859_10',\n    'iso_8859_10_1992'   : 'iso8859_10',\n    'iso_ir_157'         : 'iso8859_10',\n    'l6'                 : 'iso8859_10',\n    'latin6'             : 'iso8859_10',\n\n    # iso8859_11 codec\n    'thai'               : 'iso8859_11',\n    'iso_8859_11'        : 'iso8859_11',\n    'iso_8859_11_2001'   : 'iso8859_11',\n\n    # iso8859_13 codec\n    'iso_8859_13'        : 'iso8859_13',\n    'l7'                 : 'iso8859_13',\n    'latin7'             : 'iso8859_13',\n\n    # iso8859_14 codec\n    'iso_8859_14'        : 'iso8859_14',\n    'iso_8859_14_1998'   : 'iso8859_14',\n    'iso_celtic'         : 'iso8859_14',\n    'iso_ir_199'         : 'iso8859_14',\n    'l8'                 : 'iso8859_14',\n    'latin8'             : 'iso8859_14',\n\n    # iso8859_15 codec\n    'iso_8859_15'        : 'iso8859_15',\n    'l9'                 : 'iso8859_15',\n    'latin9'             : 'iso8859_15',\n\n    # iso8859_16 codec\n    'iso_8859_16'        : 'iso8859_16',\n    'iso_8859_16_2001'   : 'iso8859_16',\n    'iso_ir_226'         : 'iso8859_16',\n    'l10'                : 'iso8859_16',\n    'latin10'            : 'iso8859_16',\n\n    # iso8859_2 codec\n    'csisolatin2'        : 'iso8859_2',\n    'iso_8859_2'         : 'iso8859_2',\n    'iso_8859_2_1987'    : 'iso8859_2',\n    'iso_ir_101'         : 'iso8859_2',\n    'l2'                 : 'iso8859_2',\n    'latin2'             : 'iso8859_2',\n\n    # iso8859_3 codec\n    'csisolatin3'        : 'iso8859_3',\n    'iso_8859_3'         : 'iso8859_3',\n    'iso_8859_3_1988'    : 'iso8859_3',\n    'iso_ir_109'         : 'iso8859_3',\n    'l3'                 : 'iso8859_3',\n    'latin3'             : 'iso8859_3',\n\n    # iso8859_4 codec\n    'csisolatin4'        : 'iso8859_4',\n    'iso_8859_4'         : 'iso8859_4',\n    'iso_8859_4_1988'    : 'iso8859_4',\n    'iso_ir_110'         : 'iso8859_4',\n    'l4'                 : 'iso8859_4',\n    'latin4'             : 'iso8859_4',\n\n    # iso8859_5 codec\n    'csisolatincyrillic' : 'iso8859_5',\n    'cyrillic'           : 'iso8859_5',\n    'iso_8859_5'         : 'iso8859_5',\n    'iso_8859_5_1988'    : 'iso8859_5',\n    'iso_ir_144'         : 'iso8859_5',\n\n    # iso8859_6 codec\n    'arabic'             : 'iso8859_6',\n    'asmo_708'           : 'iso8859_6',\n    'csisolatinarabic'   : 'iso8859_6',\n    'ecma_114'           : 'iso8859_6',\n    'iso_8859_6'         : 'iso8859_6',\n    'iso_8859_6_1987'    : 'iso8859_6',\n    'iso_ir_127'         : 'iso8859_6',\n\n    # iso8859_7 codec\n    'csisolatingreek'    : 'iso8859_7',\n    'ecma_118'           : 'iso8859_7',\n    'elot_928'           : 'iso8859_7',\n    'greek'              : 'iso8859_7',\n    'greek8'             : 'iso8859_7',\n    'iso_8859_7'         : 'iso8859_7',\n    'iso_8859_7_1987'    : 'iso8859_7',\n    'iso_ir_126'         : 'iso8859_7',\n\n    # iso8859_8 codec\n    'csisolatinhebrew'   : 'iso8859_8',\n    'hebrew'             : 'iso8859_8',\n    'iso_8859_8'         : 'iso8859_8',\n    'iso_8859_8_1988'    : 'iso8859_8',\n    'iso_ir_138'         : 'iso8859_8',\n\n    # iso8859_9 codec\n    'csisolatin5'        : 'iso8859_9',\n    'iso_8859_9'         : 'iso8859_9',\n    'iso_8859_9_1989'    : 'iso8859_9',\n    'iso_ir_148'         : 'iso8859_9',\n    'l5'                 : 'iso8859_9',\n    'latin5'             : 'iso8859_9',\n\n    # johab codec\n    'cp1361'             : 'johab',\n    'ms1361'             : 'johab',\n\n    # koi8_r codec\n    'cskoi8r'            : 'koi8_r',\n\n    # latin_1 codec\n    #\n    # Note that the latin_1 codec is implemented internally in C and a\n    # lot faster than the charmap codec iso8859_1 which uses the same\n    # encoding. This is why we discourage the use of the iso8859_1\n    # codec and alias it to latin_1 instead.\n    #\n    '8859'               : 'latin_1',\n    'cp819'              : 'latin_1',\n    'csisolatin1'        : 'latin_1',\n    'ibm819'             : 'latin_1',\n    'iso8859'            : 'latin_1',\n    'iso8859_1'          : 'latin_1',\n    'iso_8859_1'         : 'latin_1',\n    'iso_8859_1_1987'    : 'latin_1',\n    'iso_ir_100'         : 'latin_1',\n    'l1'                 : 'latin_1',\n    'latin'              : 'latin_1',\n    'latin1'             : 'latin_1',\n\n    # mac_cyrillic codec\n    'maccyrillic'        : 'mac_cyrillic',\n\n    # mac_greek codec\n    'macgreek'           : 'mac_greek',\n\n    # mac_iceland codec\n    'maciceland'         : 'mac_iceland',\n\n    # mac_latin2 codec\n    'maccentraleurope'   : 'mac_latin2',\n    'maclatin2'          : 'mac_latin2',\n\n    # mac_roman codec\n    'macroman'           : 'mac_roman',\n\n    # mac_turkish codec\n    'macturkish'         : 'mac_turkish',\n\n    # mbcs codec\n    'dbcs'               : 'mbcs',\n\n    # ptcp154 codec\n    'csptcp154'          : 'ptcp154',\n    'pt154'              : 'ptcp154',\n    'cp154'              : 'ptcp154',\n    'cyrillic_asian'     : 'ptcp154',\n\n    # quopri_codec codec\n    'quopri'             : 'quopri_codec',\n    'quoted_printable'   : 'quopri_codec',\n    'quotedprintable'    : 'quopri_codec',\n\n    # rot_13 codec\n    'rot13'              : 'rot_13',\n\n    # shift_jis codec\n    'csshiftjis'         : 'shift_jis',\n    'shiftjis'           : 'shift_jis',\n    'sjis'               : 'shift_jis',\n    's_jis'              : 'shift_jis',\n\n    # shift_jis_2004 codec\n    'shiftjis2004'       : 'shift_jis_2004',\n    'sjis_2004'          : 'shift_jis_2004',\n    's_jis_2004'         : 'shift_jis_2004',\n\n    # shift_jisx0213 codec\n    'shiftjisx0213'      : 'shift_jisx0213',\n    'sjisx0213'          : 'shift_jisx0213',\n    's_jisx0213'         : 'shift_jisx0213',\n\n    # tactis codec\n    'tis260'             : 'tactis',\n\n    # tis_620 codec\n    'tis620'             : 'tis_620',\n    'tis_620_0'          : 'tis_620',\n    'tis_620_2529_0'     : 'tis_620',\n    'tis_620_2529_1'     : 'tis_620',\n    'iso_ir_166'         : 'tis_620',\n\n    # utf_16 codec\n    'u16'                : 'utf_16',\n    'utf16'              : 'utf_16',\n\n    # utf_16_be codec\n    'unicodebigunmarked' : 'utf_16_be',\n    'utf_16be'           : 'utf_16_be',\n\n    # utf_16_le codec\n    'unicodelittleunmarked' : 'utf_16_le',\n    'utf_16le'           : 'utf_16_le',\n\n    # utf_32 codec\n    'u32'                : 'utf_32',\n    'utf32'              : 'utf_32',\n\n    # utf_32_be codec\n    'utf_32be'           : 'utf_32_be',\n\n    # utf_32_le codec\n    'utf_32le'           : 'utf_32_le',\n\n    # utf_7 codec\n    'u7'                 : 'utf_7',\n    'utf7'               : 'utf_7',\n    'unicode_1_1_utf_7'  : 'utf_7',\n\n    # utf_8 codec\n    'u8'                 : 'utf_8',\n    'utf'                : 'utf_8',\n    'utf8'               : 'utf_8',\n    'utf8_ucs2'          : 'utf_8',\n    'utf8_ucs4'          : 'utf_8',\n\n    # uu_codec codec\n    'uu'                 : 'uu_codec',\n\n    # zlib_codec codec\n    'zip'                : 'zlib_codec',\n    'zlib'               : 'zlib_codec',\n\n}\n", 
    "encodings.ascii": "\"\"\" Python 'ascii' Codec\n\n\nWritten by Marc-Andre Lemburg (mal@lemburg.com).\n\n(c) Copyright CNRI, All Rights Reserved. NO WARRANTY.\n\n\"\"\"\nimport codecs\n\n### Codec APIs\n\nclass Codec(codecs.Codec):\n\n    # Note: Binding these as C functions will result in the class not\n    # converting them to methods. This is intended.\n    encode = codecs.ascii_encode\n    decode = codecs.ascii_decode\n\nclass IncrementalEncoder(codecs.IncrementalEncoder):\n    def encode(self, input, final=False):\n        return codecs.ascii_encode(input, self.errors)[0]\n\nclass IncrementalDecoder(codecs.IncrementalDecoder):\n    def decode(self, input, final=False):\n        return codecs.ascii_decode(input, self.errors)[0]\n\nclass StreamWriter(Codec,codecs.StreamWriter):\n    pass\n\nclass StreamReader(Codec,codecs.StreamReader):\n    pass\n\nclass StreamConverter(StreamWriter,StreamReader):\n\n    encode = codecs.ascii_decode\n    decode = codecs.ascii_encode\n\n### encodings module API\n\ndef getregentry():\n    return codecs.CodecInfo(\n        name='ascii',\n        encode=Codec.encode,\n        decode=Codec.decode,\n        incrementalencoder=IncrementalEncoder,\n        incrementaldecoder=IncrementalDecoder,\n        streamwriter=StreamWriter,\n        streamreader=StreamReader,\n    )\n", 
    "encodings.base64_codec": "\"\"\" Python 'base64_codec' Codec - base64 content transfer encoding\n\n    Unlike most of the other codecs which target Unicode, this codec\n    will return Python string objects for both encode and decode.\n\n    Written by Marc-Andre Lemburg (mal@lemburg.com).\n\n\"\"\"\nimport codecs, base64\n\n### Codec APIs\n\ndef base64_encode(input,errors='strict'):\n\n    \"\"\" Encodes the object input and returns a tuple (output\n        object, length consumed).\n\n        errors defines the error handling to apply. It defaults to\n        'strict' handling which is the only currently supported\n        error handling for this codec.\n\n    \"\"\"\n    assert errors == 'strict'\n    output = base64.encodestring(input)\n    return (output, len(input))\n\ndef base64_decode(input,errors='strict'):\n\n    \"\"\" Decodes the object input and returns a tuple (output\n        object, length consumed).\n\n        input must be an object which provides the bf_getreadbuf\n        buffer slot. Python strings, buffer objects and memory\n        mapped files are examples of objects providing this slot.\n\n        errors defines the error handling to apply. It defaults to\n        'strict' handling which is the only currently supported\n        error handling for this codec.\n\n    \"\"\"\n    assert errors == 'strict'\n    output = base64.decodestring(input)\n    return (output, len(input))\n\nclass Codec(codecs.Codec):\n\n    def encode(self, input,errors='strict'):\n        return base64_encode(input,errors)\n    def decode(self, input,errors='strict'):\n        return base64_decode(input,errors)\n\nclass IncrementalEncoder(codecs.IncrementalEncoder):\n    def encode(self, input, final=False):\n        assert self.errors == 'strict'\n        return base64.encodestring(input)\n\nclass IncrementalDecoder(codecs.IncrementalDecoder):\n    def decode(self, input, final=False):\n        assert self.errors == 'strict'\n        return base64.decodestring(input)\n\nclass StreamWriter(Codec,codecs.StreamWriter):\n    pass\n\nclass StreamReader(Codec,codecs.StreamReader):\n    pass\n\n### encodings module API\n\ndef getregentry():\n    return codecs.CodecInfo(\n        name='base64',\n        encode=base64_encode,\n        decode=base64_decode,\n        incrementalencoder=IncrementalEncoder,\n        incrementaldecoder=IncrementalDecoder,\n        streamwriter=StreamWriter,\n        streamreader=StreamReader,\n    )\n", 
    "encodings.hex_codec": "\"\"\" Python 'hex_codec' Codec - 2-digit hex content transfer encoding\n\n    Unlike most of the other codecs which target Unicode, this codec\n    will return Python string objects for both encode and decode.\n\n    Written by Marc-Andre Lemburg (mal@lemburg.com).\n\n\"\"\"\nimport codecs, binascii\n\n### Codec APIs\n\ndef hex_encode(input,errors='strict'):\n\n    \"\"\" Encodes the object input and returns a tuple (output\n        object, length consumed).\n\n        errors defines the error handling to apply. It defaults to\n        'strict' handling which is the only currently supported\n        error handling for this codec.\n\n    \"\"\"\n    assert errors == 'strict'\n    output = binascii.b2a_hex(input)\n    return (output, len(input))\n\ndef hex_decode(input,errors='strict'):\n\n    \"\"\" Decodes the object input and returns a tuple (output\n        object, length consumed).\n\n        input must be an object which provides the bf_getreadbuf\n        buffer slot. Python strings, buffer objects and memory\n        mapped files are examples of objects providing this slot.\n\n        errors defines the error handling to apply. It defaults to\n        'strict' handling which is the only currently supported\n        error handling for this codec.\n\n    \"\"\"\n    assert errors == 'strict'\n    output = binascii.a2b_hex(input)\n    return (output, len(input))\n\nclass Codec(codecs.Codec):\n\n    def encode(self, input,errors='strict'):\n        return hex_encode(input,errors)\n    def decode(self, input,errors='strict'):\n        return hex_decode(input,errors)\n\nclass IncrementalEncoder(codecs.IncrementalEncoder):\n    def encode(self, input, final=False):\n        assert self.errors == 'strict'\n        return binascii.b2a_hex(input)\n\nclass IncrementalDecoder(codecs.IncrementalDecoder):\n    def decode(self, input, final=False):\n        assert self.errors == 'strict'\n        return binascii.a2b_hex(input)\n\nclass StreamWriter(Codec,codecs.StreamWriter):\n    pass\n\nclass StreamReader(Codec,codecs.StreamReader):\n    pass\n\n### encodings module API\n\ndef getregentry():\n    return codecs.CodecInfo(\n        name='hex',\n        encode=hex_encode,\n        decode=hex_decode,\n        incrementalencoder=IncrementalEncoder,\n        incrementaldecoder=IncrementalDecoder,\n        streamwriter=StreamWriter,\n        streamreader=StreamReader,\n    )\n", 
    "encodings.latin_1": "\"\"\" Python 'latin-1' Codec\n\n\nWritten by Marc-Andre Lemburg (mal@lemburg.com).\n\n(c) Copyright CNRI, All Rights Reserved. NO WARRANTY.\n\n\"\"\"\nimport codecs\n\n### Codec APIs\n\nclass Codec(codecs.Codec):\n\n    # Note: Binding these as C functions will result in the class not\n    # converting them to methods. This is intended.\n    encode = codecs.latin_1_encode\n    decode = codecs.latin_1_decode\n\nclass IncrementalEncoder(codecs.IncrementalEncoder):\n    def encode(self, input, final=False):\n        return codecs.latin_1_encode(input,self.errors)[0]\n\nclass IncrementalDecoder(codecs.IncrementalDecoder):\n    def decode(self, input, final=False):\n        return codecs.latin_1_decode(input,self.errors)[0]\n\nclass StreamWriter(Codec,codecs.StreamWriter):\n    pass\n\nclass StreamReader(Codec,codecs.StreamReader):\n    pass\n\nclass StreamConverter(StreamWriter,StreamReader):\n\n    encode = codecs.latin_1_decode\n    decode = codecs.latin_1_encode\n\n### encodings module API\n\ndef getregentry():\n    return codecs.CodecInfo(\n        name='iso8859-1',\n        encode=Codec.encode,\n        decode=Codec.decode,\n        incrementalencoder=IncrementalEncoder,\n        incrementaldecoder=IncrementalDecoder,\n        streamreader=StreamReader,\n        streamwriter=StreamWriter,\n    )\n", 
    "encodings.raw_unicode_escape": "\"\"\" Python 'raw-unicode-escape' Codec\n\n\nWritten by Marc-Andre Lemburg (mal@lemburg.com).\n\n(c) Copyright CNRI, All Rights Reserved. NO WARRANTY.\n\n\"\"\"\nimport codecs\n\n### Codec APIs\n\nclass Codec(codecs.Codec):\n\n    # Note: Binding these as C functions will result in the class not\n    # converting them to methods. This is intended.\n    encode = codecs.raw_unicode_escape_encode\n    decode = codecs.raw_unicode_escape_decode\n\nclass IncrementalEncoder(codecs.IncrementalEncoder):\n    def encode(self, input, final=False):\n        return codecs.raw_unicode_escape_encode(input, self.errors)[0]\n\nclass IncrementalDecoder(codecs.IncrementalDecoder):\n    def decode(self, input, final=False):\n        return codecs.raw_unicode_escape_decode(input, self.errors)[0]\n\nclass StreamWriter(Codec,codecs.StreamWriter):\n    pass\n\nclass StreamReader(Codec,codecs.StreamReader):\n    pass\n\n### encodings module API\n\ndef getregentry():\n    return codecs.CodecInfo(\n        name='raw-unicode-escape',\n        encode=Codec.encode,\n        decode=Codec.decode,\n        incrementalencoder=IncrementalEncoder,\n        incrementaldecoder=IncrementalDecoder,\n        streamwriter=StreamWriter,\n        streamreader=StreamReader,\n    )\n", 
    "encodings.unicode_escape": "\"\"\" Python 'unicode-escape' Codec\n\n\nWritten by Marc-Andre Lemburg (mal@lemburg.com).\n\n(c) Copyright CNRI, All Rights Reserved. NO WARRANTY.\n\n\"\"\"\nimport codecs\n\n### Codec APIs\n\nclass Codec(codecs.Codec):\n\n    # Note: Binding these as C functions will result in the class not\n    # converting them to methods. This is intended.\n    encode = codecs.unicode_escape_encode\n    decode = codecs.unicode_escape_decode\n\nclass IncrementalEncoder(codecs.IncrementalEncoder):\n    def encode(self, input, final=False):\n        return codecs.unicode_escape_encode(input, self.errors)[0]\n\nclass IncrementalDecoder(codecs.IncrementalDecoder):\n    def decode(self, input, final=False):\n        return codecs.unicode_escape_decode(input, self.errors)[0]\n\nclass StreamWriter(Codec,codecs.StreamWriter):\n    pass\n\nclass StreamReader(Codec,codecs.StreamReader):\n    pass\n\n### encodings module API\n\ndef getregentry():\n    return codecs.CodecInfo(\n        name='unicode-escape',\n        encode=Codec.encode,\n        decode=Codec.decode,\n        incrementalencoder=IncrementalEncoder,\n        incrementaldecoder=IncrementalDecoder,\n        streamwriter=StreamWriter,\n        streamreader=StreamReader,\n    )\n", 
    "encodings.unicode_internal": "\"\"\" Python 'unicode-internal' Codec\n\n\nWritten by Marc-Andre Lemburg (mal@lemburg.com).\n\n(c) Copyright CNRI, All Rights Reserved. NO WARRANTY.\n\n\"\"\"\nimport codecs\n\n### Codec APIs\n\nclass Codec(codecs.Codec):\n\n    # Note: Binding these as C functions will result in the class not\n    # converting them to methods. This is intended.\n    encode = codecs.unicode_internal_encode\n    decode = codecs.unicode_internal_decode\n\nclass IncrementalEncoder(codecs.IncrementalEncoder):\n    def encode(self, input, final=False):\n        return codecs.unicode_internal_encode(input, self.errors)[0]\n\nclass IncrementalDecoder(codecs.IncrementalDecoder):\n    def decode(self, input, final=False):\n        return codecs.unicode_internal_decode(input, self.errors)[0]\n\nclass StreamWriter(Codec,codecs.StreamWriter):\n    pass\n\nclass StreamReader(Codec,codecs.StreamReader):\n    pass\n\n### encodings module API\n\ndef getregentry():\n    return codecs.CodecInfo(\n        name='unicode-internal',\n        encode=Codec.encode,\n        decode=Codec.decode,\n        incrementalencoder=IncrementalEncoder,\n        incrementaldecoder=IncrementalDecoder,\n        streamwriter=StreamWriter,\n        streamreader=StreamReader,\n    )\n", 
    "encodings.utf_16": "\"\"\" Python 'utf-16' Codec\n\n\nWritten by Marc-Andre Lemburg (mal@lemburg.com).\n\n(c) Copyright CNRI, All Rights Reserved. NO WARRANTY.\n\n\"\"\"\nimport codecs, sys\n\n### Codec APIs\n\nencode = codecs.utf_16_encode\n\ndef decode(input, errors='strict'):\n    return codecs.utf_16_decode(input, errors, True)\n\nclass IncrementalEncoder(codecs.IncrementalEncoder):\n    def __init__(self, errors='strict'):\n        codecs.IncrementalEncoder.__init__(self, errors)\n        self.encoder = None\n\n    def encode(self, input, final=False):\n        if self.encoder is None:\n            result = codecs.utf_16_encode(input, self.errors)[0]\n            if sys.byteorder == 'little':\n                self.encoder = codecs.utf_16_le_encode\n            else:\n                self.encoder = codecs.utf_16_be_encode\n            return result\n        return self.encoder(input, self.errors)[0]\n\n    def reset(self):\n        codecs.IncrementalEncoder.reset(self)\n        self.encoder = None\n\n    def getstate(self):\n        # state info we return to the caller:\n        # 0: stream is in natural order for this platform\n        # 2: endianness hasn't been determined yet\n        # (we're never writing in unnatural order)\n        return (2 if self.encoder is None else 0)\n\n    def setstate(self, state):\n        if state:\n            self.encoder = None\n        else:\n            if sys.byteorder == 'little':\n                self.encoder = codecs.utf_16_le_encode\n            else:\n                self.encoder = codecs.utf_16_be_encode\n\nclass IncrementalDecoder(codecs.BufferedIncrementalDecoder):\n    def __init__(self, errors='strict'):\n        codecs.BufferedIncrementalDecoder.__init__(self, errors)\n        self.decoder = None\n\n    def _buffer_decode(self, input, errors, final):\n        if self.decoder is None:\n            (output, consumed, byteorder) = \\\n                codecs.utf_16_ex_decode(input, errors, 0, final)\n            if byteorder == -1:\n                self.decoder = codecs.utf_16_le_decode\n            elif byteorder == 1:\n                self.decoder = codecs.utf_16_be_decode\n            elif consumed >= 2:\n                raise UnicodeError(\"UTF-16 stream does not start with BOM\")\n            return (output, consumed)\n        return self.decoder(input, self.errors, final)\n\n    def reset(self):\n        codecs.BufferedIncrementalDecoder.reset(self)\n        self.decoder = None\n\nclass StreamWriter(codecs.StreamWriter):\n    def __init__(self, stream, errors='strict'):\n        codecs.StreamWriter.__init__(self, stream, errors)\n        self.encoder = None\n\n    def reset(self):\n        codecs.StreamWriter.reset(self)\n        self.encoder = None\n\n    def encode(self, input, errors='strict'):\n        if self.encoder is None:\n            result = codecs.utf_16_encode(input, errors)\n            if sys.byteorder == 'little':\n                self.encoder = codecs.utf_16_le_encode\n            else:\n                self.encoder = codecs.utf_16_be_encode\n            return result\n        else:\n            return self.encoder(input, errors)\n\nclass StreamReader(codecs.StreamReader):\n\n    def reset(self):\n        codecs.StreamReader.reset(self)\n        try:\n            del self.decode\n        except AttributeError:\n            pass\n\n    def decode(self, input, errors='strict'):\n        (object, consumed, byteorder) = \\\n            codecs.utf_16_ex_decode(input, errors, 0, False)\n        if byteorder == -1:\n            self.decode = codecs.utf_16_le_decode\n        elif byteorder == 1:\n            self.decode = codecs.utf_16_be_decode\n        elif consumed>=2:\n            raise UnicodeError,\"UTF-16 stream does not start with BOM\"\n        return (object, consumed)\n\n### encodings module API\n\ndef getregentry():\n    return codecs.CodecInfo(\n        name='utf-16',\n        encode=encode,\n        decode=decode,\n        incrementalencoder=IncrementalEncoder,\n        incrementaldecoder=IncrementalDecoder,\n        streamreader=StreamReader,\n        streamwriter=StreamWriter,\n    )\n", 
    "encodings.utf_8": "\"\"\" Python 'utf-8' Codec\n\n\nWritten by Marc-Andre Lemburg (mal@lemburg.com).\n\n(c) Copyright CNRI, All Rights Reserved. NO WARRANTY.\n\n\"\"\"\nimport codecs\n\n### Codec APIs\n\nencode = codecs.utf_8_encode\n\ndef decode(input, errors='strict'):\n    return codecs.utf_8_decode(input, errors, True)\n\nclass IncrementalEncoder(codecs.IncrementalEncoder):\n    def encode(self, input, final=False):\n        return codecs.utf_8_encode(input, self.errors)[0]\n\nclass IncrementalDecoder(codecs.BufferedIncrementalDecoder):\n    _buffer_decode = codecs.utf_8_decode\n\nclass StreamWriter(codecs.StreamWriter):\n    encode = codecs.utf_8_encode\n\nclass StreamReader(codecs.StreamReader):\n    decode = codecs.utf_8_decode\n\n### encodings module API\n\ndef getregentry():\n    return codecs.CodecInfo(\n        name='utf-8',\n        encode=encode,\n        decode=decode,\n        incrementalencoder=IncrementalEncoder,\n        incrementaldecoder=IncrementalDecoder,\n        streamreader=StreamReader,\n        streamwriter=StreamWriter,\n    )\n", 
    "genericpath": "\"\"\"\nPath operations common to more than one OS\nDo not use directly.  The OS specific modules import the appropriate\nfunctions from this module themselves.\n\"\"\"\nimport os\nimport stat\n\n__all__ = ['commonprefix', 'exists', 'getatime', 'getctime', 'getmtime',\n           'getsize', 'isdir', 'isfile']\n\n\n# Does a path exist?\n# This is false for dangling symbolic links on systems that support them.\ndef exists(path):\n    \"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\n    try:\n        os.stat(path)\n    except os.error:\n        return False\n    return True\n\n\n# This follows symbolic links, so both islink() and isdir() can be true\n# for the same path on systems that support symlinks\ndef isfile(path):\n    \"\"\"Test whether a path is a regular file\"\"\"\n    try:\n        st = os.stat(path)\n    except os.error:\n        return False\n    return stat.S_ISREG(st.st_mode)\n\n\n# Is a path a directory?\n# This follows symbolic links, so both islink() and isdir()\n# can be true for the same path on systems that support symlinks\ndef isdir(s):\n    \"\"\"Return true if the pathname refers to an existing directory.\"\"\"\n    try:\n        st = os.stat(s)\n    except os.error:\n        return False\n    return stat.S_ISDIR(st.st_mode)\n\n\ndef getsize(filename):\n    \"\"\"Return the size of a file, reported by os.stat().\"\"\"\n    return os.stat(filename).st_size\n\n\ndef getmtime(filename):\n    \"\"\"Return the last modification time of a file, reported by os.stat().\"\"\"\n    return os.stat(filename).st_mtime\n\n\ndef getatime(filename):\n    \"\"\"Return the last access time of a file, reported by os.stat().\"\"\"\n    return os.stat(filename).st_atime\n\n\ndef getctime(filename):\n    \"\"\"Return the metadata change time of a file, reported by os.stat().\"\"\"\n    return os.stat(filename).st_ctime\n\n\n# Return the longest prefix of all list elements.\ndef commonprefix(m):\n    \"Given a list of pathnames, returns the longest common leading component\"\n    if not m: return ''\n    s1 = min(m)\n    s2 = max(m)\n    for i, c in enumerate(s1):\n        if c != s2[i]:\n            return s1[:i]\n    return s1\n\n# Split a path in root and extension.\n# The extension is everything starting at the last dot in the last\n# pathname component; the root is everything before that.\n# It is always true that root + ext == p.\n\n# Generic implementation of splitext, to be parametrized with\n# the separators\ndef _splitext(p, sep, altsep, extsep):\n    \"\"\"Split the extension from a pathname.\n\n    Extension is everything from the last dot to the end, ignoring\n    leading dots.  Returns \"(root, ext)\"; ext may be empty.\"\"\"\n\n    sepIndex = p.rfind(sep)\n    if altsep:\n        altsepIndex = p.rfind(altsep)\n        sepIndex = max(sepIndex, altsepIndex)\n\n    dotIndex = p.rfind(extsep)\n    if dotIndex > sepIndex:\n        # skip all leading dots\n        filenameIndex = sepIndex + 1\n        while filenameIndex < dotIndex:\n            if p[filenameIndex] != extsep:\n                return p[:dotIndex], p[dotIndex:]\n            filenameIndex += 1\n\n    return p, ''\n", 
    "getopt": "\"\"\"Parser for command line options.\n\nThis module helps scripts to parse the command line arguments in\nsys.argv.  It supports the same conventions as the Unix getopt()\nfunction (including the special meanings of arguments of the form `-'\nand `--').  Long options similar to those supported by GNU software\nmay be used as well via an optional third argument.  This module\nprovides two functions and an exception:\n\ngetopt() -- Parse command line options\ngnu_getopt() -- Like getopt(), but allow option and non-option arguments\nto be intermixed.\nGetoptError -- exception (class) raised with 'opt' attribute, which is the\noption involved with the exception.\n\"\"\"\n\n# Long option support added by Lars Wirzenius <liw@iki.fi>.\n#\n# Gerrit Holl <gerrit@nl.linux.org> moved the string-based exceptions\n# to class-based exceptions.\n#\n# Peter Astrand <astrand@lysator.liu.se> added gnu_getopt().\n#\n# TODO for gnu_getopt():\n#\n# - GNU getopt_long_only mechanism\n# - allow the caller to specify ordering\n# - RETURN_IN_ORDER option\n# - GNU extension with '-' as first character of option string\n# - optional arguments, specified by double colons\n# - a option string with a W followed by semicolon should\n#   treat \"-W foo\" as \"--foo\"\n\n__all__ = [\"GetoptError\",\"error\",\"getopt\",\"gnu_getopt\"]\n\nimport os\n\nclass GetoptError(Exception):\n    opt = ''\n    msg = ''\n    def __init__(self, msg, opt=''):\n        self.msg = msg\n        self.opt = opt\n        Exception.__init__(self, msg, opt)\n\n    def __str__(self):\n        return self.msg\n\nerror = GetoptError # backward compatibility\n\ndef getopt(args, shortopts, longopts = []):\n    \"\"\"getopt(args, options[, long_options]) -> opts, args\n\n    Parses command line options and parameter list.  args is the\n    argument list to be parsed, without the leading reference to the\n    running program.  Typically, this means \"sys.argv[1:]\".  shortopts\n    is the string of option letters that the script wants to\n    recognize, with options that require an argument followed by a\n    colon (i.e., the same format that Unix getopt() uses).  If\n    specified, longopts is a list of strings with the names of the\n    long options which should be supported.  The leading '--'\n    characters should not be included in the option name.  Options\n    which require an argument should be followed by an equal sign\n    ('=').\n\n    The return value consists of two elements: the first is a list of\n    (option, value) pairs; the second is the list of program arguments\n    left after the option list was stripped (this is a trailing slice\n    of the first argument).  Each option-and-value pair returned has\n    the option as its first element, prefixed with a hyphen (e.g.,\n    '-x'), and the option argument as its second element, or an empty\n    string if the option has no argument.  The options occur in the\n    list in the same order in which they were found, thus allowing\n    multiple occurrences.  Long and short options may be mixed.\n\n    \"\"\"\n\n    opts = []\n    if type(longopts) == type(\"\"):\n        longopts = [longopts]\n    else:\n        longopts = list(longopts)\n    while args and args[0].startswith('-') and args[0] != '-':\n        if args[0] == '--':\n            args = args[1:]\n            break\n        if args[0].startswith('--'):\n            opts, args = do_longs(opts, args[0][2:], longopts, args[1:])\n        else:\n            opts, args = do_shorts(opts, args[0][1:], shortopts, args[1:])\n\n    return opts, args\n\ndef gnu_getopt(args, shortopts, longopts = []):\n    \"\"\"getopt(args, options[, long_options]) -> opts, args\n\n    This function works like getopt(), except that GNU style scanning\n    mode is used by default. This means that option and non-option\n    arguments may be intermixed. The getopt() function stops\n    processing options as soon as a non-option argument is\n    encountered.\n\n    If the first character of the option string is `+', or if the\n    environment variable POSIXLY_CORRECT is set, then option\n    processing stops as soon as a non-option argument is encountered.\n\n    \"\"\"\n\n    opts = []\n    prog_args = []\n    if isinstance(longopts, str):\n        longopts = [longopts]\n    else:\n        longopts = list(longopts)\n\n    # Allow options after non-option arguments?\n    if shortopts.startswith('+'):\n        shortopts = shortopts[1:]\n        all_options_first = True\n    elif os.environ.get(\"POSIXLY_CORRECT\"):\n        all_options_first = True\n    else:\n        all_options_first = False\n\n    while args:\n        if args[0] == '--':\n            prog_args += args[1:]\n            break\n\n        if args[0][:2] == '--':\n            opts, args = do_longs(opts, args[0][2:], longopts, args[1:])\n        elif args[0][:1] == '-' and args[0] != '-':\n            opts, args = do_shorts(opts, args[0][1:], shortopts, args[1:])\n        else:\n            if all_options_first:\n                prog_args += args\n                break\n            else:\n                prog_args.append(args[0])\n                args = args[1:]\n\n    return opts, prog_args\n\ndef do_longs(opts, opt, longopts, args):\n    try:\n        i = opt.index('=')\n    except ValueError:\n        optarg = None\n    else:\n        opt, optarg = opt[:i], opt[i+1:]\n\n    has_arg, opt = long_has_args(opt, longopts)\n    if has_arg:\n        if optarg is None:\n            if not args:\n                raise GetoptError('option --%s requires argument' % opt, opt)\n            optarg, args = args[0], args[1:]\n    elif optarg is not None:\n        raise GetoptError('option --%s must not have an argument' % opt, opt)\n    opts.append(('--' + opt, optarg or ''))\n    return opts, args\n\n# Return:\n#   has_arg?\n#   full option name\ndef long_has_args(opt, longopts):\n    possibilities = [o for o in longopts if o.startswith(opt)]\n    if not possibilities:\n        raise GetoptError('option --%s not recognized' % opt, opt)\n    # Is there an exact match?\n    if opt in possibilities:\n        return False, opt\n    elif opt + '=' in possibilities:\n        return True, opt\n    # No exact match, so better be unique.\n    if len(possibilities) > 1:\n        # XXX since possibilities contains all valid continuations, might be\n        # nice to work them into the error msg\n        raise GetoptError('option --%s not a unique prefix' % opt, opt)\n    assert len(possibilities) == 1\n    unique_match = possibilities[0]\n    has_arg = unique_match.endswith('=')\n    if has_arg:\n        unique_match = unique_match[:-1]\n    return has_arg, unique_match\n\ndef do_shorts(opts, optstring, shortopts, args):\n    while optstring != '':\n        opt, optstring = optstring[0], optstring[1:]\n        if short_has_arg(opt, shortopts):\n            if optstring == '':\n                if not args:\n                    raise GetoptError('option -%s requires argument' % opt,\n                                      opt)\n                optstring, args = args[0], args[1:]\n            optarg, optstring = optstring, ''\n        else:\n            optarg = ''\n        opts.append(('-' + opt, optarg))\n    return opts, args\n\ndef short_has_arg(opt, shortopts):\n    for i in range(len(shortopts)):\n        if opt == shortopts[i] != ':':\n            return shortopts.startswith(':', i+1)\n    raise GetoptError('option -%s not recognized' % opt, opt)\n\nif __name__ == '__main__':\n    import sys\n    print getopt(sys.argv[1:], \"a:b\", [\"alpha=\", \"beta\"])\n", 
    "linecache": "\"\"\"Cache lines from files.\n\nThis is intended to read lines from modules imported -- hence if a filename\nis not found, it will look down the module search path for a file by\nthat name.\n\"\"\"\n\nimport sys\nimport os\n\n__all__ = [\"getline\", \"clearcache\", \"checkcache\"]\n\ndef getline(filename, lineno, module_globals=None):\n    lines = getlines(filename, module_globals)\n    if 1 <= lineno <= len(lines):\n        return lines[lineno-1]\n    else:\n        return ''\n\n\n# The cache\n\ncache = {} # The cache\n\n\ndef clearcache():\n    \"\"\"Clear the cache entirely.\"\"\"\n\n    global cache\n    cache = {}\n\n\ndef getlines(filename, module_globals=None):\n    \"\"\"Get the lines for a file from the cache.\n    Update the cache if it doesn't contain an entry for this file already.\"\"\"\n\n    if filename in cache:\n        return cache[filename][2]\n    else:\n        return updatecache(filename, module_globals)\n\n\ndef checkcache(filename=None):\n    \"\"\"Discard cache entries that are out of date.\n    (This is not checked upon each call!)\"\"\"\n\n    if filename is None:\n        filenames = cache.keys()\n    else:\n        if filename in cache:\n            filenames = [filename]\n        else:\n            return\n\n    for filename in filenames:\n        size, mtime, lines, fullname = cache[filename]\n        if mtime is None:\n            continue   # no-op for files loaded via a __loader__\n        try:\n            stat = os.stat(fullname)\n        except os.error:\n            del cache[filename]\n            continue\n        if size != stat.st_size or mtime != stat.st_mtime:\n            del cache[filename]\n\n\ndef updatecache(filename, module_globals=None):\n    \"\"\"Update a cache entry and return its list of lines.\n    If something's wrong, print a message, discard the cache entry,\n    and return an empty list.\"\"\"\n\n    if filename in cache:\n        del cache[filename]\n    if not filename or (filename.startswith('<') and filename.endswith('>')):\n        return []\n\n    fullname = filename\n    try:\n        stat = os.stat(fullname)\n    except OSError:\n        basename = filename\n\n        # Try for a __loader__, if available\n        if module_globals and '__loader__' in module_globals:\n            name = module_globals.get('__name__')\n            loader = module_globals['__loader__']\n            get_source = getattr(loader, 'get_source', None)\n\n            if name and get_source:\n                try:\n                    data = get_source(name)\n                except (ImportError, IOError):\n                    pass\n                else:\n                    if data is None:\n                        # No luck, the PEP302 loader cannot find the source\n                        # for this module.\n                        return []\n                    cache[filename] = (\n                        len(data), None,\n                        [line+'\\n' for line in data.splitlines()], fullname\n                    )\n                    return cache[filename][2]\n\n        # Try looking through the module search path, which is only useful\n        # when handling a relative filename.\n        if os.path.isabs(filename):\n            return []\n\n        for dirname in sys.path:\n            # When using imputil, sys.path may contain things other than\n            # strings; ignore them when it happens.\n            try:\n                fullname = os.path.join(dirname, basename)\n            except (TypeError, AttributeError):\n                # Not sufficiently string-like to do anything useful with.\n                continue\n            try:\n                stat = os.stat(fullname)\n                break\n            except os.error:\n                pass\n        else:\n            return []\n    try:\n        with open(fullname, 'rU') as fp:\n            lines = fp.readlines()\n    except IOError:\n        return []\n    if lines and not lines[-1].endswith('\\n'):\n        lines[-1] += '\\n'\n    size, mtime = stat.st_size, stat.st_mtime\n    cache[filename] = size, mtime, lines, fullname\n    return lines\n", 
    "os": "r\"\"\"OS routines for NT or Posix depending on what system we're on.\n\nThis exports:\n  - all functions from posix, nt, os2, or ce, e.g. unlink, stat, etc.\n  - os.path is one of the modules posixpath, or ntpath\n  - os.name is 'posix', 'nt', 'os2', 'ce' or 'riscos'\n  - os.curdir is a string representing the current directory ('.' or ':')\n  - os.pardir is a string representing the parent directory ('..' or '::')\n  - os.sep is the (or a most common) pathname separator ('/' or ':' or '\\\\')\n  - os.extsep is the extension separator ('.' or '/')\n  - os.altsep is the alternate pathname separator (None or '/')\n  - os.pathsep is the component separator used in $PATH etc\n  - os.linesep is the line separator in text files ('\\r' or '\\n' or '\\r\\n')\n  - os.defpath is the default search path for executables\n  - os.devnull is the file path of the null device ('/dev/null', etc.)\n\nPrograms that import and use 'os' stand a better chance of being\nportable between different platforms.  Of course, they must then\nonly use functions that are defined by all platforms (e.g., unlink\nand opendir), and leave all pathname manipulation to os.path\n(e.g., split and join).\n\"\"\"\n\n#'\n\nimport sys, errno\n\n_names = sys.builtin_module_names\n\n# Note:  more names are added to __all__ later.\n__all__ = [\"altsep\", \"curdir\", \"pardir\", \"sep\", \"extsep\", \"pathsep\", \"linesep\",\n           \"defpath\", \"name\", \"path\", \"devnull\",\n           \"SEEK_SET\", \"SEEK_CUR\", \"SEEK_END\"]\n\ndef _get_exports_list(module):\n    try:\n        return list(module.__all__)\n    except AttributeError:\n        return [n for n in dir(module) if n[0] != '_']\n\nif 'posix' in _names:\n    name = 'posix'\n    linesep = '\\n'\n    from posix import *\n    try:\n        from posix import _exit\n    except ImportError:\n        pass\n    import posixpath as path\n\n    import posix\n    __all__.extend(_get_exports_list(posix))\n    del posix\n\nelif 'nt' in _names:\n    name = 'nt'\n    linesep = '\\r\\n'\n    from nt import *\n    try:\n        from nt import _exit\n    except ImportError:\n        pass\n    import ntpath as path\n\n    import nt\n    __all__.extend(_get_exports_list(nt))\n    del nt\n\nelif 'os2' in _names:\n    name = 'os2'\n    linesep = '\\r\\n'\n    from os2 import *\n    try:\n        from os2 import _exit\n    except ImportError:\n        pass\n    if sys.version.find('EMX GCC') == -1:\n        import ntpath as path\n    else:\n        import os2emxpath as path\n        from _emx_link import link\n\n    import os2\n    __all__.extend(_get_exports_list(os2))\n    del os2\n\nelif 'ce' in _names:\n    name = 'ce'\n    linesep = '\\r\\n'\n    from ce import *\n    try:\n        from ce import _exit\n    except ImportError:\n        pass\n    # We can use the standard Windows path.\n    import ntpath as path\n\n    import ce\n    __all__.extend(_get_exports_list(ce))\n    del ce\n\nelif 'riscos' in _names:\n    name = 'riscos'\n    linesep = '\\n'\n    from riscos import *\n    try:\n        from riscos import _exit\n    except ImportError:\n        pass\n    import riscospath as path\n\n    import riscos\n    __all__.extend(_get_exports_list(riscos))\n    del riscos\n\nelse:\n    raise ImportError, 'no os specific module found'\n\nsys.modules['os.path'] = path\nfrom os.path import (curdir, pardir, sep, pathsep, defpath, extsep, altsep,\n    devnull)\n\ndel _names\n\n# Python uses fixed values for the SEEK_ constants; they are mapped\n# to native constants if necessary in posixmodule.c\nSEEK_SET = 0\nSEEK_CUR = 1\nSEEK_END = 2\n\n#'\n\n# Super directory utilities.\n# (Inspired by Eric Raymond; the doc strings are mostly his)\n\ndef makedirs(name, mode=0777):\n    \"\"\"makedirs(path [, mode=0777])\n\n    Super-mkdir; create a leaf directory and all intermediate ones.\n    Works like mkdir, except that any intermediate path segment (not\n    just the rightmost) will be created if it does not exist.  This is\n    recursive.\n\n    \"\"\"\n    head, tail = path.split(name)\n    if not tail:\n        head, tail = path.split(head)\n    if head and tail and not path.exists(head):\n        try:\n            makedirs(head, mode)\n        except OSError, e:\n            # be happy if someone already created the path\n            if e.errno != errno.EEXIST:\n                raise\n        if tail == curdir:           # xxx/newdir/. exists if xxx/newdir exists\n            return\n    mkdir(name, mode)\n\ndef removedirs(name):\n    \"\"\"removedirs(path)\n\n    Super-rmdir; remove a leaf directory and all empty intermediate\n    ones.  Works like rmdir except that, if the leaf directory is\n    successfully removed, directories corresponding to rightmost path\n    segments will be pruned away until either the whole path is\n    consumed or an error occurs.  Errors during this latter phase are\n    ignored -- they generally mean that a directory was not empty.\n\n    \"\"\"\n    rmdir(name)\n    head, tail = path.split(name)\n    if not tail:\n        head, tail = path.split(head)\n    while head and tail:\n        try:\n            rmdir(head)\n        except error:\n            break\n        head, tail = path.split(head)\n\ndef renames(old, new):\n    \"\"\"renames(old, new)\n\n    Super-rename; create directories as necessary and delete any left\n    empty.  Works like rename, except creation of any intermediate\n    directories needed to make the new pathname good is attempted\n    first.  After the rename, directories corresponding to rightmost\n    path segments of the old name will be pruned way until either the\n    whole path is consumed or a nonempty directory is found.\n\n    Note: this function can fail with the new directory structure made\n    if you lack permissions needed to unlink the leaf directory or\n    file.\n\n    \"\"\"\n    head, tail = path.split(new)\n    if head and tail and not path.exists(head):\n        makedirs(head)\n    rename(old, new)\n    head, tail = path.split(old)\n    if head and tail:\n        try:\n            removedirs(head)\n        except error:\n            pass\n\n__all__.extend([\"makedirs\", \"removedirs\", \"renames\"])\n\ndef walk(top, topdown=True, onerror=None, followlinks=False):\n    \"\"\"Directory tree generator.\n\n    For each directory in the directory tree rooted at top (including top\n    itself, but excluding '.' and '..'), yields a 3-tuple\n\n        dirpath, dirnames, filenames\n\n    dirpath is a string, the path to the directory.  dirnames is a list of\n    the names of the subdirectories in dirpath (excluding '.' and '..').\n    filenames is a list of the names of the non-directory files in dirpath.\n    Note that the names in the lists are just names, with no path components.\n    To get a full path (which begins with top) to a file or directory in\n    dirpath, do os.path.join(dirpath, name).\n\n    If optional arg 'topdown' is true or not specified, the triple for a\n    directory is generated before the triples for any of its subdirectories\n    (directories are generated top down).  If topdown is false, the triple\n    for a directory is generated after the triples for all of its\n    subdirectories (directories are generated bottom up).\n\n    When topdown is true, the caller can modify the dirnames list in-place\n    (e.g., via del or slice assignment), and walk will only recurse into the\n    subdirectories whose names remain in dirnames; this can be used to prune the\n    search, or to impose a specific order of visiting.  Modifying dirnames when\n    topdown is false is ineffective, since the directories in dirnames have\n    already been generated by the time dirnames itself is generated. No matter\n    the value of topdown, the list of subdirectories is retrieved before the\n    tuples for the directory and its subdirectories are generated.\n\n    By default errors from the os.listdir() call are ignored.  If\n    optional arg 'onerror' is specified, it should be a function; it\n    will be called with one argument, an os.error instance.  It can\n    report the error to continue with the walk, or raise the exception\n    to abort the walk.  Note that the filename is available as the\n    filename attribute of the exception object.\n\n    By default, os.walk does not follow symbolic links to subdirectories on\n    systems that support them.  In order to get this functionality, set the\n    optional argument 'followlinks' to true.\n\n    Caution:  if you pass a relative pathname for top, don't change the\n    current working directory between resumptions of walk.  walk never\n    changes the current directory, and assumes that the client doesn't\n    either.\n\n    Example:\n\n    import os\n    from os.path import join, getsize\n    for root, dirs, files in os.walk('python/Lib/email'):\n        print root, \"consumes\",\n        print sum([getsize(join(root, name)) for name in files]),\n        print \"bytes in\", len(files), \"non-directory files\"\n        if 'CVS' in dirs:\n            dirs.remove('CVS')  # don't visit CVS directories\n\n    \"\"\"\n\n    islink, join, isdir = path.islink, path.join, path.isdir\n\n    # We may not have read permission for top, in which case we can't\n    # get a list of the files the directory contains.  os.path.walk\n    # always suppressed the exception then, rather than blow up for a\n    # minor reason when (say) a thousand readable directories are still\n    # left to visit.  That logic is copied here.\n    try:\n        # Note that listdir and error are globals in this module due\n        # to earlier import-*.\n        names = listdir(top)\n    except error, err:\n        if onerror is not None:\n            onerror(err)\n        return\n\n    dirs, nondirs = [], []\n    for name in names:\n        if isdir(join(top, name)):\n            dirs.append(name)\n        else:\n            nondirs.append(name)\n\n    if topdown:\n        yield top, dirs, nondirs\n    for name in dirs:\n        new_path = join(top, name)\n        if followlinks or not islink(new_path):\n            for x in walk(new_path, topdown, onerror, followlinks):\n                yield x\n    if not topdown:\n        yield top, dirs, nondirs\n\n__all__.append(\"walk\")\n\n# Make sure os.environ exists, at least\ntry:\n    environ\nexcept NameError:\n    environ = {}\n\ndef execl(file, *args):\n    \"\"\"execl(file, *args)\n\n    Execute the executable file with argument list args, replacing the\n    current process. \"\"\"\n    execv(file, args)\n\ndef execle(file, *args):\n    \"\"\"execle(file, *args, env)\n\n    Execute the executable file with argument list args and\n    environment env, replacing the current process. \"\"\"\n    env = args[-1]\n    execve(file, args[:-1], env)\n\ndef execlp(file, *args):\n    \"\"\"execlp(file, *args)\n\n    Execute the executable file (which is searched for along $PATH)\n    with argument list args, replacing the current process. \"\"\"\n    execvp(file, args)\n\ndef execlpe(file, *args):\n    \"\"\"execlpe(file, *args, env)\n\n    Execute the executable file (which is searched for along $PATH)\n    with argument list args and environment env, replacing the current\n    process. \"\"\"\n    env = args[-1]\n    execvpe(file, args[:-1], env)\n\ndef execvp(file, args):\n    \"\"\"execvp(file, args)\n\n    Execute the executable file (which is searched for along $PATH)\n    with argument list args, replacing the current process.\n    args may be a list or tuple of strings. \"\"\"\n    _execvpe(file, args)\n\ndef execvpe(file, args, env):\n    \"\"\"execvpe(file, args, env)\n\n    Execute the executable file (which is searched for along $PATH)\n    with argument list args and environment env , replacing the\n    current process.\n    args may be a list or tuple of strings. \"\"\"\n    _execvpe(file, args, env)\n\n__all__.extend([\"execl\",\"execle\",\"execlp\",\"execlpe\",\"execvp\",\"execvpe\"])\n\ndef _execvpe(file, args, env=None):\n    if env is not None:\n        func = execve\n        argrest = (args, env)\n    else:\n        func = execv\n        argrest = (args,)\n        env = environ\n\n    head, tail = path.split(file)\n    if head:\n        func(file, *argrest)\n        return\n    if 'PATH' in env:\n        envpath = env['PATH']\n    else:\n        envpath = defpath\n    PATH = envpath.split(pathsep)\n    saved_exc = None\n    saved_tb = None\n    for dir in PATH:\n        fullname = path.join(dir, file)\n        try:\n            func(fullname, *argrest)\n        except error, e:\n            tb = sys.exc_info()[2]\n            if (e.errno != errno.ENOENT and e.errno != errno.ENOTDIR\n                and saved_exc is None):\n                saved_exc = e\n                saved_tb = tb\n    if saved_exc:\n        raise error, saved_exc, saved_tb\n    raise error, e, tb\n\n# Change environ to automatically call putenv() if it exists\ntry:\n    # This will fail if there's no putenv\n    putenv\nexcept NameError:\n    pass\nelse:\n    import UserDict\n\n    # Fake unsetenv() for Windows\n    # not sure about os2 here but\n    # I'm guessing they are the same.\n\n    if name in ('os2', 'nt'):\n        def unsetenv(key):\n            putenv(key, \"\")\n\n    if name == \"riscos\":\n        # On RISC OS, all env access goes through getenv and putenv\n        from riscosenviron import _Environ\n    elif name in ('os2', 'nt'):  # Where Env Var Names Must Be UPPERCASE\n        # But we store them as upper case\n        class _Environ(UserDict.IterableUserDict):\n            def __init__(self, environ):\n                UserDict.UserDict.__init__(self)\n                data = self.data\n                for k, v in environ.items():\n                    data[k.upper()] = v\n            def __setitem__(self, key, item):\n                putenv(key, item)\n                self.data[key.upper()] = item\n            def __getitem__(self, key):\n                return self.data[key.upper()]\n            try:\n                unsetenv\n            except NameError:\n                def __delitem__(self, key):\n                    del self.data[key.upper()]\n            else:\n                def __delitem__(self, key):\n                    unsetenv(key)\n                    del self.data[key.upper()]\n                def clear(self):\n                    for key in self.data.keys():\n                        unsetenv(key)\n                        del self.data[key]\n                def pop(self, key, *args):\n                    unsetenv(key)\n                    return self.data.pop(key.upper(), *args)\n            def has_key(self, key):\n                return key.upper() in self.data\n            def __contains__(self, key):\n                return key.upper() in self.data\n            def get(self, key, failobj=None):\n                return self.data.get(key.upper(), failobj)\n            def update(self, dict=None, **kwargs):\n                if dict:\n                    try:\n                        keys = dict.keys()\n                    except AttributeError:\n                        # List of (key, value)\n                        for k, v in dict:\n                            self[k] = v\n                    else:\n                        # got keys\n                        # cannot use items(), since mappings\n                        # may not have them.\n                        for k in keys:\n                            self[k] = dict[k]\n                if kwargs:\n                    self.update(kwargs)\n            def copy(self):\n                return dict(self)\n\n    else:  # Where Env Var Names Can Be Mixed Case\n        class _Environ(UserDict.IterableUserDict):\n            def __init__(self, environ):\n                UserDict.UserDict.__init__(self)\n                self.data = environ\n            def __setitem__(self, key, item):\n                putenv(key, item)\n                self.data[key] = item\n            def update(self,  dict=None, **kwargs):\n                if dict:\n                    try:\n                        keys = dict.keys()\n                    except AttributeError:\n                        # List of (key, value)\n                        for k, v in dict:\n                            self[k] = v\n                    else:\n                        # got keys\n                        # cannot use items(), since mappings\n                        # may not have them.\n                        for k in keys:\n                            self[k] = dict[k]\n                if kwargs:\n                    self.update(kwargs)\n            try:\n                unsetenv\n            except NameError:\n                pass\n            else:\n                def __delitem__(self, key):\n                    unsetenv(key)\n                    del self.data[key]\n                def clear(self):\n                    for key in self.data.keys():\n                        unsetenv(key)\n                        del self.data[key]\n                def pop(self, key, *args):\n                    unsetenv(key)\n                    return self.data.pop(key, *args)\n            def copy(self):\n                return dict(self)\n\n\n    environ = _Environ(environ)\n\ndef getenv(key, default=None):\n    \"\"\"Get an environment variable, return None if it doesn't exist.\n    The optional second argument can specify an alternate default.\"\"\"\n    return environ.get(key, default)\n__all__.append(\"getenv\")\n\ndef _exists(name):\n    return name in globals()\n\n# Supply spawn*() (probably only for Unix)\nif _exists(\"fork\") and not _exists(\"spawnv\") and _exists(\"execv\"):\n\n    P_WAIT = 0\n    P_NOWAIT = P_NOWAITO = 1\n\n    # XXX Should we support P_DETACH?  I suppose it could fork()**2\n    # and close the std I/O streams.  Also, P_OVERLAY is the same\n    # as execv*()?\n\n    def _spawnvef(mode, file, args, env, func):\n        # Internal helper; func is the exec*() function to use\n        pid = fork()\n        if not pid:\n            # Child\n            try:\n                if env is None:\n                    func(file, args)\n                else:\n                    func(file, args, env)\n            except:\n                _exit(127)\n        else:\n            # Parent\n            if mode == P_NOWAIT:\n                return pid # Caller is responsible for waiting!\n            while 1:\n                wpid, sts = waitpid(pid, 0)\n                if WIFSTOPPED(sts):\n                    continue\n                elif WIFSIGNALED(sts):\n                    return -WTERMSIG(sts)\n                elif WIFEXITED(sts):\n                    return WEXITSTATUS(sts)\n                else:\n                    raise error, \"Not stopped, signaled or exited???\"\n\n    def spawnv(mode, file, args):\n        \"\"\"spawnv(mode, file, args) -> integer\n\nExecute file with arguments from args in a subprocess.\nIf mode == P_NOWAIT return the pid of the process.\nIf mode == P_WAIT return the process's exit code if it exits normally;\notherwise return -SIG, where SIG is the signal that killed it. \"\"\"\n        return _spawnvef(mode, file, args, None, execv)\n\n    def spawnve(mode, file, args, env):\n        \"\"\"spawnve(mode, file, args, env) -> integer\n\nExecute file with arguments from args in a subprocess with the\nspecified environment.\nIf mode == P_NOWAIT return the pid of the process.\nIf mode == P_WAIT return the process's exit code if it exits normally;\notherwise return -SIG, where SIG is the signal that killed it. \"\"\"\n        return _spawnvef(mode, file, args, env, execve)\n\n    # Note: spawnvp[e] is't currently supported on Windows\n\n    def spawnvp(mode, file, args):\n        \"\"\"spawnvp(mode, file, args) -> integer\n\nExecute file (which is looked for along $PATH) with arguments from\nargs in a subprocess.\nIf mode == P_NOWAIT return the pid of the process.\nIf mode == P_WAIT return the process's exit code if it exits normally;\notherwise return -SIG, where SIG is the signal that killed it. \"\"\"\n        return _spawnvef(mode, file, args, None, execvp)\n\n    def spawnvpe(mode, file, args, env):\n        \"\"\"spawnvpe(mode, file, args, env) -> integer\n\nExecute file (which is looked for along $PATH) with arguments from\nargs in a subprocess with the supplied environment.\nIf mode == P_NOWAIT return the pid of the process.\nIf mode == P_WAIT return the process's exit code if it exits normally;\notherwise return -SIG, where SIG is the signal that killed it. \"\"\"\n        return _spawnvef(mode, file, args, env, execvpe)\n\nif _exists(\"spawnv\"):\n    # These aren't supplied by the basic Windows code\n    # but can be easily implemented in Python\n\n    def spawnl(mode, file, *args):\n        \"\"\"spawnl(mode, file, *args) -> integer\n\nExecute file with arguments from args in a subprocess.\nIf mode == P_NOWAIT return the pid of the process.\nIf mode == P_WAIT return the process's exit code if it exits normally;\notherwise return -SIG, where SIG is the signal that killed it. \"\"\"\n        return spawnv(mode, file, args)\n\n    def spawnle(mode, file, *args):\n        \"\"\"spawnle(mode, file, *args, env) -> integer\n\nExecute file with arguments from args in a subprocess with the\nsupplied environment.\nIf mode == P_NOWAIT return the pid of the process.\nIf mode == P_WAIT return the process's exit code if it exits normally;\notherwise return -SIG, where SIG is the signal that killed it. \"\"\"\n        env = args[-1]\n        return spawnve(mode, file, args[:-1], env)\n\n\n    __all__.extend([\"spawnv\", \"spawnve\", \"spawnl\", \"spawnle\",])\n\n\nif _exists(\"spawnvp\"):\n    # At the moment, Windows doesn't implement spawnvp[e],\n    # so it won't have spawnlp[e] either.\n    def spawnlp(mode, file, *args):\n        \"\"\"spawnlp(mode, file, *args) -> integer\n\nExecute file (which is looked for along $PATH) with arguments from\nargs in a subprocess with the supplied environment.\nIf mode == P_NOWAIT return the pid of the process.\nIf mode == P_WAIT return the process's exit code if it exits normally;\notherwise return -SIG, where SIG is the signal that killed it. \"\"\"\n        return spawnvp(mode, file, args)\n\n    def spawnlpe(mode, file, *args):\n        \"\"\"spawnlpe(mode, file, *args, env) -> integer\n\nExecute file (which is looked for along $PATH) with arguments from\nargs in a subprocess with the supplied environment.\nIf mode == P_NOWAIT return the pid of the process.\nIf mode == P_WAIT return the process's exit code if it exits normally;\notherwise return -SIG, where SIG is the signal that killed it. \"\"\"\n        env = args[-1]\n        return spawnvpe(mode, file, args[:-1], env)\n\n\n    __all__.extend([\"spawnvp\", \"spawnvpe\", \"spawnlp\", \"spawnlpe\",])\n\n\n# Supply popen2 etc. (for Unix)\nif _exists(\"fork\"):\n    if not _exists(\"popen2\"):\n        def popen2(cmd, mode=\"t\", bufsize=-1):\n            \"\"\"Execute the shell command 'cmd' in a sub-process.  On UNIX, 'cmd'\n            may be a sequence, in which case arguments will be passed directly to\n            the program without shell intervention (as with os.spawnv()).  If 'cmd'\n            is a string it will be passed to the shell (as with os.system()). If\n            'bufsize' is specified, it sets the buffer size for the I/O pipes.  The\n            file objects (child_stdin, child_stdout) are returned.\"\"\"\n            import warnings\n            msg = \"os.popen2 is deprecated.  Use the subprocess module.\"\n            warnings.warn(msg, DeprecationWarning, stacklevel=2)\n\n            import subprocess\n            PIPE = subprocess.PIPE\n            p = subprocess.Popen(cmd, shell=isinstance(cmd, basestring),\n                                 bufsize=bufsize, stdin=PIPE, stdout=PIPE,\n                                 close_fds=True)\n            return p.stdin, p.stdout\n        __all__.append(\"popen2\")\n\n    if not _exists(\"popen3\"):\n        def popen3(cmd, mode=\"t\", bufsize=-1):\n            \"\"\"Execute the shell command 'cmd' in a sub-process.  On UNIX, 'cmd'\n            may be a sequence, in which case arguments will be passed directly to\n            the program without shell intervention (as with os.spawnv()).  If 'cmd'\n            is a string it will be passed to the shell (as with os.system()). If\n            'bufsize' is specified, it sets the buffer size for the I/O pipes.  The\n            file objects (child_stdin, child_stdout, child_stderr) are returned.\"\"\"\n            import warnings\n            msg = \"os.popen3 is deprecated.  Use the subprocess module.\"\n            warnings.warn(msg, DeprecationWarning, stacklevel=2)\n\n            import subprocess\n            PIPE = subprocess.PIPE\n            p = subprocess.Popen(cmd, shell=isinstance(cmd, basestring),\n                                 bufsize=bufsize, stdin=PIPE, stdout=PIPE,\n                                 stderr=PIPE, close_fds=True)\n            return p.stdin, p.stdout, p.stderr\n        __all__.append(\"popen3\")\n\n    if not _exists(\"popen4\"):\n        def popen4(cmd, mode=\"t\", bufsize=-1):\n            \"\"\"Execute the shell command 'cmd' in a sub-process.  On UNIX, 'cmd'\n            may be a sequence, in which case arguments will be passed directly to\n            the program without shell intervention (as with os.spawnv()).  If 'cmd'\n            is a string it will be passed to the shell (as with os.system()). If\n            'bufsize' is specified, it sets the buffer size for the I/O pipes.  The\n            file objects (child_stdin, child_stdout_stderr) are returned.\"\"\"\n            import warnings\n            msg = \"os.popen4 is deprecated.  Use the subprocess module.\"\n            warnings.warn(msg, DeprecationWarning, stacklevel=2)\n\n            import subprocess\n            PIPE = subprocess.PIPE\n            p = subprocess.Popen(cmd, shell=isinstance(cmd, basestring),\n                                 bufsize=bufsize, stdin=PIPE, stdout=PIPE,\n                                 stderr=subprocess.STDOUT, close_fds=True)\n            return p.stdin, p.stdout\n        __all__.append(\"popen4\")\n\nimport copy_reg as _copy_reg\n\ndef _make_stat_result(tup, dict):\n    return stat_result(tup, dict)\n\ndef _pickle_stat_result(sr):\n    (type, args) = sr.__reduce__()\n    return (_make_stat_result, args)\n\ntry:\n    _copy_reg.pickle(stat_result, _pickle_stat_result, _make_stat_result)\nexcept NameError: # stat_result may not exist\n    pass\n\ndef _make_statvfs_result(tup, dict):\n    return statvfs_result(tup, dict)\n\ndef _pickle_statvfs_result(sr):\n    (type, args) = sr.__reduce__()\n    return (_make_statvfs_result, args)\n\ntry:\n    _copy_reg.pickle(statvfs_result, _pickle_statvfs_result,\n                     _make_statvfs_result)\nexcept NameError: # statvfs_result may not exist\n    pass\n", 
    "posixpath": "\"\"\"Common operations on Posix pathnames.\n\nInstead of importing this module directly, import os and refer to\nthis module as os.path.  The \"os.path\" name is an alias for this\nmodule on Posix systems; on other systems (e.g. Mac, Windows),\nos.path provides the same operations in a manner specific to that\nplatform, and is an alias to another module (e.g. macpath, ntpath).\n\nSome of this can actually be useful on non-Posix systems too, e.g.\nfor manipulation of the pathname component of URLs.\n\"\"\"\n\nimport os\nimport sys\nimport stat\nimport genericpath\nimport warnings\nfrom genericpath import *\n\ntry:\n    _unicode = unicode\nexcept NameError:\n    # If Python is built without Unicode support, the unicode type\n    # will not exist. Fake one.\n    class _unicode(object):\n        pass\n\n__all__ = [\"normcase\",\"isabs\",\"join\",\"splitdrive\",\"split\",\"splitext\",\n           \"basename\",\"dirname\",\"commonprefix\",\"getsize\",\"getmtime\",\n           \"getatime\",\"getctime\",\"islink\",\"exists\",\"lexists\",\"isdir\",\"isfile\",\n           \"ismount\",\"walk\",\"expanduser\",\"expandvars\",\"normpath\",\"abspath\",\n           \"samefile\",\"sameopenfile\",\"samestat\",\n           \"curdir\",\"pardir\",\"sep\",\"pathsep\",\"defpath\",\"altsep\",\"extsep\",\n           \"devnull\",\"realpath\",\"supports_unicode_filenames\",\"relpath\"]\n\n# strings representing various path-related bits and pieces\ncurdir = '.'\npardir = '..'\nextsep = '.'\nsep = '/'\npathsep = ':'\ndefpath = ':/bin:/usr/bin'\naltsep = None\ndevnull = '/dev/null'\n\n# Normalize the case of a pathname.  Trivial in Posix, string.lower on Mac.\n# On MS-DOS this may also turn slashes into backslashes; however, other\n# normalizations (such as optimizing '../' away) are not allowed\n# (another function should be defined to do that).\n\ndef normcase(s):\n    \"\"\"Normalize case of pathname.  Has no effect under Posix\"\"\"\n    return s\n\n\n# Return whether a path is absolute.\n# Trivial in Posix, harder on the Mac or MS-DOS.\n\ndef isabs(s):\n    \"\"\"Test whether a path is absolute\"\"\"\n    return s.startswith('/')\n\n\n# Join pathnames.\n# Ignore the previous parts if a part is absolute.\n# Insert a '/' unless the first part is empty or already ends in '/'.\n\ndef join(a, *p):\n    \"\"\"Join two or more pathname components, inserting '/' as needed.\n    If any component is an absolute path, all previous path components\n    will be discarded.  An empty last part will result in a path that\n    ends with a separator.\"\"\"\n    path = a\n    for b in p:\n        if b.startswith('/'):\n            path = b\n        elif path == '' or path.endswith('/'):\n            path +=  b\n        else:\n            path += '/' + b\n    return path\n\n\n# Split a path in head (everything up to the last '/') and tail (the\n# rest).  If the path ends in '/', tail will be empty.  If there is no\n# '/' in the path, head  will be empty.\n# Trailing '/'es are stripped from head unless it is the root.\n\ndef split(p):\n    \"\"\"Split a pathname.  Returns tuple \"(head, tail)\" where \"tail\" is\n    everything after the final slash.  Either part may be empty.\"\"\"\n    i = p.rfind('/') + 1\n    head, tail = p[:i], p[i:]\n    if head and head != '/'*len(head):\n        head = head.rstrip('/')\n    return head, tail\n\n\n# Split a path in root and extension.\n# The extension is everything starting at the last dot in the last\n# pathname component; the root is everything before that.\n# It is always true that root + ext == p.\n\ndef splitext(p):\n    return genericpath._splitext(p, sep, altsep, extsep)\nsplitext.__doc__ = genericpath._splitext.__doc__\n\n# Split a pathname into a drive specification and the rest of the\n# path.  Useful on DOS/Windows/NT; on Unix, the drive is always empty.\n\ndef splitdrive(p):\n    \"\"\"Split a pathname into drive and path. On Posix, drive is always\n    empty.\"\"\"\n    return '', p\n\n\n# Return the tail (basename) part of a path, same as split(path)[1].\n\ndef basename(p):\n    \"\"\"Returns the final component of a pathname\"\"\"\n    i = p.rfind('/') + 1\n    return p[i:]\n\n\n# Return the head (dirname) part of a path, same as split(path)[0].\n\ndef dirname(p):\n    \"\"\"Returns the directory component of a pathname\"\"\"\n    i = p.rfind('/') + 1\n    head = p[:i]\n    if head and head != '/'*len(head):\n        head = head.rstrip('/')\n    return head\n\n\n# Is a path a symbolic link?\n# This will always return false on systems where os.lstat doesn't exist.\n\ndef islink(path):\n    \"\"\"Test whether a path is a symbolic link\"\"\"\n    try:\n        st = os.lstat(path)\n    except (os.error, AttributeError):\n        return False\n    return stat.S_ISLNK(st.st_mode)\n\n# Being true for dangling symbolic links is also useful.\n\ndef lexists(path):\n    \"\"\"Test whether a path exists.  Returns True for broken symbolic links\"\"\"\n    try:\n        os.lstat(path)\n    except os.error:\n        return False\n    return True\n\n\n# Are two filenames really pointing to the same file?\n\ndef samefile(f1, f2):\n    \"\"\"Test whether two pathnames reference the same actual file\"\"\"\n    s1 = os.stat(f1)\n    s2 = os.stat(f2)\n    return samestat(s1, s2)\n\n\n# Are two open files really referencing the same file?\n# (Not necessarily the same file descriptor!)\n\ndef sameopenfile(fp1, fp2):\n    \"\"\"Test whether two open file objects reference the same file\"\"\"\n    s1 = os.fstat(fp1)\n    s2 = os.fstat(fp2)\n    return samestat(s1, s2)\n\n\n# Are two stat buffers (obtained from stat, fstat or lstat)\n# describing the same file?\n\ndef samestat(s1, s2):\n    \"\"\"Test whether two stat buffers reference the same file\"\"\"\n    return s1.st_ino == s2.st_ino and \\\n           s1.st_dev == s2.st_dev\n\n\n# Is a path a mount point?\n# (Does this work for all UNIXes?  Is it even guaranteed to work by Posix?)\n\ndef ismount(path):\n    \"\"\"Test whether a path is a mount point\"\"\"\n    if islink(path):\n        # A symlink can never be a mount point\n        return False\n    try:\n        s1 = os.lstat(path)\n        s2 = os.lstat(join(path, '..'))\n    except os.error:\n        return False # It doesn't exist -- so not a mount point :-)\n    dev1 = s1.st_dev\n    dev2 = s2.st_dev\n    if dev1 != dev2:\n        return True     # path/.. on a different device as path\n    ino1 = s1.st_ino\n    ino2 = s2.st_ino\n    if ino1 == ino2:\n        return True     # path/.. is the same i-node as path\n    return False\n\n\n# Directory tree walk.\n# For each directory under top (including top itself, but excluding\n# '.' and '..'), func(arg, dirname, filenames) is called, where\n# dirname is the name of the directory and filenames is the list\n# of files (and subdirectories etc.) in the directory.\n# The func may modify the filenames list, to implement a filter,\n# or to impose a different order of visiting.\n\ndef walk(top, func, arg):\n    \"\"\"Directory tree walk with callback function.\n\n    For each directory in the directory tree rooted at top (including top\n    itself, but excluding '.' and '..'), call func(arg, dirname, fnames).\n    dirname is the name of the directory, and fnames a list of the names of\n    the files and subdirectories in dirname (excluding '.' and '..').  func\n    may modify the fnames list in-place (e.g. via del or slice assignment),\n    and walk will only recurse into the subdirectories whose names remain in\n    fnames; this can be used to implement a filter, or to impose a specific\n    order of visiting.  No semantics are defined for, or required of, arg,\n    beyond that arg is always passed to func.  It can be used, e.g., to pass\n    a filename pattern, or a mutable object designed to accumulate\n    statistics.  Passing None for arg is common.\"\"\"\n    warnings.warnpy3k(\"In 3.x, os.path.walk is removed in favor of os.walk.\",\n                      stacklevel=2)\n    try:\n        names = os.listdir(top)\n    except os.error:\n        return\n    func(arg, top, names)\n    for name in names:\n        name = join(top, name)\n        try:\n            st = os.lstat(name)\n        except os.error:\n            continue\n        if stat.S_ISDIR(st.st_mode):\n            walk(name, func, arg)\n\n\n# Expand paths beginning with '~' or '~user'.\n# '~' means $HOME; '~user' means that user's home directory.\n# If the path doesn't begin with '~', or if the user or $HOME is unknown,\n# the path is returned unchanged (leaving error reporting to whatever\n# function is called with the expanded path as argument).\n# See also module 'glob' for expansion of *, ? and [...] in pathnames.\n# (A function should also be defined to do full *sh-style environment\n# variable expansion.)\n\ndef expanduser(path):\n    \"\"\"Expand ~ and ~user constructions.  If user or $HOME is unknown,\n    do nothing.\"\"\"\n    if not path.startswith('~'):\n        return path\n    i = path.find('/', 1)\n    if i < 0:\n        i = len(path)\n    if i == 1:\n        if 'HOME' not in os.environ:\n            import pwd\n            userhome = pwd.getpwuid(os.getuid()).pw_dir\n        else:\n            userhome = os.environ['HOME']\n    else:\n        import pwd\n        try:\n            pwent = pwd.getpwnam(path[1:i])\n        except KeyError:\n            return path\n        userhome = pwent.pw_dir\n    userhome = userhome.rstrip('/')\n    return (userhome + path[i:]) or '/'\n\n\n# Expand paths containing shell variable substitutions.\n# This expands the forms $variable and ${variable} only.\n# Non-existent variables are left unchanged.\n\n_varprog = None\n_uvarprog = None\n\ndef expandvars(path):\n    \"\"\"Expand shell variables of form $var and ${var}.  Unknown variables\n    are left unchanged.\"\"\"\n    global _varprog, _uvarprog\n    if '$' not in path:\n        return path\n    if isinstance(path, _unicode):\n        if not _varprog:\n            import re\n            _varprog = re.compile(r'\\$(\\w+|\\{[^}]*\\})')\n        varprog = _varprog\n        encoding = sys.getfilesystemencoding()\n    else:\n        if not _uvarprog:\n            import re\n            _uvarprog = re.compile(_unicode(r'\\$(\\w+|\\{[^}]*\\})'), re.UNICODE)\n        varprog = _uvarprog\n        encoding = None\n    i = 0\n    while True:\n        m = varprog.search(path, i)\n        if not m:\n            break\n        i, j = m.span(0)\n        name = m.group(1)\n        if name.startswith('{') and name.endswith('}'):\n            name = name[1:-1]\n        if encoding:\n            name = name.encode(encoding)\n        if name in os.environ:\n            tail = path[j:]\n            value = os.environ[name]\n            if encoding:\n                value = value.decode(encoding)\n            path = path[:i] + value\n            i = len(path)\n            path += tail\n        else:\n            i = j\n    return path\n\n\n# Normalize a path, e.g. A//B, A/./B and A/foo/../B all become A/B.\n# It should be understood that this may change the meaning of the path\n# if it contains symbolic links!\n\ndef normpath(path):\n    \"\"\"Normalize path, eliminating double slashes, etc.\"\"\"\n    # Preserve unicode (if path is unicode)\n    slash, dot = (u'/', u'.') if isinstance(path, _unicode) else ('/', '.')\n    if path == '':\n        return dot\n    initial_slashes = path.startswith('/')\n    # POSIX allows one or two initial slashes, but treats three or more\n    # as single slash.\n    if (initial_slashes and\n        path.startswith('//') and not path.startswith('///')):\n        initial_slashes = 2\n    comps = path.split('/')\n    new_comps = []\n    for comp in comps:\n        if comp in ('', '.'):\n            continue\n        if (comp != '..' or (not initial_slashes and not new_comps) or\n             (new_comps and new_comps[-1] == '..')):\n            new_comps.append(comp)\n        elif new_comps:\n            new_comps.pop()\n    comps = new_comps\n    path = slash.join(comps)\n    if initial_slashes:\n        path = slash*initial_slashes + path\n    return path or dot\n\n\ndef abspath(path):\n    \"\"\"Return an absolute path.\"\"\"\n    if not isabs(path):\n        if isinstance(path, _unicode):\n            cwd = os.getcwdu()\n        else:\n            cwd = os.getcwd()\n        path = join(cwd, path)\n    return normpath(path)\n\n\n# Return a canonical path (i.e. the absolute location of a file on the\n# filesystem).\n\ndef realpath(filename):\n    \"\"\"Return the canonical path of the specified filename, eliminating any\nsymbolic links encountered in the path.\"\"\"\n    path, ok = _joinrealpath('', filename, {})\n    return abspath(path)\n\n# Join two paths, normalizing ang eliminating any symbolic links\n# encountered in the second path.\ndef _joinrealpath(path, rest, seen):\n    if isabs(rest):\n        rest = rest[1:]\n        path = sep\n\n    while rest:\n        name, _, rest = rest.partition(sep)\n        if not name or name == curdir:\n            # current dir\n            continue\n        if name == pardir:\n            # parent dir\n            if path:\n                path, name = split(path)\n                if name == pardir:\n                    path = join(path, pardir, pardir)\n            else:\n                path = pardir\n            continue\n        newpath = join(path, name)\n        if not islink(newpath):\n            path = newpath\n            continue\n        # Resolve the symbolic link\n        if newpath in seen:\n            # Already seen this path\n            path = seen[newpath]\n            if path is not None:\n                # use cached value\n                continue\n            # The symlink is not resolved, so we must have a symlink loop.\n            # Return already resolved part + rest of the path unchanged.\n            return join(newpath, rest), False\n        seen[newpath] = None # not resolved symlink\n        path, ok = _joinrealpath(path, os.readlink(newpath), seen)\n        if not ok:\n            return join(path, rest), False\n        seen[newpath] = path # resolved symlink\n\n    return path, True\n\n\nsupports_unicode_filenames = (sys.platform == 'darwin')\n\ndef relpath(path, start=curdir):\n    \"\"\"Return a relative version of a path\"\"\"\n\n    if not path:\n        raise ValueError(\"no path specified\")\n\n    start_list = [x for x in abspath(start).split(sep) if x]\n    path_list = [x for x in abspath(path).split(sep) if x]\n\n    # Work out how much of the filepath is shared by start and path.\n    i = len(commonprefix([start_list, path_list]))\n\n    rel_list = [pardir] * (len(start_list)-i) + path_list[i:]\n    if not rel_list:\n        return curdir\n    return join(*rel_list)\n", 
    "pwd": "# ctypes implementation: Victor Stinner, 2008-05-08\n\"\"\"\nThis module provides access to the Unix password database.\nIt is available on all Unix versions.\n\nPassword database entries are reported as 7-tuples containing the following\nitems from the password database (see `<pwd.h>'), in order:\npw_name, pw_passwd, pw_uid, pw_gid, pw_gecos, pw_dir, pw_shell.\nThe uid and gid items are integers, all others are strings. An\nexception is raised if the entry asked for cannot be found.\n\"\"\"\n\nimport sys\nif sys.platform == 'win32':\n    raise ImportError(\"No pwd module on Windows\")\n\nfrom ctypes_support import standard_c_lib as libc\nfrom ctypes import Structure, POINTER, c_int, c_char_p, c_long\nfrom _structseq import structseqtype, structseqfield\n\ntry: from __pypy__ import builtinify\nexcept ImportError: builtinify = lambda f: f\n\n\nuid_t = c_int\ngid_t = c_int\ntime_t = c_long\n\nif sys.platform == 'darwin':\n    class passwd(Structure):\n        _fields_ = (\n            (\"pw_name\", c_char_p),\n            (\"pw_passwd\", c_char_p),\n            (\"pw_uid\", uid_t),\n            (\"pw_gid\", gid_t),\n            (\"pw_change\", time_t),\n            (\"pw_class\", c_char_p),\n            (\"pw_gecos\", c_char_p),\n            (\"pw_dir\", c_char_p),\n            (\"pw_shell\", c_char_p),\n            (\"pw_expire\", time_t),\n            (\"pw_fields\", c_int),\n        )\n        def __iter__(self):\n            yield self.pw_name\n            yield self.pw_passwd\n            yield self.pw_uid\n            yield self.pw_gid\n            yield self.pw_gecos\n            yield self.pw_dir\n            yield self.pw_shell\nelse:\n    class passwd(Structure):\n        _fields_ = (\n            (\"pw_name\", c_char_p),\n            (\"pw_passwd\", c_char_p),\n            (\"pw_uid\", uid_t),\n            (\"pw_gid\", gid_t),\n            (\"pw_gecos\", c_char_p),\n            (\"pw_dir\", c_char_p),\n            (\"pw_shell\", c_char_p),\n        )\n        def __iter__(self):\n            yield self.pw_name\n            yield self.pw_passwd\n            yield self.pw_uid\n            yield self.pw_gid\n            yield self.pw_gecos\n            yield self.pw_dir\n            yield self.pw_shell\n\nclass struct_passwd:\n    \"\"\"\n    pwd.struct_passwd: Results from getpw*() routines.\n\n    This object may be accessed either as a tuple of\n      (pw_name,pw_passwd,pw_uid,pw_gid,pw_gecos,pw_dir,pw_shell)\n    or via the object attributes as named in the above tuple.\n    \"\"\"\n    __metaclass__ = structseqtype\n    name = \"pwd.struct_passwd\"\n    pw_name = structseqfield(0)\n    pw_passwd = structseqfield(1)\n    pw_uid = structseqfield(2)\n    pw_gid = structseqfield(3)\n    pw_gecos = structseqfield(4)\n    pw_dir = structseqfield(5)\n    pw_shell = structseqfield(6)\n\npasswd_p = POINTER(passwd)\n\n_getpwuid = libc.getpwuid\n_getpwuid.argtypes = (uid_t,)\n_getpwuid.restype = passwd_p\n\n_getpwnam = libc.getpwnam\n_getpwnam.argtypes = (c_char_p,)\n_getpwnam.restype = passwd_p\n\n_setpwent = libc.setpwent\n_setpwent.argtypes = None\n_setpwent.restype = None\n\n_getpwent = libc.getpwent\n_getpwent.argtypes = None\n_getpwent.restype = passwd_p\n\n_endpwent = libc.endpwent\n_endpwent.argtypes = None\n_endpwent.restype = None\n\n@builtinify\ndef mkpwent(pw):\n    pw = pw.contents\n    return struct_passwd(pw)\n\n@builtinify\ndef getpwuid(uid):\n    \"\"\"\n    getpwuid(uid) -> (pw_name,pw_passwd,pw_uid,\n                      pw_gid,pw_gecos,pw_dir,pw_shell)\n    Return the password database entry for the given numeric user ID.\n    See pwd.__doc__ for more on password database entries.\n    \"\"\"\n    pw = _getpwuid(uid)\n    if not pw:\n        raise KeyError(\"getpwuid(): uid not found: %s\" % uid)\n    return mkpwent(pw)\n\n@builtinify\ndef getpwnam(name):\n    \"\"\"\n    getpwnam(name) -> (pw_name,pw_passwd,pw_uid,\n                        pw_gid,pw_gecos,pw_dir,pw_shell)\n    Return the password database entry for the given user name.\n    See pwd.__doc__ for more on password database entries.\n    \"\"\"\n    if not isinstance(name, str):\n        raise TypeError(\"expected string\")\n    pw = _getpwnam(name)\n    if not pw:\n        raise KeyError(\"getpwname(): name not found: %s\" % name)\n    return mkpwent(pw)\n\n@builtinify\ndef getpwall():\n    \"\"\"\n    getpwall() -> list_of_entries\n    Return a list of all available password database entries, in arbitrary order.\n    See pwd.__doc__ for more on password database entries.\n    \"\"\"\n    users = []\n    _setpwent()\n    while True:\n        pw = _getpwent()\n        if not pw:\n            break\n        users.append(mkpwent(pw))\n    _endpwent()\n    return users\n\n__all__ = ('struct_passwd', 'getpwuid', 'getpwnam', 'getpwall')\n\nif __name__ == \"__main__\":\n# Uncomment next line to test CPython implementation\n#    from pwd import getpwuid, getpwnam, getpwall\n    from os import getuid\n    uid = getuid()\n    pw = getpwuid(uid)\n    print(\"uid %s: %s\" % (pw.pw_uid, pw))\n    name = pw.pw_name\n    print(\"name %r: %s\" % (name, getpwnam(name)))\n    print(\"All:\")\n    for pw in getpwall():\n        print(pw)\n\n", 
    "re": "#\n# Secret Labs' Regular Expression Engine\n#\n# re-compatible interface for the sre matching engine\n#\n# Copyright (c) 1998-2001 by Secret Labs AB.  All rights reserved.\n#\n# This version of the SRE library can be redistributed under CNRI's\n# Python 1.6 license.  For any other use, please contact Secret Labs\n# AB (info@pythonware.com).\n#\n# Portions of this engine have been developed in cooperation with\n# CNRI.  Hewlett-Packard provided funding for 1.6 integration and\n# other compatibility work.\n#\n\nr\"\"\"Support for regular expressions (RE).\n\nThis module provides regular expression matching operations similar to\nthose found in Perl.  It supports both 8-bit and Unicode strings; both\nthe pattern and the strings being processed can contain null bytes and\ncharacters outside the US ASCII range.\n\nRegular expressions can contain both special and ordinary characters.\nMost ordinary characters, like \"A\", \"a\", or \"0\", are the simplest\nregular expressions; they simply match themselves.  You can\nconcatenate ordinary characters, so last matches the string 'last'.\n\nThe special characters are:\n    \".\"      Matches any character except a newline.\n    \"^\"      Matches the start of the string.\n    \"$\"      Matches the end of the string or just before the newline at\n             the end of the string.\n    \"*\"      Matches 0 or more (greedy) repetitions of the preceding RE.\n             Greedy means that it will match as many repetitions as possible.\n    \"+\"      Matches 1 or more (greedy) repetitions of the preceding RE.\n    \"?\"      Matches 0 or 1 (greedy) of the preceding RE.\n    *?,+?,?? Non-greedy versions of the previous three special characters.\n    {m,n}    Matches from m to n repetitions of the preceding RE.\n    {m,n}?   Non-greedy version of the above.\n    \"\\\\\"     Either escapes special characters or signals a special sequence.\n    []       Indicates a set of characters.\n             A \"^\" as the first character indicates a complementing set.\n    \"|\"      A|B, creates an RE that will match either A or B.\n    (...)    Matches the RE inside the parentheses.\n             The contents can be retrieved or matched later in the string.\n    (?iLmsux) Set the I, L, M, S, U, or X flag for the RE (see below).\n    (?:...)  Non-grouping version of regular parentheses.\n    (?P<name>...) The substring matched by the group is accessible by name.\n    (?P=name)     Matches the text matched earlier by the group named name.\n    (?#...)  A comment; ignored.\n    (?=...)  Matches if ... matches next, but doesn't consume the string.\n    (?!...)  Matches if ... doesn't match next.\n    (?<=...) Matches if preceded by ... (must be fixed length).\n    (?<!...) Matches if not preceded by ... (must be fixed length).\n    (?(id/name)yes|no) Matches yes pattern if the group with id/name matched,\n                       the (optional) no pattern otherwise.\n\nThe special sequences consist of \"\\\\\" and a character from the list\nbelow.  If the ordinary character is not on the list, then the\nresulting RE will match the second character.\n    \\number  Matches the contents of the group of the same number.\n    \\A       Matches only at the start of the string.\n    \\Z       Matches only at the end of the string.\n    \\b       Matches the empty string, but only at the start or end of a word.\n    \\B       Matches the empty string, but not at the start or end of a word.\n    \\d       Matches any decimal digit; equivalent to the set [0-9].\n    \\D       Matches any non-digit character; equivalent to the set [^0-9].\n    \\s       Matches any whitespace character; equivalent to [ \\t\\n\\r\\f\\v].\n    \\S       Matches any non-whitespace character; equiv. to [^ \\t\\n\\r\\f\\v].\n    \\w       Matches any alphanumeric character; equivalent to [a-zA-Z0-9_].\n             With LOCALE, it will match the set [0-9_] plus characters defined\n             as letters for the current locale.\n    \\W       Matches the complement of \\w.\n    \\\\       Matches a literal backslash.\n\nThis module exports the following functions:\n    match    Match a regular expression pattern to the beginning of a string.\n    search   Search a string for the presence of a pattern.\n    sub      Substitute occurrences of a pattern found in a string.\n    subn     Same as sub, but also return the number of substitutions made.\n    split    Split a string by the occurrences of a pattern.\n    findall  Find all occurrences of a pattern in a string.\n    finditer Return an iterator yielding a match object for each match.\n    compile  Compile a pattern into a RegexObject.\n    purge    Clear the regular expression cache.\n    escape   Backslash all non-alphanumerics in a string.\n\nSome of the functions in this module takes flags as optional parameters:\n    I  IGNORECASE  Perform case-insensitive matching.\n    L  LOCALE      Make \\w, \\W, \\b, \\B, dependent on the current locale.\n    M  MULTILINE   \"^\" matches the beginning of lines (after a newline)\n                   as well as the string.\n                   \"$\" matches the end of lines (before a newline) as well\n                   as the end of the string.\n    S  DOTALL      \".\" matches any character at all, including the newline.\n    X  VERBOSE     Ignore whitespace and comments for nicer looking RE's.\n    U  UNICODE     Make \\w, \\W, \\b, \\B, dependent on the Unicode locale.\n\nThis module also defines an exception 'error'.\n\n\"\"\"\n\nimport sys\nimport sre_compile\nimport sre_parse\n\n# public symbols\n__all__ = [ \"match\", \"search\", \"sub\", \"subn\", \"split\", \"findall\",\n    \"compile\", \"purge\", \"template\", \"escape\", \"I\", \"L\", \"M\", \"S\", \"X\",\n    \"U\", \"IGNORECASE\", \"LOCALE\", \"MULTILINE\", \"DOTALL\", \"VERBOSE\",\n    \"UNICODE\", \"error\" ]\n\n__version__ = \"2.2.1\"\n\n# flags\nI = IGNORECASE = sre_compile.SRE_FLAG_IGNORECASE # ignore case\nL = LOCALE = sre_compile.SRE_FLAG_LOCALE # assume current 8-bit locale\nU = UNICODE = sre_compile.SRE_FLAG_UNICODE # assume unicode locale\nM = MULTILINE = sre_compile.SRE_FLAG_MULTILINE # make anchors look for newline\nS = DOTALL = sre_compile.SRE_FLAG_DOTALL # make dot match newline\nX = VERBOSE = sre_compile.SRE_FLAG_VERBOSE # ignore whitespace and comments\n\n# sre extensions (experimental, don't rely on these)\nT = TEMPLATE = sre_compile.SRE_FLAG_TEMPLATE # disable backtracking\nDEBUG = sre_compile.SRE_FLAG_DEBUG # dump pattern after compilation\n\n# sre exception\nerror = sre_compile.error\n\n# --------------------------------------------------------------------\n# public interface\n\ndef match(pattern, string, flags=0):\n    \"\"\"Try to apply the pattern at the start of the string, returning\n    a match object, or None if no match was found.\"\"\"\n    return _compile(pattern, flags).match(string)\n\ndef search(pattern, string, flags=0):\n    \"\"\"Scan through string looking for a match to the pattern, returning\n    a match object, or None if no match was found.\"\"\"\n    return _compile(pattern, flags).search(string)\n\ndef sub(pattern, repl, string, count=0, flags=0):\n    \"\"\"Return the string obtained by replacing the leftmost\n    non-overlapping occurrences of the pattern in string by the\n    replacement repl.  repl can be either a string or a callable;\n    if a string, backslash escapes in it are processed.  If it is\n    a callable, it's passed the match object and must return\n    a replacement string to be used.\"\"\"\n    return _compile(pattern, flags).sub(repl, string, count)\n\ndef subn(pattern, repl, string, count=0, flags=0):\n    \"\"\"Return a 2-tuple containing (new_string, number).\n    new_string is the string obtained by replacing the leftmost\n    non-overlapping occurrences of the pattern in the source\n    string by the replacement repl.  number is the number of\n    substitutions that were made. repl can be either a string or a\n    callable; if a string, backslash escapes in it are processed.\n    If it is a callable, it's passed the match object and must\n    return a replacement string to be used.\"\"\"\n    return _compile(pattern, flags).subn(repl, string, count)\n\ndef split(pattern, string, maxsplit=0, flags=0):\n    \"\"\"Split the source string by the occurrences of the pattern,\n    returning a list containing the resulting substrings.\"\"\"\n    return _compile(pattern, flags).split(string, maxsplit)\n\ndef findall(pattern, string, flags=0):\n    \"\"\"Return a list of all non-overlapping matches in the string.\n\n    If one or more groups are present in the pattern, return a\n    list of groups; this will be a list of tuples if the pattern\n    has more than one group.\n\n    Empty matches are included in the result.\"\"\"\n    return _compile(pattern, flags).findall(string)\n\nif sys.hexversion >= 0x02020000:\n    __all__.append(\"finditer\")\n    def finditer(pattern, string, flags=0):\n        \"\"\"Return an iterator over all non-overlapping matches in the\n        string.  For each match, the iterator returns a match object.\n\n        Empty matches are included in the result.\"\"\"\n        return _compile(pattern, flags).finditer(string)\n\ndef compile(pattern, flags=0):\n    \"Compile a regular expression pattern, returning a pattern object.\"\n    return _compile(pattern, flags)\n\ndef purge():\n    \"Clear the regular expression cache\"\n    _cache.clear()\n    _cache_repl.clear()\n\ndef template(pattern, flags=0):\n    \"Compile a template pattern, returning a pattern object\"\n    return _compile(pattern, flags|T)\n\n_alphanum = frozenset(\n    \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\")\n\ndef escape(pattern):\n    \"Escape all non-alphanumeric characters in pattern.\"\n    s = list(pattern)\n    alphanum = _alphanum\n    for i, c in enumerate(pattern):\n        if c not in alphanum:\n            if c == \"\\000\":\n                s[i] = \"\\\\000\"\n            else:\n                s[i] = \"\\\\\" + c\n    return pattern[:0].join(s)\n\n# --------------------------------------------------------------------\n# internals\n\n_cache = {}\n_cache_repl = {}\n\n_pattern_type = type(sre_compile.compile(\"\", 0))\n\n_MAXCACHE = 100\n\ndef _compile(*key):\n    # internal: compile pattern\n    pattern, flags = key\n    bypass_cache = flags & DEBUG\n    if not bypass_cache:\n        cachekey = (type(key[0]),) + key\n        p = _cache.get(cachekey)\n        if p is not None:\n            return p\n    if isinstance(pattern, _pattern_type):\n        if flags:\n            raise ValueError('Cannot process flags argument with a compiled pattern')\n        return pattern\n    if not sre_compile.isstring(pattern):\n        raise TypeError, \"first argument must be string or compiled pattern\"\n    try:\n        p = sre_compile.compile(pattern, flags)\n    except error, v:\n        raise error, v # invalid expression\n    if not bypass_cache:\n        if len(_cache) >= _MAXCACHE:\n            _cache.clear()\n        _cache[cachekey] = p\n    return p\n\ndef _compile_repl(*key):\n    # internal: compile replacement pattern\n    p = _cache_repl.get(key)\n    if p is not None:\n        return p\n    repl, pattern = key\n    try:\n        p = sre_parse.parse_template(repl, pattern)\n    except error, v:\n        raise error, v # invalid expression\n    if len(_cache_repl) >= _MAXCACHE:\n        _cache_repl.clear()\n    _cache_repl[key] = p\n    return p\n\ndef _expand(pattern, match, template):\n    # internal: match.expand implementation hook\n    template = sre_parse.parse_template(template, pattern)\n    return sre_parse.expand_template(template, match)\n\ndef _subx(pattern, template):\n    # internal: pattern.sub/subn implementation helper\n    template = _compile_repl(template, pattern)\n    if not template[0] and len(template[1]) == 1:\n        # literal replacement\n        return template[1][0]\n    def filter(match, template=template):\n        return sre_parse.expand_template(template, match)\n    return filter\n\n# register myself for pickling\n\nimport copy_reg\n\ndef _pickle(p):\n    return _compile, (p.pattern, p.flags)\n\ncopy_reg.pickle(_pattern_type, _pickle, _compile)\n\n# --------------------------------------------------------------------\n# experimental stuff (see python-dev discussions for details)\n\nclass Scanner:\n    def __init__(self, lexicon, flags=0):\n        from sre_constants import BRANCH, SUBPATTERN\n        self.lexicon = lexicon\n        # combine phrases into a compound pattern\n        p = []\n        s = sre_parse.Pattern()\n        s.flags = flags\n        for phrase, action in lexicon:\n            p.append(sre_parse.SubPattern(s, [\n                (SUBPATTERN, (len(p)+1, sre_parse.parse(phrase, flags))),\n                ]))\n        s.groups = len(p)+1\n        p = sre_parse.SubPattern(s, [(BRANCH, (None, p))])\n        self.scanner = sre_compile.compile(p)\n    def scan(self, string):\n        result = []\n        append = result.append\n        match = self.scanner.scanner(string).match\n        i = 0\n        while 1:\n            m = match()\n            if not m:\n                break\n            j = m.end()\n            if i == j:\n                break\n            action = self.lexicon[m.lastindex-1][1]\n            if hasattr(action, '__call__'):\n                self.match = m\n                action = action(self, m.group())\n            if action is not None:\n                append(action)\n            i = j\n        return result, string[i:]\n", 
    "repr": "\"\"\"Redo the builtin repr() (representation) but with limits on most sizes.\"\"\"\n\n__all__ = [\"Repr\",\"repr\"]\n\nimport __builtin__\nfrom itertools import islice\n\nclass Repr:\n\n    def __init__(self):\n        self.maxlevel = 6\n        self.maxtuple = 6\n        self.maxlist = 6\n        self.maxarray = 5\n        self.maxdict = 4\n        self.maxset = 6\n        self.maxfrozenset = 6\n        self.maxdeque = 6\n        self.maxstring = 30\n        self.maxlong = 40\n        self.maxother = 20\n\n    def repr(self, x):\n        return self.repr1(x, self.maxlevel)\n\n    def repr1(self, x, level):\n        typename = type(x).__name__\n        if ' ' in typename:\n            parts = typename.split()\n            typename = '_'.join(parts)\n        if hasattr(self, 'repr_' + typename):\n            return getattr(self, 'repr_' + typename)(x, level)\n        else:\n            s = __builtin__.repr(x)\n            if len(s) > self.maxother:\n                i = max(0, (self.maxother-3)//2)\n                j = max(0, self.maxother-3-i)\n                s = s[:i] + '...' + s[len(s)-j:]\n            return s\n\n    def _repr_iterable(self, x, level, left, right, maxiter, trail=''):\n        n = len(x)\n        if level <= 0 and n:\n            s = '...'\n        else:\n            newlevel = level - 1\n            repr1 = self.repr1\n            pieces = [repr1(elem, newlevel) for elem in islice(x, maxiter)]\n            if n > maxiter:  pieces.append('...')\n            s = ', '.join(pieces)\n            if n == 1 and trail:  right = trail + right\n        return '%s%s%s' % (left, s, right)\n\n    def repr_tuple(self, x, level):\n        return self._repr_iterable(x, level, '(', ')', self.maxtuple, ',')\n\n    def repr_list(self, x, level):\n        return self._repr_iterable(x, level, '[', ']', self.maxlist)\n\n    def repr_array(self, x, level):\n        header = \"array('%s', [\" % x.typecode\n        return self._repr_iterable(x, level, header, '])', self.maxarray)\n\n    def repr_set(self, x, level):\n        x = _possibly_sorted(x)\n        return self._repr_iterable(x, level, 'set([', '])', self.maxset)\n\n    def repr_frozenset(self, x, level):\n        x = _possibly_sorted(x)\n        return self._repr_iterable(x, level, 'frozenset([', '])',\n                                   self.maxfrozenset)\n\n    def repr_deque(self, x, level):\n        return self._repr_iterable(x, level, 'deque([', '])', self.maxdeque)\n\n    def repr_dict(self, x, level):\n        n = len(x)\n        if n == 0: return '{}'\n        if level <= 0: return '{...}'\n        newlevel = level - 1\n        repr1 = self.repr1\n        pieces = []\n        for key in islice(_possibly_sorted(x), self.maxdict):\n            keyrepr = repr1(key, newlevel)\n            valrepr = repr1(x[key], newlevel)\n            pieces.append('%s: %s' % (keyrepr, valrepr))\n        if n > self.maxdict: pieces.append('...')\n        s = ', '.join(pieces)\n        return '{%s}' % (s,)\n\n    def repr_str(self, x, level):\n        s = __builtin__.repr(x[:self.maxstring])\n        if len(s) > self.maxstring:\n            i = max(0, (self.maxstring-3)//2)\n            j = max(0, self.maxstring-3-i)\n            s = __builtin__.repr(x[:i] + x[len(x)-j:])\n            s = s[:i] + '...' + s[len(s)-j:]\n        return s\n\n    def repr_long(self, x, level):\n        s = __builtin__.repr(x) # XXX Hope this isn't too slow...\n        if len(s) > self.maxlong:\n            i = max(0, (self.maxlong-3)//2)\n            j = max(0, self.maxlong-3-i)\n            s = s[:i] + '...' + s[len(s)-j:]\n        return s\n\n    def repr_instance(self, x, level):\n        try:\n            s = __builtin__.repr(x)\n            # Bugs in x.__repr__() can cause arbitrary\n            # exceptions -- then make up something\n        except Exception:\n            return '<%s instance at %x>' % (x.__class__.__name__, id(x))\n        if len(s) > self.maxstring:\n            i = max(0, (self.maxstring-3)//2)\n            j = max(0, self.maxstring-3-i)\n            s = s[:i] + '...' + s[len(s)-j:]\n        return s\n\n\ndef _possibly_sorted(x):\n    # Since not all sequences of items can be sorted and comparison\n    # functions may raise arbitrary exceptions, return an unsorted\n    # sequence in that case.\n    try:\n        return sorted(x)\n    except Exception:\n        return list(x)\n\naRepr = Repr()\nrepr = aRepr.repr\n", 
    "sre_compile": "#\n# Secret Labs' Regular Expression Engine\n#\n# convert template to internal format\n#\n# Copyright (c) 1997-2001 by Secret Labs AB.  All rights reserved.\n#\n# See the sre.py file for information on usage and redistribution.\n#\n\n\"\"\"Internal support module for sre\"\"\"\n\nimport _sre, sys\nimport sre_parse\nfrom sre_constants import *\n\nassert _sre.MAGIC == MAGIC, \"SRE module mismatch\"\n\nif _sre.CODESIZE == 2:\n    MAXCODE = 65535\nelse:\n    MAXCODE = 0xFFFFFFFFL\n\ndef _identityfunction(x):\n    return x\n\n_LITERAL_CODES = set([LITERAL, NOT_LITERAL])\n_REPEATING_CODES = set([REPEAT, MIN_REPEAT, MAX_REPEAT])\n_SUCCESS_CODES = set([SUCCESS, FAILURE])\n_ASSERT_CODES = set([ASSERT, ASSERT_NOT])\n\ndef _compile(code, pattern, flags):\n    # internal: compile a (sub)pattern\n    emit = code.append\n    _len = len\n    LITERAL_CODES = _LITERAL_CODES\n    REPEATING_CODES = _REPEATING_CODES\n    SUCCESS_CODES = _SUCCESS_CODES\n    ASSERT_CODES = _ASSERT_CODES\n    for op, av in pattern:\n        if op in LITERAL_CODES:\n            if flags & SRE_FLAG_IGNORECASE:\n                emit(OPCODES[OP_IGNORE[op]])\n                emit(_sre.getlower(av, flags))\n            else:\n                emit(OPCODES[op])\n                emit(av)\n        elif op is IN:\n            if flags & SRE_FLAG_IGNORECASE:\n                emit(OPCODES[OP_IGNORE[op]])\n                def fixup(literal, flags=flags):\n                    return _sre.getlower(literal, flags)\n            else:\n                emit(OPCODES[op])\n                fixup = _identityfunction\n            skip = _len(code); emit(0)\n            _compile_charset(av, flags, code, fixup)\n            code[skip] = _len(code) - skip\n        elif op is ANY:\n            if flags & SRE_FLAG_DOTALL:\n                emit(OPCODES[ANY_ALL])\n            else:\n                emit(OPCODES[ANY])\n        elif op in REPEATING_CODES:\n            if flags & SRE_FLAG_TEMPLATE:\n                raise error, \"internal: unsupported template operator\"\n                emit(OPCODES[REPEAT])\n                skip = _len(code); emit(0)\n                emit(av[0])\n                emit(av[1])\n                _compile(code, av[2], flags)\n                emit(OPCODES[SUCCESS])\n                code[skip] = _len(code) - skip\n            elif _simple(av) and op is not REPEAT:\n                if op is MAX_REPEAT:\n                    emit(OPCODES[REPEAT_ONE])\n                else:\n                    emit(OPCODES[MIN_REPEAT_ONE])\n                skip = _len(code); emit(0)\n                emit(av[0])\n                emit(av[1])\n                _compile(code, av[2], flags)\n                emit(OPCODES[SUCCESS])\n                code[skip] = _len(code) - skip\n            else:\n                emit(OPCODES[REPEAT])\n                skip = _len(code); emit(0)\n                emit(av[0])\n                emit(av[1])\n                _compile(code, av[2], flags)\n                code[skip] = _len(code) - skip\n                if op is MAX_REPEAT:\n                    emit(OPCODES[MAX_UNTIL])\n                else:\n                    emit(OPCODES[MIN_UNTIL])\n        elif op is SUBPATTERN:\n            if av[0]:\n                emit(OPCODES[MARK])\n                emit((av[0]-1)*2)\n            # _compile_info(code, av[1], flags)\n            _compile(code, av[1], flags)\n            if av[0]:\n                emit(OPCODES[MARK])\n                emit((av[0]-1)*2+1)\n        elif op in SUCCESS_CODES:\n            emit(OPCODES[op])\n        elif op in ASSERT_CODES:\n            emit(OPCODES[op])\n            skip = _len(code); emit(0)\n            if av[0] >= 0:\n                emit(0) # look ahead\n            else:\n                lo, hi = av[1].getwidth()\n                if lo != hi:\n                    raise error, \"look-behind requires fixed-width pattern\"\n                emit(lo) # look behind\n            _compile(code, av[1], flags)\n            emit(OPCODES[SUCCESS])\n            code[skip] = _len(code) - skip\n        elif op is CALL:\n            emit(OPCODES[op])\n            skip = _len(code); emit(0)\n            _compile(code, av, flags)\n            emit(OPCODES[SUCCESS])\n            code[skip] = _len(code) - skip\n        elif op is AT:\n            emit(OPCODES[op])\n            if flags & SRE_FLAG_MULTILINE:\n                av = AT_MULTILINE.get(av, av)\n            if flags & SRE_FLAG_LOCALE:\n                av = AT_LOCALE.get(av, av)\n            elif flags & SRE_FLAG_UNICODE:\n                av = AT_UNICODE.get(av, av)\n            emit(ATCODES[av])\n        elif op is BRANCH:\n            emit(OPCODES[op])\n            tail = []\n            tailappend = tail.append\n            for av in av[1]:\n                skip = _len(code); emit(0)\n                # _compile_info(code, av, flags)\n                _compile(code, av, flags)\n                emit(OPCODES[JUMP])\n                tailappend(_len(code)); emit(0)\n                code[skip] = _len(code) - skip\n            emit(0) # end of branch\n            for tail in tail:\n                code[tail] = _len(code) - tail\n        elif op is CATEGORY:\n            emit(OPCODES[op])\n            if flags & SRE_FLAG_LOCALE:\n                av = CH_LOCALE[av]\n            elif flags & SRE_FLAG_UNICODE:\n                av = CH_UNICODE[av]\n            emit(CHCODES[av])\n        elif op is GROUPREF:\n            if flags & SRE_FLAG_IGNORECASE:\n                emit(OPCODES[OP_IGNORE[op]])\n            else:\n                emit(OPCODES[op])\n            emit(av-1)\n        elif op is GROUPREF_EXISTS:\n            emit(OPCODES[op])\n            emit(av[0]-1)\n            skipyes = _len(code); emit(0)\n            _compile(code, av[1], flags)\n            if av[2]:\n                emit(OPCODES[JUMP])\n                skipno = _len(code); emit(0)\n                code[skipyes] = _len(code) - skipyes + 1\n                _compile(code, av[2], flags)\n                code[skipno] = _len(code) - skipno\n            else:\n                code[skipyes] = _len(code) - skipyes + 1\n        else:\n            raise ValueError, (\"unsupported operand type\", op)\n\ndef _compile_charset(charset, flags, code, fixup=None):\n    # compile charset subprogram\n    emit = code.append\n    if fixup is None:\n        fixup = _identityfunction\n    for op, av in _optimize_charset(charset, fixup):\n        emit(OPCODES[op])\n        if op is NEGATE:\n            pass\n        elif op is LITERAL:\n            emit(fixup(av))\n        elif op is RANGE:\n            emit(fixup(av[0]))\n            emit(fixup(av[1]))\n        elif op is CHARSET:\n            code.extend(av)\n        elif op is BIGCHARSET:\n            code.extend(av)\n        elif op is CATEGORY:\n            if flags & SRE_FLAG_LOCALE:\n                emit(CHCODES[CH_LOCALE[av]])\n            elif flags & SRE_FLAG_UNICODE:\n                emit(CHCODES[CH_UNICODE[av]])\n            else:\n                emit(CHCODES[av])\n        else:\n            raise error, \"internal: unsupported set operator\"\n    emit(OPCODES[FAILURE])\n\ndef _optimize_charset(charset, fixup):\n    # internal: optimize character set\n    out = []\n    outappend = out.append\n    charmap = [0]*256\n    try:\n        for op, av in charset:\n            if op is NEGATE:\n                outappend((op, av))\n            elif op is LITERAL:\n                charmap[fixup(av)] = 1\n            elif op is RANGE:\n                for i in range(fixup(av[0]), fixup(av[1])+1):\n                    charmap[i] = 1\n            elif op is CATEGORY:\n                # XXX: could append to charmap tail\n                return charset # cannot compress\n    except IndexError:\n        # character set contains unicode characters\n        return _optimize_unicode(charset, fixup)\n    # compress character map\n    i = p = n = 0\n    runs = []\n    runsappend = runs.append\n    for c in charmap:\n        if c:\n            if n == 0:\n                p = i\n            n = n + 1\n        elif n:\n            runsappend((p, n))\n            n = 0\n        i = i + 1\n    if n:\n        runsappend((p, n))\n    if len(runs) <= 2:\n        # use literal/range\n        for p, n in runs:\n            if n == 1:\n                outappend((LITERAL, p))\n            else:\n                outappend((RANGE, (p, p+n-1)))\n        if len(out) < len(charset):\n            return out\n    else:\n        # use bitmap\n        data = _mk_bitmap(charmap)\n        outappend((CHARSET, data))\n        return out\n    return charset\n\ndef _mk_bitmap(bits):\n    data = []\n    dataappend = data.append\n    if _sre.CODESIZE == 2:\n        start = (1, 0)\n    else:\n        start = (1L, 0L)\n    m, v = start\n    for c in bits:\n        if c:\n            v = v + m\n        m = m + m\n        if m > MAXCODE:\n            dataappend(v)\n            m, v = start\n    return data\n\n# To represent a big charset, first a bitmap of all characters in the\n# set is constructed. Then, this bitmap is sliced into chunks of 256\n# characters, duplicate chunks are eliminated, and each chunk is\n# given a number. In the compiled expression, the charset is\n# represented by a 32-bit word sequence, consisting of one word for\n# the number of different chunks, a sequence of 256 bytes (64 words)\n# of chunk numbers indexed by their original chunk position, and a\n# sequence of 256-bit chunks (8 words each).\n\n# Compression is normally good: in a typical charset, large ranges of\n# Unicode will be either completely excluded (e.g. if only cyrillic\n# letters are to be matched), or completely included (e.g. if large\n# subranges of Kanji match). These ranges will be represented by\n# chunks of all one-bits or all zero-bits.\n\n# Matching can be also done efficiently: the more significant byte of\n# the Unicode character is an index into the chunk number, and the\n# less significant byte is a bit index in the chunk (just like the\n# CHARSET matching).\n\n# In UCS-4 mode, the BIGCHARSET opcode still supports only subsets\n# of the basic multilingual plane; an efficient representation\n# for all of Unicode has not yet been developed. This means,\n# in particular, that negated charsets cannot be represented as\n# bigcharsets.\n\ndef _optimize_unicode(charset, fixup):\n    try:\n        import array\n    except ImportError:\n        return charset\n    charmap = [0]*65536\n    negate = 0\n    try:\n        for op, av in charset:\n            if op is NEGATE:\n                negate = 1\n            elif op is LITERAL:\n                charmap[fixup(av)] = 1\n            elif op is RANGE:\n                for i in xrange(fixup(av[0]), fixup(av[1])+1):\n                    charmap[i] = 1\n            elif op is CATEGORY:\n                # XXX: could expand category\n                return charset # cannot compress\n    except IndexError:\n        # non-BMP characters\n        return charset\n    if negate:\n        if sys.maxunicode != 65535:\n            # XXX: negation does not work with big charsets\n            return charset\n        for i in xrange(65536):\n            charmap[i] = not charmap[i]\n    comps = {}\n    mapping = [0]*256\n    block = 0\n    data = []\n    for i in xrange(256):\n        chunk = tuple(charmap[i*256:(i+1)*256])\n        new = comps.setdefault(chunk, block)\n        mapping[i] = new\n        if new == block:\n            block = block + 1\n            data = data + _mk_bitmap(chunk)\n    header = [block]\n    if _sre.CODESIZE == 2:\n        code = 'H'\n    else:\n        code = 'I'\n    # Convert block indices to byte array of 256 bytes\n    mapping = array.array('B', mapping).tostring()\n    # Convert byte array to word array\n    mapping = array.array(code, mapping)\n    assert mapping.itemsize == _sre.CODESIZE\n    header = header + mapping.tolist()\n    data[0:0] = header\n    return [(BIGCHARSET, data)]\n\ndef _simple(av):\n    # check if av is a \"simple\" operator\n    lo, hi = av[2].getwidth()\n    return lo == hi == 1 and av[2][0][0] != SUBPATTERN\n\ndef _compile_info(code, pattern, flags):\n    # internal: compile an info block.  in the current version,\n    # this contains min/max pattern width, and an optional literal\n    # prefix or a character map\n    lo, hi = pattern.getwidth()\n    if lo == 0:\n        return # not worth it\n    # look for a literal prefix\n    prefix = []\n    prefixappend = prefix.append\n    prefix_skip = 0\n    charset = [] # not used\n    charsetappend = charset.append\n    if not (flags & SRE_FLAG_IGNORECASE):\n        # look for literal prefix\n        for op, av in pattern.data:\n            if op is LITERAL:\n                if len(prefix) == prefix_skip:\n                    prefix_skip = prefix_skip + 1\n                prefixappend(av)\n            elif op is SUBPATTERN and len(av[1]) == 1:\n                op, av = av[1][0]\n                if op is LITERAL:\n                    prefixappend(av)\n                else:\n                    break\n            else:\n                break\n        # if no prefix, look for charset prefix\n        if not prefix and pattern.data:\n            op, av = pattern.data[0]\n            if op is SUBPATTERN and av[1]:\n                op, av = av[1][0]\n                if op is LITERAL:\n                    charsetappend((op, av))\n                elif op is BRANCH:\n                    c = []\n                    cappend = c.append\n                    for p in av[1]:\n                        if not p:\n                            break\n                        op, av = p[0]\n                        if op is LITERAL:\n                            cappend((op, av))\n                        else:\n                            break\n                    else:\n                        charset = c\n            elif op is BRANCH:\n                c = []\n                cappend = c.append\n                for p in av[1]:\n                    if not p:\n                        break\n                    op, av = p[0]\n                    if op is LITERAL:\n                        cappend((op, av))\n                    else:\n                        break\n                else:\n                    charset = c\n            elif op is IN:\n                charset = av\n##     if prefix:\n##         print \"*** PREFIX\", prefix, prefix_skip\n##     if charset:\n##         print \"*** CHARSET\", charset\n    # add an info block\n    emit = code.append\n    emit(OPCODES[INFO])\n    skip = len(code); emit(0)\n    # literal flag\n    mask = 0\n    if prefix:\n        mask = SRE_INFO_PREFIX\n        if len(prefix) == prefix_skip == len(pattern.data):\n            mask = mask + SRE_INFO_LITERAL\n    elif charset:\n        mask = mask + SRE_INFO_CHARSET\n    emit(mask)\n    # pattern length\n    if lo < MAXCODE:\n        emit(lo)\n    else:\n        emit(MAXCODE)\n        prefix = prefix[:MAXCODE]\n    if hi < MAXCODE:\n        emit(hi)\n    else:\n        emit(0)\n    # add literal prefix\n    if prefix:\n        emit(len(prefix)) # length\n        emit(prefix_skip) # skip\n        code.extend(prefix)\n        # generate overlap table\n        table = [-1] + ([0]*len(prefix))\n        for i in xrange(len(prefix)):\n            table[i+1] = table[i]+1\n            while table[i+1] > 0 and prefix[i] != prefix[table[i+1]-1]:\n                table[i+1] = table[table[i+1]-1]+1\n        code.extend(table[1:]) # don't store first entry\n    elif charset:\n        _compile_charset(charset, flags, code)\n    code[skip] = len(code) - skip\n\ntry:\n    unicode\nexcept NameError:\n    STRING_TYPES = (type(\"\"),)\nelse:\n    STRING_TYPES = (type(\"\"), type(unicode(\"\")))\n\ndef isstring(obj):\n    for tp in STRING_TYPES:\n        if isinstance(obj, tp):\n            return 1\n    return 0\n\ndef _code(p, flags):\n\n    flags = p.pattern.flags | flags\n    code = []\n\n    # compile info block\n    _compile_info(code, p, flags)\n\n    # compile the pattern\n    _compile(code, p.data, flags)\n\n    code.append(OPCODES[SUCCESS])\n\n    return code\n\ndef compile(p, flags=0):\n    # internal: convert pattern list to internal format\n\n    if isstring(p):\n        pattern = p\n        p = sre_parse.parse(p, flags)\n    else:\n        pattern = None\n\n    code = _code(p, flags)\n\n    # print code\n\n    # XXX: <fl> get rid of this limitation!\n    if p.pattern.groups > 100:\n        raise AssertionError(\n            \"sorry, but this version only supports 100 named groups\"\n            )\n\n    # map in either direction\n    groupindex = p.pattern.groupdict\n    indexgroup = [None] * p.pattern.groups\n    for k, i in groupindex.items():\n        indexgroup[i] = k\n\n    return _sre.compile(\n        pattern, flags | p.pattern.flags, code,\n        p.pattern.groups-1,\n        groupindex, indexgroup\n        )\n", 
    "sre_constants": "#\n# Secret Labs' Regular Expression Engine\n#\n# various symbols used by the regular expression engine.\n# run this script to update the _sre include files!\n#\n# Copyright (c) 1998-2001 by Secret Labs AB.  All rights reserved.\n#\n# See the sre.py file for information on usage and redistribution.\n#\n\n\"\"\"Internal support module for sre\"\"\"\n\n# update when constants are added or removed\n\nMAGIC = 20031017\n\ntry:\n    from _sre import MAXREPEAT\nexcept ImportError:\n    import _sre\n    MAXREPEAT = _sre.MAXREPEAT = 65535\n\n# SRE standard exception (access as sre.error)\n# should this really be here?\n\nclass error(Exception):\n    pass\n\n# operators\n\nFAILURE = \"failure\"\nSUCCESS = \"success\"\n\nANY = \"any\"\nANY_ALL = \"any_all\"\nASSERT = \"assert\"\nASSERT_NOT = \"assert_not\"\nAT = \"at\"\nBIGCHARSET = \"bigcharset\"\nBRANCH = \"branch\"\nCALL = \"call\"\nCATEGORY = \"category\"\nCHARSET = \"charset\"\nGROUPREF = \"groupref\"\nGROUPREF_IGNORE = \"groupref_ignore\"\nGROUPREF_EXISTS = \"groupref_exists\"\nIN = \"in\"\nIN_IGNORE = \"in_ignore\"\nINFO = \"info\"\nJUMP = \"jump\"\nLITERAL = \"literal\"\nLITERAL_IGNORE = \"literal_ignore\"\nMARK = \"mark\"\nMAX_REPEAT = \"max_repeat\"\nMAX_UNTIL = \"max_until\"\nMIN_REPEAT = \"min_repeat\"\nMIN_UNTIL = \"min_until\"\nNEGATE = \"negate\"\nNOT_LITERAL = \"not_literal\"\nNOT_LITERAL_IGNORE = \"not_literal_ignore\"\nRANGE = \"range\"\nREPEAT = \"repeat\"\nREPEAT_ONE = \"repeat_one\"\nSUBPATTERN = \"subpattern\"\nMIN_REPEAT_ONE = \"min_repeat_one\"\n\n# positions\nAT_BEGINNING = \"at_beginning\"\nAT_BEGINNING_LINE = \"at_beginning_line\"\nAT_BEGINNING_STRING = \"at_beginning_string\"\nAT_BOUNDARY = \"at_boundary\"\nAT_NON_BOUNDARY = \"at_non_boundary\"\nAT_END = \"at_end\"\nAT_END_LINE = \"at_end_line\"\nAT_END_STRING = \"at_end_string\"\nAT_LOC_BOUNDARY = \"at_loc_boundary\"\nAT_LOC_NON_BOUNDARY = \"at_loc_non_boundary\"\nAT_UNI_BOUNDARY = \"at_uni_boundary\"\nAT_UNI_NON_BOUNDARY = \"at_uni_non_boundary\"\n\n# categories\nCATEGORY_DIGIT = \"category_digit\"\nCATEGORY_NOT_DIGIT = \"category_not_digit\"\nCATEGORY_SPACE = \"category_space\"\nCATEGORY_NOT_SPACE = \"category_not_space\"\nCATEGORY_WORD = \"category_word\"\nCATEGORY_NOT_WORD = \"category_not_word\"\nCATEGORY_LINEBREAK = \"category_linebreak\"\nCATEGORY_NOT_LINEBREAK = \"category_not_linebreak\"\nCATEGORY_LOC_WORD = \"category_loc_word\"\nCATEGORY_LOC_NOT_WORD = \"category_loc_not_word\"\nCATEGORY_UNI_DIGIT = \"category_uni_digit\"\nCATEGORY_UNI_NOT_DIGIT = \"category_uni_not_digit\"\nCATEGORY_UNI_SPACE = \"category_uni_space\"\nCATEGORY_UNI_NOT_SPACE = \"category_uni_not_space\"\nCATEGORY_UNI_WORD = \"category_uni_word\"\nCATEGORY_UNI_NOT_WORD = \"category_uni_not_word\"\nCATEGORY_UNI_LINEBREAK = \"category_uni_linebreak\"\nCATEGORY_UNI_NOT_LINEBREAK = \"category_uni_not_linebreak\"\n\nOPCODES = [\n\n    # failure=0 success=1 (just because it looks better that way :-)\n    FAILURE, SUCCESS,\n\n    ANY, ANY_ALL,\n    ASSERT, ASSERT_NOT,\n    AT,\n    BRANCH,\n    CALL,\n    CATEGORY,\n    CHARSET, BIGCHARSET,\n    GROUPREF, GROUPREF_EXISTS, GROUPREF_IGNORE,\n    IN, IN_IGNORE,\n    INFO,\n    JUMP,\n    LITERAL, LITERAL_IGNORE,\n    MARK,\n    MAX_UNTIL,\n    MIN_UNTIL,\n    NOT_LITERAL, NOT_LITERAL_IGNORE,\n    NEGATE,\n    RANGE,\n    REPEAT,\n    REPEAT_ONE,\n    SUBPATTERN,\n    MIN_REPEAT_ONE\n\n]\n\nATCODES = [\n    AT_BEGINNING, AT_BEGINNING_LINE, AT_BEGINNING_STRING, AT_BOUNDARY,\n    AT_NON_BOUNDARY, AT_END, AT_END_LINE, AT_END_STRING,\n    AT_LOC_BOUNDARY, AT_LOC_NON_BOUNDARY, AT_UNI_BOUNDARY,\n    AT_UNI_NON_BOUNDARY\n]\n\nCHCODES = [\n    CATEGORY_DIGIT, CATEGORY_NOT_DIGIT, CATEGORY_SPACE,\n    CATEGORY_NOT_SPACE, CATEGORY_WORD, CATEGORY_NOT_WORD,\n    CATEGORY_LINEBREAK, CATEGORY_NOT_LINEBREAK, CATEGORY_LOC_WORD,\n    CATEGORY_LOC_NOT_WORD, CATEGORY_UNI_DIGIT, CATEGORY_UNI_NOT_DIGIT,\n    CATEGORY_UNI_SPACE, CATEGORY_UNI_NOT_SPACE, CATEGORY_UNI_WORD,\n    CATEGORY_UNI_NOT_WORD, CATEGORY_UNI_LINEBREAK,\n    CATEGORY_UNI_NOT_LINEBREAK\n]\n\ndef makedict(list):\n    d = {}\n    i = 0\n    for item in list:\n        d[item] = i\n        i = i + 1\n    return d\n\nOPCODES = makedict(OPCODES)\nATCODES = makedict(ATCODES)\nCHCODES = makedict(CHCODES)\n\n# replacement operations for \"ignore case\" mode\nOP_IGNORE = {\n    GROUPREF: GROUPREF_IGNORE,\n    IN: IN_IGNORE,\n    LITERAL: LITERAL_IGNORE,\n    NOT_LITERAL: NOT_LITERAL_IGNORE\n}\n\nAT_MULTILINE = {\n    AT_BEGINNING: AT_BEGINNING_LINE,\n    AT_END: AT_END_LINE\n}\n\nAT_LOCALE = {\n    AT_BOUNDARY: AT_LOC_BOUNDARY,\n    AT_NON_BOUNDARY: AT_LOC_NON_BOUNDARY\n}\n\nAT_UNICODE = {\n    AT_BOUNDARY: AT_UNI_BOUNDARY,\n    AT_NON_BOUNDARY: AT_UNI_NON_BOUNDARY\n}\n\nCH_LOCALE = {\n    CATEGORY_DIGIT: CATEGORY_DIGIT,\n    CATEGORY_NOT_DIGIT: CATEGORY_NOT_DIGIT,\n    CATEGORY_SPACE: CATEGORY_SPACE,\n    CATEGORY_NOT_SPACE: CATEGORY_NOT_SPACE,\n    CATEGORY_WORD: CATEGORY_LOC_WORD,\n    CATEGORY_NOT_WORD: CATEGORY_LOC_NOT_WORD,\n    CATEGORY_LINEBREAK: CATEGORY_LINEBREAK,\n    CATEGORY_NOT_LINEBREAK: CATEGORY_NOT_LINEBREAK\n}\n\nCH_UNICODE = {\n    CATEGORY_DIGIT: CATEGORY_UNI_DIGIT,\n    CATEGORY_NOT_DIGIT: CATEGORY_UNI_NOT_DIGIT,\n    CATEGORY_SPACE: CATEGORY_UNI_SPACE,\n    CATEGORY_NOT_SPACE: CATEGORY_UNI_NOT_SPACE,\n    CATEGORY_WORD: CATEGORY_UNI_WORD,\n    CATEGORY_NOT_WORD: CATEGORY_UNI_NOT_WORD,\n    CATEGORY_LINEBREAK: CATEGORY_UNI_LINEBREAK,\n    CATEGORY_NOT_LINEBREAK: CATEGORY_UNI_NOT_LINEBREAK\n}\n\n# flags\nSRE_FLAG_TEMPLATE = 1 # template mode (disable backtracking)\nSRE_FLAG_IGNORECASE = 2 # case insensitive\nSRE_FLAG_LOCALE = 4 # honour system locale\nSRE_FLAG_MULTILINE = 8 # treat target as multiline string\nSRE_FLAG_DOTALL = 16 # treat target as a single string\nSRE_FLAG_UNICODE = 32 # use unicode locale\nSRE_FLAG_VERBOSE = 64 # ignore whitespace and comments\nSRE_FLAG_DEBUG = 128 # debugging\n\n# flags for INFO primitive\nSRE_INFO_PREFIX = 1 # has prefix\nSRE_INFO_LITERAL = 2 # entire pattern is literal (given by prefix)\nSRE_INFO_CHARSET = 4 # pattern starts with character from given set\n\nif __name__ == \"__main__\":\n    def dump(f, d, prefix):\n        items = d.items()\n        items.sort(key=lambda a: a[1])\n        for k, v in items:\n            f.write(\"#define %s_%s %s\\n\" % (prefix, k.upper(), v))\n    f = open(\"sre_constants.h\", \"w\")\n    f.write(\"\"\"\\\n/*\n * Secret Labs' Regular Expression Engine\n *\n * regular expression matching engine\n *\n * NOTE: This file is generated by sre_constants.py.  If you need\n * to change anything in here, edit sre_constants.py and run it.\n *\n * Copyright (c) 1997-2001 by Secret Labs AB.  All rights reserved.\n *\n * See the _sre.c file for information on usage and redistribution.\n */\n\n\"\"\")\n\n    f.write(\"#define SRE_MAGIC %d\\n\" % MAGIC)\n\n    dump(f, OPCODES, \"SRE_OP\")\n    dump(f, ATCODES, \"SRE\")\n    dump(f, CHCODES, \"SRE\")\n\n    f.write(\"#define SRE_FLAG_TEMPLATE %d\\n\" % SRE_FLAG_TEMPLATE)\n    f.write(\"#define SRE_FLAG_IGNORECASE %d\\n\" % SRE_FLAG_IGNORECASE)\n    f.write(\"#define SRE_FLAG_LOCALE %d\\n\" % SRE_FLAG_LOCALE)\n    f.write(\"#define SRE_FLAG_MULTILINE %d\\n\" % SRE_FLAG_MULTILINE)\n    f.write(\"#define SRE_FLAG_DOTALL %d\\n\" % SRE_FLAG_DOTALL)\n    f.write(\"#define SRE_FLAG_UNICODE %d\\n\" % SRE_FLAG_UNICODE)\n    f.write(\"#define SRE_FLAG_VERBOSE %d\\n\" % SRE_FLAG_VERBOSE)\n\n    f.write(\"#define SRE_INFO_PREFIX %d\\n\" % SRE_INFO_PREFIX)\n    f.write(\"#define SRE_INFO_LITERAL %d\\n\" % SRE_INFO_LITERAL)\n    f.write(\"#define SRE_INFO_CHARSET %d\\n\" % SRE_INFO_CHARSET)\n\n    f.close()\n    print \"done\"\n", 
    "sre_parse": "#\n# Secret Labs' Regular Expression Engine\n#\n# convert re-style regular expression to sre pattern\n#\n# Copyright (c) 1998-2001 by Secret Labs AB.  All rights reserved.\n#\n# See the sre.py file for information on usage and redistribution.\n#\n\n\"\"\"Internal support module for sre\"\"\"\n\n# XXX: show string offset and offending character for all errors\n\nimport sys\n\nfrom sre_constants import *\n\ntry:\n    from __pypy__ import newdict\nexcept ImportError:\n    assert '__pypy__' not in sys.builtin_module_names\n    newdict = lambda _ : {}\n\nSPECIAL_CHARS = \".\\\\[{()*+?^$|\"\nREPEAT_CHARS = \"*+?{\"\n\nDIGITS = set(\"0123456789\")\n\nOCTDIGITS = set(\"01234567\")\nHEXDIGITS = set(\"0123456789abcdefABCDEF\")\n\nWHITESPACE = set(\" \\t\\n\\r\\v\\f\")\n\nESCAPES = {\n    r\"\\a\": (LITERAL, ord(\"\\a\")),\n    r\"\\b\": (LITERAL, ord(\"\\b\")),\n    r\"\\f\": (LITERAL, ord(\"\\f\")),\n    r\"\\n\": (LITERAL, ord(\"\\n\")),\n    r\"\\r\": (LITERAL, ord(\"\\r\")),\n    r\"\\t\": (LITERAL, ord(\"\\t\")),\n    r\"\\v\": (LITERAL, ord(\"\\v\")),\n    r\"\\\\\": (LITERAL, ord(\"\\\\\"))\n}\n\nCATEGORIES = {\n    r\"\\A\": (AT, AT_BEGINNING_STRING), # start of string\n    r\"\\b\": (AT, AT_BOUNDARY),\n    r\"\\B\": (AT, AT_NON_BOUNDARY),\n    r\"\\d\": (IN, [(CATEGORY, CATEGORY_DIGIT)]),\n    r\"\\D\": (IN, [(CATEGORY, CATEGORY_NOT_DIGIT)]),\n    r\"\\s\": (IN, [(CATEGORY, CATEGORY_SPACE)]),\n    r\"\\S\": (IN, [(CATEGORY, CATEGORY_NOT_SPACE)]),\n    r\"\\w\": (IN, [(CATEGORY, CATEGORY_WORD)]),\n    r\"\\W\": (IN, [(CATEGORY, CATEGORY_NOT_WORD)]),\n    r\"\\Z\": (AT, AT_END_STRING), # end of string\n}\n\nFLAGS = {\n    # standard flags\n    \"i\": SRE_FLAG_IGNORECASE,\n    \"L\": SRE_FLAG_LOCALE,\n    \"m\": SRE_FLAG_MULTILINE,\n    \"s\": SRE_FLAG_DOTALL,\n    \"x\": SRE_FLAG_VERBOSE,\n    # extensions\n    \"t\": SRE_FLAG_TEMPLATE,\n    \"u\": SRE_FLAG_UNICODE,\n}\n\nclass Pattern:\n    # master pattern object.  keeps track of global attributes\n    def __init__(self):\n        self.flags = 0\n        self.open = []\n        self.groups = 1\n        self.groupdict = newdict(\"module\")\n    def opengroup(self, name=None):\n        gid = self.groups\n        self.groups = gid + 1\n        if name is not None:\n            ogid = self.groupdict.get(name, None)\n            if ogid is not None:\n                raise error, (\"redefinition of group name %s as group %d; \"\n                              \"was group %d\" % (repr(name), gid,  ogid))\n            self.groupdict[name] = gid\n        self.open.append(gid)\n        return gid\n    def closegroup(self, gid):\n        self.open.remove(gid)\n    def checkgroup(self, gid):\n        return gid < self.groups and gid not in self.open\n\nclass SubPattern:\n    # a subpattern, in intermediate form\n    def __init__(self, pattern, data=None):\n        self.pattern = pattern\n        if data is None:\n            data = []\n        self.data = data\n        self.width = None\n    def dump(self, level=0):\n        nl = 1\n        seqtypes = type(()), type([])\n        for op, av in self.data:\n            print level*\"  \" + op,; nl = 0\n            if op == \"in\":\n                # member sublanguage\n                print; nl = 1\n                for op, a in av:\n                    print (level+1)*\"  \" + op, a\n            elif op == \"branch\":\n                print; nl = 1\n                i = 0\n                for a in av[1]:\n                    if i > 0:\n                        print level*\"  \" + \"or\"\n                    a.dump(level+1); nl = 1\n                    i = i + 1\n            elif type(av) in seqtypes:\n                for a in av:\n                    if isinstance(a, SubPattern):\n                        if not nl: print\n                        a.dump(level+1); nl = 1\n                    else:\n                        print a, ; nl = 0\n            else:\n                print av, ; nl = 0\n            if not nl: print\n    def __repr__(self):\n        return repr(self.data)\n    def __len__(self):\n        return len(self.data)\n    def __delitem__(self, index):\n        del self.data[index]\n    def __getitem__(self, index):\n        if isinstance(index, slice):\n            return SubPattern(self.pattern, self.data[index])\n        return self.data[index]\n    def __setitem__(self, index, code):\n        self.data[index] = code\n    def insert(self, index, code):\n        self.data.insert(index, code)\n    def append(self, code):\n        self.data.append(code)\n    def getwidth(self):\n        # determine the width (min, max) for this subpattern\n        if self.width:\n            return self.width\n        lo = hi = 0\n        UNITCODES = (ANY, RANGE, IN, LITERAL, NOT_LITERAL, CATEGORY)\n        REPEATCODES = (MIN_REPEAT, MAX_REPEAT)\n        for op, av in self.data:\n            if op is BRANCH:\n                i = MAXREPEAT - 1\n                j = 0\n                for av in av[1]:\n                    l, h = av.getwidth()\n                    i = min(i, l)\n                    j = max(j, h)\n                lo = lo + i\n                hi = hi + j\n            elif op is CALL:\n                i, j = av.getwidth()\n                lo = lo + i\n                hi = hi + j\n            elif op is SUBPATTERN:\n                i, j = av[1].getwidth()\n                lo = lo + i\n                hi = hi + j\n            elif op in REPEATCODES:\n                i, j = av[2].getwidth()\n                lo = lo + i * av[0]\n                hi = hi + j * av[1]\n            elif op in UNITCODES:\n                lo = lo + 1\n                hi = hi + 1\n            elif op == SUCCESS:\n                break\n        self.width = min(lo, MAXREPEAT - 1), min(hi, MAXREPEAT)\n        return self.width\n\nclass Tokenizer:\n    def __init__(self, string):\n        self.string = string\n        self.index = 0\n        self.__next()\n    def __next(self):\n        if self.index >= len(self.string):\n            self.next = None\n            return\n        char = self.string[self.index]\n        if char[0] == \"\\\\\":\n            try:\n                c = self.string[self.index + 1]\n            except IndexError:\n                raise error, \"bogus escape (end of line)\"\n            char = char + c\n        self.index = self.index + len(char)\n        self.next = char\n    def match(self, char, skip=1):\n        if char == self.next:\n            if skip:\n                self.__next()\n            return 1\n        return 0\n    def get(self):\n        this = self.next\n        self.__next()\n        return this\n    def tell(self):\n        return self.index, self.next\n    def seek(self, index):\n        self.index, self.next = index\n\ndef isident(char):\n    return \"a\" <= char <= \"z\" or \"A\" <= char <= \"Z\" or char == \"_\"\n\ndef isdigit(char):\n    return \"0\" <= char <= \"9\"\n\ndef isname(name):\n    # check that group name is a valid string\n    if not isident(name[0]):\n        return False\n    for char in name[1:]:\n        if not isident(char) and not isdigit(char):\n            return False\n    return True\n\ndef _class_escape(source, escape):\n    # handle escape code inside character class\n    code = ESCAPES.get(escape)\n    if code:\n        return code\n    code = CATEGORIES.get(escape)\n    if code and code[0] == IN:\n        return code\n    try:\n        c = escape[1:2]\n        if c == \"x\":\n            # hexadecimal escape (exactly two digits)\n            while source.next in HEXDIGITS and len(escape) < 4:\n                escape = escape + source.get()\n            escape = escape[2:]\n            if len(escape) != 2:\n                raise error, \"bogus escape: %s\" % repr(\"\\\\\" + escape)\n            return LITERAL, int(escape, 16) & 0xff\n        elif c in OCTDIGITS:\n            # octal escape (up to three digits)\n            while source.next in OCTDIGITS and len(escape) < 4:\n                escape = escape + source.get()\n            escape = escape[1:]\n            return LITERAL, int(escape, 8) & 0xff\n        elif c in DIGITS:\n            raise error, \"bogus escape: %s\" % repr(escape)\n        if len(escape) == 2:\n            return LITERAL, ord(escape[1])\n    except ValueError:\n        pass\n    raise error, \"bogus escape: %s\" % repr(escape)\n\ndef _escape(source, escape, state):\n    # handle escape code in expression\n    code = CATEGORIES.get(escape)\n    if code:\n        return code\n    code = ESCAPES.get(escape)\n    if code:\n        return code\n    try:\n        c = escape[1:2]\n        if c == \"x\":\n            # hexadecimal escape\n            while source.next in HEXDIGITS and len(escape) < 4:\n                escape = escape + source.get()\n            if len(escape) != 4:\n                raise ValueError\n            return LITERAL, int(escape[2:], 16) & 0xff\n        elif c == \"0\":\n            # octal escape\n            while source.next in OCTDIGITS and len(escape) < 4:\n                escape = escape + source.get()\n            return LITERAL, int(escape[1:], 8) & 0xff\n        elif c in DIGITS:\n            # octal escape *or* decimal group reference (sigh)\n            if source.next in DIGITS:\n                escape = escape + source.get()\n                if (escape[1] in OCTDIGITS and escape[2] in OCTDIGITS and\n                    source.next in OCTDIGITS):\n                    # got three octal digits; this is an octal escape\n                    escape = escape + source.get()\n                    return LITERAL, int(escape[1:], 8) & 0xff\n            # not an octal escape, so this is a group reference\n            group = int(escape[1:])\n            if group < state.groups:\n                if not state.checkgroup(group):\n                    raise error, \"cannot refer to open group\"\n                return GROUPREF, group\n            raise ValueError\n        if len(escape) == 2:\n            return LITERAL, ord(escape[1])\n    except ValueError:\n        pass\n    raise error, \"bogus escape: %s\" % repr(escape)\n\ndef _parse_sub(source, state, nested=1):\n    # parse an alternation: a|b|c\n\n    items = []\n    itemsappend = items.append\n    sourcematch = source.match\n    while 1:\n        itemsappend(_parse(source, state))\n        if sourcematch(\"|\"):\n            continue\n        if not nested:\n            break\n        if not source.next or sourcematch(\")\", 0):\n            break\n        else:\n            raise error, \"pattern not properly closed\"\n\n    if len(items) == 1:\n        return items[0]\n\n    subpattern = SubPattern(state)\n    subpatternappend = subpattern.append\n\n    # check if all items share a common prefix\n    while 1:\n        prefix = None\n        for item in items:\n            if not item:\n                break\n            if prefix is None:\n                prefix = item[0]\n            elif item[0] != prefix:\n                break\n        else:\n            # all subitems start with a common \"prefix\".\n            # move it out of the branch\n            for item in items:\n                del item[0]\n            subpatternappend(prefix)\n            continue # check next one\n        break\n\n    # check if the branch can be replaced by a character set\n    for item in items:\n        if len(item) != 1 or item[0][0] != LITERAL:\n            break\n    else:\n        # we can store this as a character set instead of a\n        # branch (the compiler may optimize this even more)\n        set = []\n        setappend = set.append\n        for item in items:\n            setappend(item[0])\n        subpatternappend((IN, set))\n        return subpattern\n\n    subpattern.append((BRANCH, (None, items)))\n    return subpattern\n\ndef _parse_sub_cond(source, state, condgroup):\n    item_yes = _parse(source, state)\n    if source.match(\"|\"):\n        item_no = _parse(source, state)\n        if source.match(\"|\"):\n            raise error, \"conditional backref with more than two branches\"\n    else:\n        item_no = None\n    if source.next and not source.match(\")\", 0):\n        raise error, \"pattern not properly closed\"\n    subpattern = SubPattern(state)\n    subpattern.append((GROUPREF_EXISTS, (condgroup, item_yes, item_no)))\n    return subpattern\n\n_PATTERNENDERS = set(\"|)\")\n_ASSERTCHARS = set(\"=!<\")\n_LOOKBEHINDASSERTCHARS = set(\"=!\")\n_REPEATCODES = set([MIN_REPEAT, MAX_REPEAT])\n\ndef _parse(source, state):\n    # parse a simple pattern\n    subpattern = SubPattern(state)\n\n    # precompute constants into local variables\n    subpatternappend = subpattern.append\n    sourceget = source.get\n    sourcematch = source.match\n    _len = len\n    PATTERNENDERS = _PATTERNENDERS\n    ASSERTCHARS = _ASSERTCHARS\n    LOOKBEHINDASSERTCHARS = _LOOKBEHINDASSERTCHARS\n    REPEATCODES = _REPEATCODES\n\n    while 1:\n\n        if source.next in PATTERNENDERS:\n            break # end of subpattern\n        this = sourceget()\n        if this is None:\n            break # end of pattern\n\n        if state.flags & SRE_FLAG_VERBOSE:\n            # skip whitespace and comments\n            if this in WHITESPACE:\n                continue\n            if this == \"#\":\n                while 1:\n                    this = sourceget()\n                    if this in (None, \"\\n\"):\n                        break\n                continue\n\n        if this and this[0] not in SPECIAL_CHARS:\n            subpatternappend((LITERAL, ord(this)))\n\n        elif this == \"[\":\n            # character set\n            set = []\n            setappend = set.append\n##          if sourcematch(\":\"):\n##              pass # handle character classes\n            if sourcematch(\"^\"):\n                setappend((NEGATE, None))\n            # check remaining characters\n            start = set[:]\n            while 1:\n                this = sourceget()\n                if this == \"]\" and set != start:\n                    break\n                elif this and this[0] == \"\\\\\":\n                    code1 = _class_escape(source, this)\n                elif this:\n                    code1 = LITERAL, ord(this)\n                else:\n                    raise error, \"unexpected end of regular expression\"\n                if sourcematch(\"-\"):\n                    # potential range\n                    this = sourceget()\n                    if this == \"]\":\n                        if code1[0] is IN:\n                            code1 = code1[1][0]\n                        setappend(code1)\n                        setappend((LITERAL, ord(\"-\")))\n                        break\n                    elif this:\n                        if this[0] == \"\\\\\":\n                            code2 = _class_escape(source, this)\n                        else:\n                            code2 = LITERAL, ord(this)\n                        if code1[0] != LITERAL or code2[0] != LITERAL:\n                            raise error, \"bad character range\"\n                        lo = code1[1]\n                        hi = code2[1]\n                        if hi < lo:\n                            raise error, \"bad character range\"\n                        setappend((RANGE, (lo, hi)))\n                    else:\n                        raise error, \"unexpected end of regular expression\"\n                else:\n                    if code1[0] is IN:\n                        code1 = code1[1][0]\n                    setappend(code1)\n\n            # XXX: <fl> should move set optimization to compiler!\n            if _len(set)==1 and set[0][0] is LITERAL:\n                subpatternappend(set[0]) # optimization\n            elif _len(set)==2 and set[0][0] is NEGATE and set[1][0] is LITERAL:\n                subpatternappend((NOT_LITERAL, set[1][1])) # optimization\n            else:\n                # XXX: <fl> should add charmap optimization here\n                subpatternappend((IN, set))\n\n        elif this and this[0] in REPEAT_CHARS:\n            # repeat previous item\n            if this == \"?\":\n                min, max = 0, 1\n            elif this == \"*\":\n                min, max = 0, MAXREPEAT\n\n            elif this == \"+\":\n                min, max = 1, MAXREPEAT\n            elif this == \"{\":\n                if source.next == \"}\":\n                    subpatternappend((LITERAL, ord(this)))\n                    continue\n                here = source.tell()\n                min, max = 0, MAXREPEAT\n                lo = hi = \"\"\n                while source.next in DIGITS:\n                    lo = lo + source.get()\n                if sourcematch(\",\"):\n                    while source.next in DIGITS:\n                        hi = hi + sourceget()\n                else:\n                    hi = lo\n                if not sourcematch(\"}\"):\n                    subpatternappend((LITERAL, ord(this)))\n                    source.seek(here)\n                    continue\n                if lo:\n                    min = int(lo)\n                    if min >= MAXREPEAT:\n                        raise OverflowError(\"the repetition number is too large\")\n                if hi:\n                    max = int(hi)\n                    if max >= MAXREPEAT:\n                        raise OverflowError(\"the repetition number is too large\")\n                    if max < min:\n                        raise error(\"bad repeat interval\")\n            else:\n                raise error, \"not supported\"\n            # figure out which item to repeat\n            if subpattern:\n                item = subpattern[-1:]\n            else:\n                item = None\n            if not item or (_len(item) == 1 and item[0][0] == AT):\n                raise error, \"nothing to repeat\"\n            if item[0][0] in REPEATCODES:\n                raise error, \"multiple repeat\"\n            if sourcematch(\"?\"):\n                subpattern[-1] = (MIN_REPEAT, (min, max, item))\n            else:\n                subpattern[-1] = (MAX_REPEAT, (min, max, item))\n\n        elif this == \".\":\n            subpatternappend((ANY, None))\n\n        elif this == \"(\":\n            group = 1\n            name = None\n            condgroup = None\n            if sourcematch(\"?\"):\n                group = 0\n                # options\n                if sourcematch(\"P\"):\n                    # python extensions\n                    if sourcematch(\"<\"):\n                        # named group: skip forward to end of name\n                        name = \"\"\n                        while 1:\n                            char = sourceget()\n                            if char is None:\n                                raise error, \"unterminated name\"\n                            if char == \">\":\n                                break\n                            name = name + char\n                        group = 1\n                        if not name:\n                            raise error(\"missing group name\")\n                        if not isname(name):\n                            raise error(\"bad character in group name %r\" %\n                                        name)\n                    elif sourcematch(\"=\"):\n                        # named backreference\n                        name = \"\"\n                        while 1:\n                            char = sourceget()\n                            if char is None:\n                                raise error, \"unterminated name\"\n                            if char == \")\":\n                                break\n                            name = name + char\n                        if not name:\n                            raise error(\"missing group name\")\n                        if not isname(name):\n                            raise error(\"bad character in backref group name \"\n                                        \"%r\" % name)\n                        gid = state.groupdict.get(name)\n                        if gid is None:\n                            msg = \"unknown group name: {0!r}\".format(name)\n                            raise error(msg)\n                        subpatternappend((GROUPREF, gid))\n                        continue\n                    else:\n                        char = sourceget()\n                        if char is None:\n                            raise error, \"unexpected end of pattern\"\n                        raise error, \"unknown specifier: ?P%s\" % char\n                elif sourcematch(\":\"):\n                    # non-capturing group\n                    group = 2\n                elif sourcematch(\"#\"):\n                    # comment\n                    while 1:\n                        if source.next is None or source.next == \")\":\n                            break\n                        sourceget()\n                    if not sourcematch(\")\"):\n                        raise error, \"unbalanced parenthesis\"\n                    continue\n                elif source.next in ASSERTCHARS:\n                    # lookahead assertions\n                    char = sourceget()\n                    dir = 1\n                    if char == \"<\":\n                        if source.next not in LOOKBEHINDASSERTCHARS:\n                            raise error, \"syntax error\"\n                        dir = -1 # lookbehind\n                        char = sourceget()\n                    p = _parse_sub(source, state)\n                    if not sourcematch(\")\"):\n                        raise error, \"unbalanced parenthesis\"\n                    if char == \"=\":\n                        subpatternappend((ASSERT, (dir, p)))\n                    else:\n                        subpatternappend((ASSERT_NOT, (dir, p)))\n                    continue\n                elif sourcematch(\"(\"):\n                    # conditional backreference group\n                    condname = \"\"\n                    while 1:\n                        char = sourceget()\n                        if char is None:\n                            raise error, \"unterminated name\"\n                        if char == \")\":\n                            break\n                        condname = condname + char\n                    group = 2\n                    if not condname:\n                        raise error(\"missing group name\")\n                    if isname(condname):\n                        condgroup = state.groupdict.get(condname)\n                        if condgroup is None:\n                            msg = \"unknown group name: {0!r}\".format(condname)\n                            raise error(msg)\n                    else:\n                        try:\n                            condgroup = int(condname)\n                        except ValueError:\n                            raise error, \"bad character in group name\"\n                else:\n                    # flags\n                    if not source.next in FLAGS:\n                        raise error, \"unexpected end of pattern\"\n                    while source.next in FLAGS:\n                        state.flags = state.flags | FLAGS[sourceget()]\n            if group:\n                # parse group contents\n                if group == 2:\n                    # anonymous group\n                    group = None\n                else:\n                    group = state.opengroup(name)\n                if condgroup:\n                    p = _parse_sub_cond(source, state, condgroup)\n                else:\n                    p = _parse_sub(source, state)\n                if not sourcematch(\")\"):\n                    raise error, \"unbalanced parenthesis\"\n                if group is not None:\n                    state.closegroup(group)\n                subpatternappend((SUBPATTERN, (group, p)))\n            else:\n                while 1:\n                    char = sourceget()\n                    if char is None:\n                        raise error, \"unexpected end of pattern\"\n                    if char == \")\":\n                        break\n                    raise error, \"unknown extension\"\n\n        elif this == \"^\":\n            subpatternappend((AT, AT_BEGINNING))\n\n        elif this == \"$\":\n            subpattern.append((AT, AT_END))\n\n        elif this and this[0] == \"\\\\\":\n            code = _escape(source, this, state)\n            subpatternappend(code)\n\n        else:\n            raise error, \"parser error\"\n\n    return subpattern\n\ndef parse(str, flags=0, pattern=None):\n    # parse 're' pattern into list of (opcode, argument) tuples\n\n    source = Tokenizer(str)\n\n    if pattern is None:\n        pattern = Pattern()\n    pattern.flags = flags\n    pattern.str = str\n\n    p = _parse_sub(source, pattern, 0)\n\n    tail = source.get()\n    if tail == \")\":\n        raise error, \"unbalanced parenthesis\"\n    elif tail:\n        raise error, \"bogus characters at end of regular expression\"\n\n    if flags & SRE_FLAG_DEBUG:\n        p.dump()\n\n    if not (flags & SRE_FLAG_VERBOSE) and p.pattern.flags & SRE_FLAG_VERBOSE:\n        # the VERBOSE flag was switched on inside the pattern.  to be\n        # on the safe side, we'll parse the whole thing again...\n        return parse(str, p.pattern.flags)\n\n    return p\n\ndef parse_template(source, pattern):\n    # parse 're' replacement string into list of literals and\n    # group references\n    s = Tokenizer(source)\n    sget = s.get\n    p = []\n    a = p.append\n    def literal(literal, p=p, pappend=a):\n        if p and p[-1][0] is LITERAL:\n            p[-1] = LITERAL, p[-1][1] + literal\n        else:\n            pappend((LITERAL, literal))\n    sep = source[:0]\n    if type(sep) is type(\"\"):\n        makechar = chr\n    else:\n        makechar = unichr\n    while 1:\n        this = sget()\n        if this is None:\n            break # end of replacement string\n        if this and this[0] == \"\\\\\":\n            # group\n            c = this[1:2]\n            if c == \"g\":\n                name = \"\"\n                if s.match(\"<\"):\n                    while 1:\n                        char = sget()\n                        if char is None:\n                            raise error, \"unterminated group name\"\n                        if char == \">\":\n                            break\n                        name = name + char\n                if not name:\n                    raise error, \"missing group name\"\n                try:\n                    index = int(name)\n                    if index < 0:\n                        raise error, \"negative group number\"\n                except ValueError:\n                    if not isname(name):\n                        raise error, \"bad character in group name\"\n                    try:\n                        index = pattern.groupindex[name]\n                    except KeyError:\n                        msg = \"unknown group name: {0!r}\".format(name)\n                        raise IndexError(msg)\n                a((MARK, index))\n            elif c == \"0\":\n                if s.next in OCTDIGITS:\n                    this = this + sget()\n                    if s.next in OCTDIGITS:\n                        this = this + sget()\n                literal(makechar(int(this[1:], 8) & 0xff))\n            elif c in DIGITS:\n                isoctal = False\n                if s.next in DIGITS:\n                    this = this + sget()\n                    if (c in OCTDIGITS and this[2] in OCTDIGITS and\n                        s.next in OCTDIGITS):\n                        this = this + sget()\n                        isoctal = True\n                        literal(makechar(int(this[1:], 8) & 0xff))\n                if not isoctal:\n                    a((MARK, int(this[1:])))\n            else:\n                try:\n                    this = makechar(ESCAPES[this][1])\n                except KeyError:\n                    pass\n                literal(this)\n        else:\n            literal(this)\n    # convert template to groups and literals lists\n    i = 0\n    groups = []\n    groupsappend = groups.append\n    literals = [None] * len(p)\n    for c, s in p:\n        if c is MARK:\n            groupsappend((i, s))\n            # literal[i] is already None\n        else:\n            literals[i] = s\n        i = i + 1\n    return groups, literals\n\ndef expand_template(template, match):\n    g = match.group\n    sep = match.string[:0]\n    groups, literals = template\n    literals = literals[:]\n    try:\n        for index, group in groups:\n            literals[index] = s = g(group)\n            if s is None:\n                raise error, \"unmatched group\"\n    except IndexError:\n        raise error, \"invalid group reference\"\n    return sep.join(literals)\n", 
    "stat": "\"\"\"Constants/functions for interpreting results of os.stat() and os.lstat().\n\nSuggested usage: from stat import *\n\"\"\"\n\n# Indices for stat struct members in the tuple returned by os.stat()\n\nST_MODE  = 0\nST_INO   = 1\nST_DEV   = 2\nST_NLINK = 3\nST_UID   = 4\nST_GID   = 5\nST_SIZE  = 6\nST_ATIME = 7\nST_MTIME = 8\nST_CTIME = 9\n\n# Extract bits from the mode\n\ndef S_IMODE(mode):\n    return mode & 07777\n\ndef S_IFMT(mode):\n    return mode & 0170000\n\n# Constants used as S_IFMT() for various file types\n# (not all are implemented on all systems)\n\nS_IFDIR  = 0040000\nS_IFCHR  = 0020000\nS_IFBLK  = 0060000\nS_IFREG  = 0100000\nS_IFIFO  = 0010000\nS_IFLNK  = 0120000\nS_IFSOCK = 0140000\n\n# Functions to test for each file type\n\ndef S_ISDIR(mode):\n    return S_IFMT(mode) == S_IFDIR\n\ndef S_ISCHR(mode):\n    return S_IFMT(mode) == S_IFCHR\n\ndef S_ISBLK(mode):\n    return S_IFMT(mode) == S_IFBLK\n\ndef S_ISREG(mode):\n    return S_IFMT(mode) == S_IFREG\n\ndef S_ISFIFO(mode):\n    return S_IFMT(mode) == S_IFIFO\n\ndef S_ISLNK(mode):\n    return S_IFMT(mode) == S_IFLNK\n\ndef S_ISSOCK(mode):\n    return S_IFMT(mode) == S_IFSOCK\n\n# Names for permission bits\n\nS_ISUID = 04000\nS_ISGID = 02000\nS_ENFMT = S_ISGID\nS_ISVTX = 01000\nS_IREAD = 00400\nS_IWRITE = 00200\nS_IEXEC = 00100\nS_IRWXU = 00700\nS_IRUSR = 00400\nS_IWUSR = 00200\nS_IXUSR = 00100\nS_IRWXG = 00070\nS_IRGRP = 00040\nS_IWGRP = 00020\nS_IXGRP = 00010\nS_IRWXO = 00007\nS_IROTH = 00004\nS_IWOTH = 00002\nS_IXOTH = 00001\n\n# Names for file flags\n\nUF_NODUMP    = 0x00000001\nUF_IMMUTABLE = 0x00000002\nUF_APPEND    = 0x00000004\nUF_OPAQUE    = 0x00000008\nUF_NOUNLINK  = 0x00000010\nUF_COMPRESSED = 0x00000020  # OS X: file is hfs-compressed\nUF_HIDDEN    = 0x00008000   # OS X: file should not be displayed\nSF_ARCHIVED  = 0x00010000\nSF_IMMUTABLE = 0x00020000\nSF_APPEND    = 0x00040000\nSF_NOUNLINK  = 0x00100000\nSF_SNAPSHOT  = 0x00200000\n", 
    "struct": "from _struct import *\nfrom _struct import _clearcache\nfrom _struct import __doc__\n", 
    "traceback": "\"\"\"Extract, format and print information about Python stack traces.\"\"\"\n\nimport linecache\nimport sys\nimport types\n\n__all__ = ['extract_stack', 'extract_tb', 'format_exception',\n           'format_exception_only', 'format_list', 'format_stack',\n           'format_tb', 'print_exc', 'format_exc', 'print_exception',\n           'print_last', 'print_stack', 'print_tb', 'tb_lineno']\n\ndef _print(file, str='', terminator='\\n'):\n    file.write(str+terminator)\n\n\ndef print_list(extracted_list, file=None):\n    \"\"\"Print the list of tuples as returned by extract_tb() or\n    extract_stack() as a formatted stack trace to the given file.\"\"\"\n    if file is None:\n        file = sys.stderr\n    for filename, lineno, name, line in extracted_list:\n        _print(file,\n               '  File \"%s\", line %d, in %s' % (filename,lineno,name))\n        if line:\n            _print(file, '    %s' % line.strip())\n\ndef format_list(extracted_list):\n    \"\"\"Format a list of traceback entry tuples for printing.\n\n    Given a list of tuples as returned by extract_tb() or\n    extract_stack(), return a list of strings ready for printing.\n    Each string in the resulting list corresponds to the item with the\n    same index in the argument list.  Each string ends in a newline;\n    the strings may contain internal newlines as well, for those items\n    whose source text line is not None.\n    \"\"\"\n    list = []\n    for filename, lineno, name, line in extracted_list:\n        item = '  File \"%s\", line %d, in %s\\n' % (filename,lineno,name)\n        if line:\n            item = item + '    %s\\n' % line.strip()\n        list.append(item)\n    return list\n\n\ndef print_tb(tb, limit=None, file=None):\n    \"\"\"Print up to 'limit' stack trace entries from the traceback 'tb'.\n\n    If 'limit' is omitted or None, all entries are printed.  If 'file'\n    is omitted or None, the output goes to sys.stderr; otherwise\n    'file' should be an open file or file-like object with a write()\n    method.\n    \"\"\"\n    if file is None:\n        file = sys.stderr\n    if limit is None:\n        if hasattr(sys, 'tracebacklimit'):\n            limit = sys.tracebacklimit\n    n = 0\n    while tb is not None and (limit is None or n < limit):\n        f = tb.tb_frame\n        lineno = tb.tb_lineno\n        co = f.f_code\n        filename = co.co_filename\n        name = co.co_name\n        _print(file,\n               '  File \"%s\", line %d, in %s' % (filename, lineno, name))\n        linecache.checkcache(filename)\n        line = linecache.getline(filename, lineno, f.f_globals)\n        if line: _print(file, '    ' + line.strip())\n        tb = tb.tb_next\n        n = n+1\n\ndef format_tb(tb, limit = None):\n    \"\"\"A shorthand for 'format_list(extract_tb(tb, limit))'.\"\"\"\n    return format_list(extract_tb(tb, limit))\n\ndef extract_tb(tb, limit = None):\n    \"\"\"Return list of up to limit pre-processed entries from traceback.\n\n    This is useful for alternate formatting of stack traces.  If\n    'limit' is omitted or None, all entries are extracted.  A\n    pre-processed stack trace entry is a quadruple (filename, line\n    number, function name, text) representing the information that is\n    usually printed for a stack trace.  The text is a string with\n    leading and trailing whitespace stripped; if the source is not\n    available it is None.\n    \"\"\"\n    if limit is None:\n        if hasattr(sys, 'tracebacklimit'):\n            limit = sys.tracebacklimit\n    list = []\n    n = 0\n    while tb is not None and (limit is None or n < limit):\n        f = tb.tb_frame\n        lineno = tb.tb_lineno\n        co = f.f_code\n        filename = co.co_filename\n        name = co.co_name\n        linecache.checkcache(filename)\n        line = linecache.getline(filename, lineno, f.f_globals)\n        if line: line = line.strip()\n        else: line = None\n        list.append((filename, lineno, name, line))\n        tb = tb.tb_next\n        n = n+1\n    return list\n\n\ndef print_exception(etype, value, tb, limit=None, file=None, _encoding=None):\n    \"\"\"Print exception up to 'limit' stack trace entries from 'tb' to 'file'.\n\n    This differs from print_tb() in the following ways: (1) if\n    traceback is not None, it prints a header \"Traceback (most recent\n    call last):\"; (2) it prints the exception type and value after the\n    stack trace; (3) if type is SyntaxError and value has the\n    appropriate format, it prints the line where the syntax error\n    occurred with a caret on the next line indicating the approximate\n    position of the error.\n    \"\"\"\n    if file is None:\n        file = sys.stderr\n    if tb:\n        _print(file, 'Traceback (most recent call last):')\n        print_tb(tb, limit, file)\n    lines = format_exception_only(etype, value, _encoding)\n    for line in lines:\n        _print(file, line, '')\n\ndef format_exception(etype, value, tb, limit = None):\n    \"\"\"Format a stack trace and the exception information.\n\n    The arguments have the same meaning as the corresponding arguments\n    to print_exception().  The return value is a list of strings, each\n    ending in a newline and some containing internal newlines.  When\n    these lines are concatenated and printed, exactly the same text is\n    printed as does print_exception().\n    \"\"\"\n    if tb:\n        list = ['Traceback (most recent call last):\\n']\n        list = list + format_tb(tb, limit)\n    else:\n        list = []\n    list = list + format_exception_only(etype, value)\n    return list\n\ndef format_exception_only(etype, value, _encoding=None):\n    \"\"\"Format the exception part of a traceback.\n\n    The arguments are the exception type and value such as given by\n    sys.last_type and sys.last_value. The return value is a list of\n    strings, each ending in a newline.\n\n    Normally, the list contains a single string; however, for\n    SyntaxError exceptions, it contains several lines that (when\n    printed) display detailed information about where the syntax\n    error occurred.\n\n    The message indicating which exception occurred is always the last\n    string in the list.\n\n    \"\"\"\n\n    # An instance should not have a meaningful value parameter, but\n    # sometimes does, particularly for string exceptions, such as\n    # >>> raise string1, string2  # deprecated\n    #\n    # Clear these out first because issubtype(string1, SyntaxError)\n    # would raise another exception and mask the original problem.\n    if (isinstance(etype, BaseException) or\n        isinstance(etype, types.InstanceType) or\n        etype is None or type(etype) is str):\n        return [_format_final_exc_line(etype, value, _encoding)]\n\n    stype = etype.__name__\n\n    if not issubclass(etype, SyntaxError):\n        return [_format_final_exc_line(stype, value, _encoding)]\n\n    # It was a syntax error; show exactly where the problem was found.\n    lines = []\n    try:\n        msg, (filename, lineno, offset, badline) = value.args\n    except Exception:\n        pass\n    else:\n        filename = filename or \"<string>\"\n        lines.append('  File \"%s\", line %d\\n' % (filename, lineno))\n        if badline is not None:\n            lines.append('    %s\\n' % badline.strip())\n            if offset is not None:\n                caretspace = badline.rstrip('\\n')\n                offset = min(len(caretspace), offset) - 1\n                caretspace = caretspace[:offset].lstrip()\n                # non-space whitespace (likes tabs) must be kept for alignment\n                caretspace = ((c.isspace() and c or ' ') for c in caretspace)\n                lines.append('    %s^\\n' % ''.join(caretspace))\n        value = msg\n\n    lines.append(_format_final_exc_line(stype, value, _encoding))\n    return lines\n\ndef _format_final_exc_line(etype, value, _encoding=None):\n    \"\"\"Return a list of a single line -- normal case for format_exception_only\"\"\"\n    valuestr = _some_str(value, _encoding)\n    if value is None or not valuestr:\n        line = \"%s\\n\" % etype\n    else:\n        line = \"%s: %s\\n\" % (etype, valuestr)\n    return line\n\ndef _some_str(value, _encoding=None):\n    try:\n        return str(value)\n    except Exception:\n        pass\n    try:\n        value = unicode(value)\n        return value.encode(_encoding or \"ascii\", \"backslashreplace\")\n    except Exception:\n        pass\n    return '<unprintable %s object>' % type(value).__name__\n\n\ndef print_exc(limit=None, file=None):\n    \"\"\"Shorthand for 'print_exception(sys.exc_type, sys.exc_value, sys.exc_traceback, limit, file)'.\n    (In fact, it uses sys.exc_info() to retrieve the same information\n    in a thread-safe way.)\"\"\"\n    if file is None:\n        file = sys.stderr\n    try:\n        etype, value, tb = sys.exc_info()\n        print_exception(etype, value, tb, limit, file)\n    finally:\n        etype = value = tb = None\n\n\ndef format_exc(limit=None):\n    \"\"\"Like print_exc() but return a string.\"\"\"\n    try:\n        etype, value, tb = sys.exc_info()\n        return ''.join(format_exception(etype, value, tb, limit))\n    finally:\n        etype = value = tb = None\n\n\ndef print_last(limit=None, file=None):\n    \"\"\"This is a shorthand for 'print_exception(sys.last_type,\n    sys.last_value, sys.last_traceback, limit, file)'.\"\"\"\n    if not hasattr(sys, \"last_type\"):\n        raise ValueError(\"no last exception\")\n    if file is None:\n        file = sys.stderr\n    print_exception(sys.last_type, sys.last_value, sys.last_traceback,\n                    limit, file)\n\n\ndef print_stack(f=None, limit=None, file=None):\n    \"\"\"Print a stack trace from its invocation point.\n\n    The optional 'f' argument can be used to specify an alternate\n    stack frame at which to start. The optional 'limit' and 'file'\n    arguments have the same meaning as for print_exception().\n    \"\"\"\n    if f is None:\n        try:\n            raise ZeroDivisionError\n        except ZeroDivisionError:\n            f = sys.exc_info()[2].tb_frame.f_back\n    print_list(extract_stack(f, limit), file)\n\ndef format_stack(f=None, limit=None):\n    \"\"\"Shorthand for 'format_list(extract_stack(f, limit))'.\"\"\"\n    if f is None:\n        try:\n            raise ZeroDivisionError\n        except ZeroDivisionError:\n            f = sys.exc_info()[2].tb_frame.f_back\n    return format_list(extract_stack(f, limit))\n\ndef extract_stack(f=None, limit = None):\n    \"\"\"Extract the raw traceback from the current stack frame.\n\n    The return value has the same format as for extract_tb().  The\n    optional 'f' and 'limit' arguments have the same meaning as for\n    print_stack().  Each item in the list is a quadruple (filename,\n    line number, function name, text), and the entries are in order\n    from oldest to newest stack frame.\n    \"\"\"\n    if f is None:\n        try:\n            raise ZeroDivisionError\n        except ZeroDivisionError:\n            f = sys.exc_info()[2].tb_frame.f_back\n    if limit is None:\n        if hasattr(sys, 'tracebacklimit'):\n            limit = sys.tracebacklimit\n    list = []\n    n = 0\n    while f is not None and (limit is None or n < limit):\n        lineno = f.f_lineno\n        co = f.f_code\n        filename = co.co_filename\n        name = co.co_name\n        linecache.checkcache(filename)\n        line = linecache.getline(filename, lineno, f.f_globals)\n        if line: line = line.strip()\n        else: line = None\n        list.append((filename, lineno, name, line))\n        f = f.f_back\n        n = n+1\n    list.reverse()\n    return list\n\ndef tb_lineno(tb):\n    \"\"\"Calculate correct line number of traceback given in tb.\n\n    Obsolete in 2.3.\n    \"\"\"\n    return tb.tb_lineno\n", 
    "types": "\"\"\"Define names for all type symbols known in the standard interpreter.\n\nTypes that are part of optional modules (e.g. array) are not listed.\n\"\"\"\nimport sys\n\n# Iterators in Python aren't a matter of type but of protocol.  A large\n# and changing number of builtin types implement *some* flavor of\n# iterator.  Don't check the type!  Use hasattr to check for both\n# \"__iter__\" and \"next\" attributes instead.\n\nNoneType = type(None)\nTypeType = type\nObjectType = object\n\nIntType = int\nLongType = long\nFloatType = float\nBooleanType = bool\ntry:\n    ComplexType = complex\nexcept NameError:\n    pass\n\nStringType = str\n\n# StringTypes is already outdated.  Instead of writing \"type(x) in\n# types.StringTypes\", you should use \"isinstance(x, basestring)\".  But\n# we keep around for compatibility with Python 2.2.\ntry:\n    UnicodeType = unicode\n    StringTypes = (StringType, UnicodeType)\nexcept NameError:\n    StringTypes = (StringType,)\n\nBufferType = buffer\n\nTupleType = tuple\nListType = list\nDictType = DictionaryType = dict\n\ndef _f(): pass\nFunctionType = type(_f)\nLambdaType = type(lambda: None)         # Same as FunctionType\nCodeType = type(_f.func_code)\n\ndef _g():\n    yield 1\nGeneratorType = type(_g())\n\nclass _C:\n    def _m(self): pass\nClassType = type(_C)\nUnboundMethodType = type(_C._m)         # Same as MethodType\n_x = _C()\nInstanceType = type(_x)\nMethodType = type(_x._m)\n\nBuiltinFunctionType = type(len)\nBuiltinMethodType = type([].append)     # Same as BuiltinFunctionType\n\nModuleType = type(sys)\nFileType = file\nXRangeType = xrange\n\ntry:\n    raise TypeError\nexcept TypeError:\n    tb = sys.exc_info()[2]\n    TracebackType = type(tb)\n    FrameType = type(tb.tb_frame)\n    del tb\n\nSliceType = slice\nEllipsisType = type(Ellipsis)\n\nDictProxyType = type(TypeType.__dict__)\nNotImplementedType = type(NotImplemented)\n\n# For Jython, the following two types are identical\nGetSetDescriptorType = type(FunctionType.func_code)\nMemberDescriptorType = type(FunctionType.func_globals)\n\ndel sys, _f, _g, _C, _x                           # Not for export\n", 
    "warnings": "\"\"\"Python part of the warnings subsystem.\"\"\"\n\n# Note: function level imports should *not* be used\n# in this module as it may cause import lock deadlock.\n# See bug 683658.\nimport linecache\nimport sys\nimport types\n\n__all__ = [\"warn\", \"showwarning\", \"formatwarning\", \"filterwarnings\",\n           \"resetwarnings\", \"catch_warnings\"]\n\n\ndef warnpy3k(message, category=None, stacklevel=1):\n    \"\"\"Issue a deprecation warning for Python 3.x related changes.\n\n    Warnings are omitted unless Python is started with the -3 option.\n    \"\"\"\n    if sys.py3kwarning:\n        if category is None:\n            category = DeprecationWarning\n        warn(message, category, stacklevel+1)\n\ndef _show_warning(message, category, filename, lineno, file=None, line=None):\n    \"\"\"Hook to write a warning to a file; replace if you like.\"\"\"\n    if file is None:\n        file = sys.stderr\n    try:\n        file.write(formatwarning(message, category, filename, lineno, line))\n    except IOError:\n        pass # the file (probably stderr) is invalid - this warning gets lost.\n# Keep a working version around in case the deprecation of the old API is\n# triggered.\nshowwarning = _show_warning\n\ndef formatwarning(message, category, filename, lineno, line=None):\n    \"\"\"Function to format a warning the standard way.\"\"\"\n    s =  \"%s:%s: %s: %s\\n\" % (filename, lineno, category.__name__, message)\n    line = linecache.getline(filename, lineno) if line is None else line\n    if line:\n        line = line.strip()\n        s += \"  %s\\n\" % line\n    return s\n\ndef filterwarnings(action, message=\"\", category=Warning, module=\"\", lineno=0,\n                   append=0):\n    \"\"\"Insert an entry into the list of warnings filters (at the front).\n\n    'action' -- one of \"error\", \"ignore\", \"always\", \"default\", \"module\",\n                or \"once\"\n    'message' -- a regex that the warning message must match\n    'category' -- a class that the warning must be a subclass of\n    'module' -- a regex that the module name must match\n    'lineno' -- an integer line number, 0 matches all warnings\n    'append' -- if true, append to the list of filters\n    \"\"\"\n    import re\n    assert action in (\"error\", \"ignore\", \"always\", \"default\", \"module\",\n                      \"once\"), \"invalid action: %r\" % (action,)\n    assert isinstance(message, basestring), \"message must be a string\"\n    assert isinstance(category, (type, types.ClassType)), \\\n           \"category must be a class\"\n    assert issubclass(category, Warning), \"category must be a Warning subclass\"\n    assert isinstance(module, basestring), \"module must be a string\"\n    assert isinstance(lineno, int) and lineno >= 0, \\\n           \"lineno must be an int >= 0\"\n    item = (action, re.compile(message, re.I), category,\n            re.compile(module), lineno)\n    if append:\n        filters.append(item)\n    else:\n        filters.insert(0, item)\n\ndef simplefilter(action, category=Warning, lineno=0, append=0):\n    \"\"\"Insert a simple entry into the list of warnings filters (at the front).\n\n    A simple filter matches all modules and messages.\n    'action' -- one of \"error\", \"ignore\", \"always\", \"default\", \"module\",\n                or \"once\"\n    'category' -- a class that the warning must be a subclass of\n    'lineno' -- an integer line number, 0 matches all warnings\n    'append' -- if true, append to the list of filters\n    \"\"\"\n    assert action in (\"error\", \"ignore\", \"always\", \"default\", \"module\",\n                      \"once\"), \"invalid action: %r\" % (action,)\n    assert isinstance(lineno, int) and lineno >= 0, \\\n           \"lineno must be an int >= 0\"\n    item = (action, None, category, None, lineno)\n    if append:\n        filters.append(item)\n    else:\n        filters.insert(0, item)\n\ndef resetwarnings():\n    \"\"\"Clear the list of warning filters, so that no filters are active.\"\"\"\n    filters[:] = []\n\nclass _OptionError(Exception):\n    \"\"\"Exception used by option processing helpers.\"\"\"\n    pass\n\n# Helper to process -W options passed via sys.warnoptions\ndef _processoptions(args):\n    for arg in args:\n        try:\n            _setoption(arg)\n        except _OptionError, msg:\n            print >>sys.stderr, \"Invalid -W option ignored:\", msg\n\n# Helper for _processoptions()\ndef _setoption(arg):\n    import re\n    parts = arg.split(':')\n    if len(parts) > 5:\n        raise _OptionError(\"too many fields (max 5): %r\" % (arg,))\n    while len(parts) < 5:\n        parts.append('')\n    action, message, category, module, lineno = [s.strip()\n                                                 for s in parts]\n    action = _getaction(action)\n    message = re.escape(message)\n    category = _getcategory(category)\n    module = re.escape(module)\n    if module:\n        module = module + '$'\n    if lineno:\n        try:\n            lineno = int(lineno)\n            if lineno < 0:\n                raise ValueError\n        except (ValueError, OverflowError):\n            raise _OptionError(\"invalid lineno %r\" % (lineno,))\n    else:\n        lineno = 0\n    filterwarnings(action, message, category, module, lineno)\n\n# Helper for _setoption()\ndef _getaction(action):\n    if not action:\n        return \"default\"\n    if action == \"all\": return \"always\" # Alias\n    for a in ('default', 'always', 'ignore', 'module', 'once', 'error'):\n        if a.startswith(action):\n            return a\n    raise _OptionError(\"invalid action: %r\" % (action,))\n\n# Helper for _setoption()\ndef _getcategory(category):\n    import re\n    if not category:\n        return Warning\n    if re.match(\"^[a-zA-Z0-9_]+$\", category):\n        try:\n            cat = eval(category)\n        except NameError:\n            raise _OptionError(\"unknown warning category: %r\" % (category,))\n    else:\n        i = category.rfind(\".\")\n        module = category[:i]\n        klass = category[i+1:]\n        try:\n            m = __import__(module, None, None, [klass])\n        except ImportError:\n            raise _OptionError(\"invalid module name: %r\" % (module,))\n        try:\n            cat = getattr(m, klass)\n        except AttributeError:\n            raise _OptionError(\"unknown warning category: %r\" % (category,))\n    if not issubclass(cat, Warning):\n        raise _OptionError(\"invalid warning category: %r\" % (category,))\n    return cat\n\n\n# Code typically replaced by _warnings\ndef warn(message, category=None, stacklevel=1):\n    \"\"\"Issue a warning, or maybe ignore it or raise an exception.\"\"\"\n    # Check if message is already a Warning object\n    if isinstance(message, Warning):\n        category = message.__class__\n    # Check category argument\n    if category is None:\n        category = UserWarning\n    assert issubclass(category, Warning)\n    # Get context information\n    try:\n        caller = sys._getframe(stacklevel)\n    except ValueError:\n        globals = sys.__dict__\n        lineno = 1\n    else:\n        globals = caller.f_globals\n        lineno = caller.f_lineno\n    if '__name__' in globals:\n        module = globals['__name__']\n    else:\n        module = \"<string>\"\n    filename = globals.get('__file__')\n    if filename:\n        fnl = filename.lower()\n        if fnl.endswith((\".pyc\", \".pyo\")):\n            filename = filename[:-1]\n    else:\n        if module == \"__main__\":\n            try:\n                filename = sys.argv[0]\n            except AttributeError:\n                # embedded interpreters don't have sys.argv, see bug #839151\n                filename = '__main__'\n        if not filename:\n            filename = module\n    registry = globals.setdefault(\"__warningregistry__\", {})\n    warn_explicit(message, category, filename, lineno, module, registry,\n                  globals)\n\ndef warn_explicit(message, category, filename, lineno,\n                  module=None, registry=None, module_globals=None):\n    lineno = int(lineno)\n    if module is None:\n        module = filename or \"<unknown>\"\n        if module[-3:].lower() == \".py\":\n            module = module[:-3] # XXX What about leading pathname?\n    if registry is None:\n        registry = {}\n    if isinstance(message, Warning):\n        text = str(message)\n        category = message.__class__\n    else:\n        text = message\n        message = category(message)\n    key = (text, category, lineno)\n    # Quick test for common case\n    if registry.get(key):\n        return\n    # Search the filters\n    for item in filters:\n        action, msg, cat, mod, ln = item\n        if ((msg is None or msg.match(text)) and\n            issubclass(category, cat) and\n            (mod is None or mod.match(module)) and\n            (ln == 0 or lineno == ln)):\n            break\n    else:\n        action = defaultaction\n    # Early exit actions\n    if action == \"ignore\":\n        registry[key] = 1\n        return\n\n    # Prime the linecache for formatting, in case the\n    # \"file\" is actually in a zipfile or something.\n    linecache.getlines(filename, module_globals)\n\n    if action == \"error\":\n        raise message\n    # Other actions\n    if action == \"once\":\n        registry[key] = 1\n        oncekey = (text, category)\n        if onceregistry.get(oncekey):\n            return\n        onceregistry[oncekey] = 1\n    elif action == \"always\":\n        pass\n    elif action == \"module\":\n        registry[key] = 1\n        altkey = (text, category, 0)\n        if registry.get(altkey):\n            return\n        registry[altkey] = 1\n    elif action == \"default\":\n        registry[key] = 1\n    else:\n        # Unrecognized actions are errors\n        raise RuntimeError(\n              \"Unrecognized action (%r) in warnings.filters:\\n %s\" %\n              (action, item))\n    # Print message and context\n    showwarning(message, category, filename, lineno)\n\n\nclass WarningMessage(object):\n\n    \"\"\"Holds the result of a single showwarning() call.\"\"\"\n\n    _WARNING_DETAILS = (\"message\", \"category\", \"filename\", \"lineno\", \"file\",\n                        \"line\")\n\n    def __init__(self, message, category, filename, lineno, file=None,\n                    line=None):\n        local_values = locals()\n        for attr in self._WARNING_DETAILS:\n            setattr(self, attr, local_values[attr])\n        self._category_name = category.__name__ if category else None\n\n    def __str__(self):\n        return (\"{message : %r, category : %r, filename : %r, lineno : %s, \"\n                    \"line : %r}\" % (self.message, self._category_name,\n                                    self.filename, self.lineno, self.line))\n\n\nclass catch_warnings(object):\n\n    \"\"\"A context manager that copies and restores the warnings filter upon\n    exiting the context.\n\n    The 'record' argument specifies whether warnings should be captured by a\n    custom implementation of warnings.showwarning() and be appended to a list\n    returned by the context manager. Otherwise None is returned by the context\n    manager. The objects appended to the list are arguments whose attributes\n    mirror the arguments to showwarning().\n\n    The 'module' argument is to specify an alternative module to the module\n    named 'warnings' and imported under that name. This argument is only useful\n    when testing the warnings module itself.\n\n    \"\"\"\n\n    def __init__(self, record=False, module=None):\n        \"\"\"Specify whether to record warnings and if an alternative module\n        should be used other than sys.modules['warnings'].\n\n        For compatibility with Python 3.0, please consider all arguments to be\n        keyword-only.\n\n        \"\"\"\n        self._record = record\n        self._module = sys.modules['warnings'] if module is None else module\n        self._entered = False\n\n    def __repr__(self):\n        args = []\n        if self._record:\n            args.append(\"record=True\")\n        if self._module is not sys.modules['warnings']:\n            args.append(\"module=%r\" % self._module)\n        name = type(self).__name__\n        return \"%s(%s)\" % (name, \", \".join(args))\n\n    def __enter__(self):\n        if self._entered:\n            raise RuntimeError(\"Cannot enter %r twice\" % self)\n        self._entered = True\n        self._filters = self._module.filters\n        self._module.filters = self._filters[:]\n        self._showwarning = self._module.showwarning\n        if self._record:\n            log = []\n            def showwarning(*args, **kwargs):\n                log.append(WarningMessage(*args, **kwargs))\n            self._module.showwarning = showwarning\n            return log\n        else:\n            return None\n\n    def __exit__(self, *exc_info):\n        if not self._entered:\n            raise RuntimeError(\"Cannot exit %r without entering first\" % self)\n        self._module.filters = self._filters\n        self._module.showwarning = self._showwarning\n\n\n# filters contains a sequence of filter 5-tuples\n# The components of the 5-tuple are:\n# - an action: error, ignore, always, default, module, or once\n# - a compiled regex that must match the warning message\n# - a class representing the warning category\n# - a compiled regex that must match the module that is being warned\n# - a line number for the line being warning, or 0 to mean any line\n# If either if the compiled regexs are None, match anything.\n_warnings_defaults = False\ntry:\n    from _warnings import (filters, default_action, once_registry,\n                            warn, warn_explicit)\n    defaultaction = default_action\n    onceregistry = once_registry\n    _warnings_defaults = True\nexcept ImportError:\n    filters = []\n    defaultaction = \"default\"\n    onceregistry = {}\n\n\n# Module initialization\n_processoptions(sys.warnoptions)\nif not _warnings_defaults:\n    silence = [ImportWarning, PendingDeprecationWarning]\n    # Don't silence DeprecationWarning if -3 or -Q was used.\n    if not sys.py3kwarning and not sys.flags.division_warning:\n        silence.append(DeprecationWarning)\n    for cls in silence:\n        simplefilter(\"ignore\", category=cls)\n    bytes_warning = sys.flags.bytes_warning\n    if bytes_warning > 1:\n        bytes_action = \"error\"\n    elif bytes_warning:\n        bytes_action = \"default\"\n    else:\n        bytes_action = \"ignore\"\n    simplefilter(bytes_action, category=BytesWarning, append=1)\ndel _warnings_defaults\n", 
    "weakref": "\"\"\"Weak reference support for Python.\n\nThis module is an implementation of PEP 205:\n\nhttp://www.python.org/dev/peps/pep-0205/\n\"\"\"\n\n# Naming convention: Variables named \"wr\" are weak reference objects;\n# they are called this instead of \"ref\" to avoid name collisions with\n# the module-global ref() function imported from _weakref.\n\nimport UserDict\n\nfrom _weakref import (\n     getweakrefcount,\n     getweakrefs,\n     ref,\n     proxy,\n     CallableProxyType,\n     ProxyType,\n     ReferenceType)\n\nfrom _weakrefset import WeakSet, _IterationGuard\n\nfrom exceptions import ReferenceError\n\n\nProxyTypes = (ProxyType, CallableProxyType)\n\n__all__ = [\"ref\", \"proxy\", \"getweakrefcount\", \"getweakrefs\",\n           \"WeakKeyDictionary\", \"ReferenceError\", \"ReferenceType\", \"ProxyType\",\n           \"CallableProxyType\", \"ProxyTypes\", \"WeakValueDictionary\", 'WeakSet']\n\n\nclass WeakValueDictionary(UserDict.UserDict):\n    \"\"\"Mapping class that references values weakly.\n\n    Entries in the dictionary will be discarded when no strong\n    reference to the value exists anymore\n    \"\"\"\n    # We inherit the constructor without worrying about the input\n    # dictionary; since it uses our .update() method, we get the right\n    # checks (if the other dictionary is a WeakValueDictionary,\n    # objects are unwrapped on the way out, and we always wrap on the\n    # way in).\n\n    def __init__(self, *args, **kw):\n        def remove(wr, selfref=ref(self)):\n            self = selfref()\n            if self is not None:\n                if self._iterating:\n                    self._pending_removals.append(wr.key)\n                else:\n                    # Changed this for PyPy: made more resistent.  The\n                    # issue is that in some corner cases, self.data\n                    # might already be changed or removed by the time\n                    # this weakref's callback is called.  If that is\n                    # the case, we don't want to randomly kill an\n                    # unrelated entry.\n                    if self.data.get(wr.key) is wr:\n                        del self.data[wr.key]\n        self._remove = remove\n        # A list of keys to be removed\n        self._pending_removals = []\n        self._iterating = set()\n        UserDict.UserDict.__init__(self, *args, **kw)\n\n    def _commit_removals(self):\n        l = self._pending_removals\n        d = self.data\n        # We shouldn't encounter any KeyError, because this method should\n        # always be called *before* mutating the dict.\n        while l:\n            del d[l.pop()]\n\n    def __getitem__(self, key):\n        o = self.data[key]()\n        if o is None:\n            raise KeyError, key\n        else:\n            return o\n\n    def __delitem__(self, key):\n        if self._pending_removals:\n            self._commit_removals()\n        del self.data[key]\n\n    def __contains__(self, key):\n        try:\n            o = self.data[key]()\n        except KeyError:\n            return False\n        return o is not None\n\n    def has_key(self, key):\n        try:\n            o = self.data[key]()\n        except KeyError:\n            return False\n        return o is not None\n\n    def __repr__(self):\n        return \"<WeakValueDictionary at %s>\" % id(self)\n\n    def __setitem__(self, key, value):\n        if self._pending_removals:\n            self._commit_removals()\n        self.data[key] = KeyedRef(value, self._remove, key)\n\n    def clear(self):\n        if self._pending_removals:\n            self._commit_removals()\n        self.data.clear()\n\n    def copy(self):\n        new = WeakValueDictionary()\n        for key, wr in self.data.items():\n            o = wr()\n            if o is not None:\n                new[key] = o\n        return new\n\n    __copy__ = copy\n\n    def __deepcopy__(self, memo):\n        from copy import deepcopy\n        new = self.__class__()\n        for key, wr in self.data.items():\n            o = wr()\n            if o is not None:\n                new[deepcopy(key, memo)] = o\n        return new\n\n    def get(self, key, default=None):\n        try:\n            wr = self.data[key]\n        except KeyError:\n            return default\n        else:\n            o = wr()\n            if o is None:\n                # This should only happen\n                return default\n            else:\n                return o\n\n    def items(self):\n        L = []\n        for key, wr in self.data.items():\n            o = wr()\n            if o is not None:\n                L.append((key, o))\n        return L\n\n    def iteritems(self):\n        with _IterationGuard(self):\n            for wr in self.data.itervalues():\n                value = wr()\n                if value is not None:\n                    yield wr.key, value\n\n    def iterkeys(self):\n        with _IterationGuard(self):\n            for k in self.data.iterkeys():\n                yield k\n\n    __iter__ = iterkeys\n\n    def itervaluerefs(self):\n        \"\"\"Return an iterator that yields the weak references to the values.\n\n        The references are not guaranteed to be 'live' at the time\n        they are used, so the result of calling the references needs\n        to be checked before being used.  This can be used to avoid\n        creating references that will cause the garbage collector to\n        keep the values around longer than needed.\n\n        \"\"\"\n        with _IterationGuard(self):\n            for wr in self.data.itervalues():\n                yield wr\n\n    def itervalues(self):\n        with _IterationGuard(self):\n            for wr in self.data.itervalues():\n                obj = wr()\n                if obj is not None:\n                    yield obj\n\n    def popitem(self):\n        if self._pending_removals:\n            self._commit_removals()\n        while 1:\n            key, wr = self.data.popitem()\n            o = wr()\n            if o is not None:\n                return key, o\n\n    def pop(self, key, *args):\n        if self._pending_removals:\n            self._commit_removals()\n        try:\n            o = self.data.pop(key)()\n        except KeyError:\n            o = None\n        if o is None:\n            if args:\n                return args[0]\n            raise KeyError, key\n        else:\n            return o\n        # The logic above was fixed in PyPy\n\n    def setdefault(self, key, default=None):\n        try:\n            o = self.data[key]()\n        except KeyError:\n            o = None\n        if o is None:\n            if self._pending_removals:\n                self._commit_removals()\n            self.data[key] = KeyedRef(default, self._remove, key)\n            return default\n        else:\n            return o\n        # The logic above was fixed in PyPy\n\n    def update(self, dict=None, **kwargs):\n        if self._pending_removals:\n            self._commit_removals()\n        d = self.data\n        if dict is not None:\n            if not hasattr(dict, \"items\"):\n                dict = type({})(dict)\n            for key, o in dict.items():\n                d[key] = KeyedRef(o, self._remove, key)\n        if len(kwargs):\n            self.update(kwargs)\n\n    def valuerefs(self):\n        \"\"\"Return a list of weak references to the values.\n\n        The references are not guaranteed to be 'live' at the time\n        they are used, so the result of calling the references needs\n        to be checked before being used.  This can be used to avoid\n        creating references that will cause the garbage collector to\n        keep the values around longer than needed.\n\n        \"\"\"\n        return self.data.values()\n\n    def values(self):\n        L = []\n        for wr in self.data.values():\n            o = wr()\n            if o is not None:\n                L.append(o)\n        return L\n\n\nclass KeyedRef(ref):\n    \"\"\"Specialized reference that includes a key corresponding to the value.\n\n    This is used in the WeakValueDictionary to avoid having to create\n    a function object for each key stored in the mapping.  A shared\n    callback object can use the 'key' attribute of a KeyedRef instead\n    of getting a reference to the key from an enclosing scope.\n\n    \"\"\"\n\n    __slots__ = \"key\",\n\n    def __new__(type, ob, callback, key):\n        self = ref.__new__(type, ob, callback)\n        self.key = key\n        return self\n\n    def __init__(self, ob, callback, key):\n        super(KeyedRef,  self).__init__(ob, callback)\n\n\nclass WeakKeyDictionary(UserDict.UserDict):\n    \"\"\" Mapping class that references keys weakly.\n\n    Entries in the dictionary will be discarded when there is no\n    longer a strong reference to the key. This can be used to\n    associate additional data with an object owned by other parts of\n    an application without adding attributes to those objects. This\n    can be especially useful with objects that override attribute\n    accesses.\n    \"\"\"\n\n    def __init__(self, dict=None):\n        self.data = {}\n        def remove(k, selfref=ref(self)):\n            self = selfref()\n            if self is not None:\n                if self._iterating:\n                    self._pending_removals.append(k)\n                else:\n                    del self.data[k]\n        self._remove = remove\n        # A list of dead weakrefs (keys to be removed)\n        self._pending_removals = []\n        self._iterating = set()\n        if dict is not None:\n            self.update(dict)\n\n    def _commit_removals(self):\n        # NOTE: We don't need to call this method before mutating the dict,\n        # because a dead weakref never compares equal to a live weakref,\n        # even if they happened to refer to equal objects.\n        # However, it means keys may already have been removed.\n        l = self._pending_removals\n        d = self.data\n        while l:\n            try:\n                del d[l.pop()]\n            except KeyError:\n                pass\n\n    def __delitem__(self, key):\n        del self.data[ref(key)]\n\n    def __getitem__(self, key):\n        return self.data[ref(key)]\n\n    def __repr__(self):\n        return \"<WeakKeyDictionary at %s>\" % id(self)\n\n    def __setitem__(self, key, value):\n        self.data[ref(key, self._remove)] = value\n\n    def copy(self):\n        new = WeakKeyDictionary()\n        for key, value in self.data.items():\n            o = key()\n            if o is not None:\n                new[o] = value\n        return new\n\n    __copy__ = copy\n\n    def __deepcopy__(self, memo):\n        from copy import deepcopy\n        new = self.__class__()\n        for key, value in self.data.items():\n            o = key()\n            if o is not None:\n                new[o] = deepcopy(value, memo)\n        return new\n\n    def get(self, key, default=None):\n        return self.data.get(ref(key),default)\n\n    def has_key(self, key):\n        try:\n            wr = ref(key)\n        except TypeError:\n            return 0\n        return wr in self.data\n\n    def __contains__(self, key):\n        try:\n            wr = ref(key)\n        except TypeError:\n            return 0\n        return wr in self.data\n\n    def items(self):\n        L = []\n        for key, value in self.data.items():\n            o = key()\n            if o is not None:\n                L.append((o, value))\n        return L\n\n    def iteritems(self):\n        with _IterationGuard(self):\n            for wr, value in self.data.iteritems():\n                key = wr()\n                if key is not None:\n                    yield key, value\n\n    def iterkeyrefs(self):\n        \"\"\"Return an iterator that yields the weak references to the keys.\n\n        The references are not guaranteed to be 'live' at the time\n        they are used, so the result of calling the references needs\n        to be checked before being used.  This can be used to avoid\n        creating references that will cause the garbage collector to\n        keep the keys around longer than needed.\n\n        \"\"\"\n        with _IterationGuard(self):\n            for wr in self.data.iterkeys():\n                yield wr\n\n    def iterkeys(self):\n        with _IterationGuard(self):\n            for wr in self.data.iterkeys():\n                obj = wr()\n                if obj is not None:\n                    yield obj\n\n    __iter__ = iterkeys\n\n    def itervalues(self):\n        with _IterationGuard(self):\n            for value in self.data.itervalues():\n                yield value\n\n    def keyrefs(self):\n        \"\"\"Return a list of weak references to the keys.\n\n        The references are not guaranteed to be 'live' at the time\n        they are used, so the result of calling the references needs\n        to be checked before being used.  This can be used to avoid\n        creating references that will cause the garbage collector to\n        keep the keys around longer than needed.\n\n        \"\"\"\n        return self.data.keys()\n\n    def keys(self):\n        L = []\n        for wr in self.data.keys():\n            o = wr()\n            if o is not None:\n                L.append(o)\n        return L\n\n    def popitem(self):\n        while 1:\n            key, value = self.data.popitem()\n            o = key()\n            if o is not None:\n                return o, value\n\n    def pop(self, key, *args):\n        return self.data.pop(ref(key), *args)\n\n    def setdefault(self, key, default=None):\n        return self.data.setdefault(ref(key, self._remove),default)\n\n    def update(self, dict=None, **kwargs):\n        d = self.data\n        if dict is not None:\n            if not hasattr(dict, \"items\"):\n                dict = type({})(dict)\n            for key, value in dict.items():\n                d[ref(key, self._remove)] = value\n        if len(kwargs):\n            self.update(kwargs)\n"
  }
}